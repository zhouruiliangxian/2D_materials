2024/04/10 15:44:31 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0,1: NVIDIA RTX A2000 12GB
    CUDA_HOME: /home/zhouruiliang/.conda/envs/mmseg
    NVCC: Cuda compilation tools, release 11.6, V11.6.124
    GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 4.9.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: True
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 0
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2024/04/10 15:44:32 - mmengine - INFO - Config:
checkpoint = 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb256-rsb-a1-600e_in1k_20211228-20e21305.pth'
crop_size = (
    640,
    640,
)
custom_imports = dict(
    allow_failed_imports=False, imports=[
        'mmpretrain.models',
    ])
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'MoS2_data/'
dataset_type = 'MoSdata'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=2500,
        max_keep_ckpts=1,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=192,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=4,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        features_only=True,
        model_name='fastvit_t8',
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        pretrained=True,
        type='mmpretrain.TIMMBackbone'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            640,
            640,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=384,
        in_index=3,
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=4,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='PSPHead'),
    pretrained=None,
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=dict(max_norm=1, norm_type=2),
    optimizer=dict(lr=0.0005, type='AdamW', weight_decay=0.05),
    type='OptimWrapper')
optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=1000, start_factor=0.001,
        type='LinearLR'),
    dict(
        begin=1000,
        by_epoch=False,
        end=80000,
        milestones=[
            60000,
            72000,
        ],
        type='MultiStepLR'),
]
randomness = dict(seed=0)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/test', seg_map_path='ann_dir/test'),
        data_root='MoS2_data/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MoSdata'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=500)
train_dataloader = dict(
    batch_size=8,
    dataset=dict(
        data_prefix=dict(
            img_path='img_dir/train', seg_map_path='ann_dir/train'),
        data_root='MoS2_data/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    2048,
                    1024,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    640,
                    640,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='MoSdata'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            1024,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        640,
        640,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),
        data_root='MoS2_data/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MoSdata'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_head_dirs/fastvit-pspnet_ful'

2024/04/10 15:44:48 - mmengine - INFO - backbone out_indices: (0, 1, 2, 3)
2024/04/10 15:44:48 - mmengine - INFO - backbone out_channels: [48, 96, 192, 384]
2024/04/10 15:44:48 - mmengine - INFO - backbone out_strides: [4, 8, 16, 32]
2024/04/10 15:44:50 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2024/04/10 15:44:50 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/04/10 15:44:50 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.timm_model.stem_0.conv_kxk.0.conv.weight - torch.Size([48, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_0.conv_kxk.0.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_0.conv_kxk.0.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_0.conv_scale.conv.weight - torch.Size([48, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_0.conv_scale.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_0.conv_scale.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_1.conv_kxk.0.conv.weight - torch.Size([48, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_1.conv_kxk.0.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_1.conv_kxk.0.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_1.conv_scale.conv.weight - torch.Size([48, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_1.conv_scale.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_1.conv_scale.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_2.identity.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_2.identity.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_2.conv_kxk.0.conv.weight - torch.Size([48, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_2.conv_kxk.0.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stem_2.conv_kxk.0.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.norm.identity.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.norm.identity.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.identity.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.identity.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([48, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.conv_scale.conv.weight - torch.Size([48, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.conv_scale.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.mixer.conv_scale.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.token_mixer.layer_scale.gamma - torch.Size([48, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.mlp.conv.conv.weight - torch.Size([48, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.mlp.conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.mlp.conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.mlp.fc1.weight - torch.Size([144, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.mlp.fc1.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.mlp.fc2.weight - torch.Size([48, 144, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.mlp.fc2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.0.layer_scale.gamma - torch.Size([48, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.norm.identity.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.norm.identity.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.identity.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.identity.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([48, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.conv_scale.conv.weight - torch.Size([48, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.conv_scale.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.mixer.conv_scale.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.token_mixer.layer_scale.gamma - torch.Size([48, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.mlp.conv.conv.weight - torch.Size([48, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.mlp.conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.mlp.conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.mlp.fc1.weight - torch.Size([144, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.mlp.fc1.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.mlp.fc2.weight - torch.Size([48, 144, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.mlp.fc2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_0.blocks.1.layer_scale.gamma - torch.Size([48, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.0.large_conv.conv.weight - torch.Size([96, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.0.large_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.0.large_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.0.small_conv.conv.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.0.small_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.0.small_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.1.identity.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.1.identity.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.1.conv_kxk.0.conv.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.1.conv_kxk.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.downsample.proj.1.conv_kxk.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.norm.identity.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.norm.identity.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.identity.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.identity.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.conv_scale.conv.weight - torch.Size([96, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.conv_scale.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.mixer.conv_scale.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.token_mixer.layer_scale.gamma - torch.Size([96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.mlp.conv.conv.weight - torch.Size([96, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.mlp.conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.mlp.conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.mlp.fc1.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.mlp.fc1.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.mlp.fc2.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.mlp.fc2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.0.layer_scale.gamma - torch.Size([96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.norm.identity.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.norm.identity.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.identity.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.identity.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.conv_scale.conv.weight - torch.Size([96, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.conv_scale.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.mixer.conv_scale.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.token_mixer.layer_scale.gamma - torch.Size([96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.mlp.conv.conv.weight - torch.Size([96, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.mlp.conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.mlp.conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.mlp.fc1.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.mlp.fc1.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.mlp.fc2.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.mlp.fc2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_1.blocks.1.layer_scale.gamma - torch.Size([96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.0.large_conv.conv.weight - torch.Size([192, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.0.large_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.0.large_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.0.small_conv.conv.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.0.small_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.0.small_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.1.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.1.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.1.conv_kxk.0.conv.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.1.conv_kxk.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.downsample.proj.1.conv_kxk.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.norm.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.norm.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.conv_scale.conv.weight - torch.Size([192, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.conv_scale.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.mixer.conv_scale.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.token_mixer.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.mlp.conv.conv.weight - torch.Size([192, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.mlp.conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.mlp.conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.mlp.fc1.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.mlp.fc1.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.mlp.fc2.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.mlp.fc2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.0.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.norm.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.norm.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.conv_scale.conv.weight - torch.Size([192, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.conv_scale.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.mixer.conv_scale.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.token_mixer.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.mlp.conv.conv.weight - torch.Size([192, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.mlp.conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.mlp.conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.mlp.fc1.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.mlp.fc1.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.mlp.fc2.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.mlp.fc2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.1.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.norm.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.norm.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.conv_scale.conv.weight - torch.Size([192, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.conv_scale.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.mixer.conv_scale.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.token_mixer.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.mlp.conv.conv.weight - torch.Size([192, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.mlp.conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.mlp.conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.mlp.fc1.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.mlp.fc1.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.mlp.fc2.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.mlp.fc2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.2.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.norm.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.norm.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.identity.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.identity.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.conv_scale.conv.weight - torch.Size([192, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.conv_scale.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.mixer.conv_scale.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.token_mixer.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.mlp.conv.conv.weight - torch.Size([192, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.mlp.conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.mlp.conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.mlp.fc1.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.mlp.fc1.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.mlp.fc2.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.mlp.fc2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_2.blocks.3.layer_scale.gamma - torch.Size([192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.0.large_conv.conv.weight - torch.Size([384, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.0.large_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.0.large_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.0.small_conv.conv.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.0.small_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.0.small_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.1.identity.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.1.identity.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.1.conv_kxk.0.conv.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.1.conv_kxk.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.downsample.proj.1.conv_kxk.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.norm.identity.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.norm.identity.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.identity.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.identity.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.conv_scale.conv.weight - torch.Size([384, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.conv_scale.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.mixer.conv_scale.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.token_mixer.layer_scale.gamma - torch.Size([384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.mlp.conv.conv.weight - torch.Size([384, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.mlp.conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.mlp.conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.mlp.fc1.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.mlp.fc1.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.mlp.fc2.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.0.layer_scale.gamma - torch.Size([384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.norm.identity.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.norm.identity.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.identity.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.identity.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.conv_kxk.0.conv.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.conv_kxk.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.conv_kxk.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.conv_scale.conv.weight - torch.Size([384, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.conv_scale.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.mixer.conv_scale.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.token_mixer.layer_scale.gamma - torch.Size([384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.mlp.conv.conv.weight - torch.Size([384, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.mlp.conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.mlp.conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.mlp.fc1.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.mlp.fc1.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.mlp.fc2.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.timm_model.stages_3.blocks.1.layer_scale.gamma - torch.Size([384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([4, 512, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.psp_modules.0.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.conv.weight - torch.Size([512, 2432, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.conv_seg.weight - torch.Size([4, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.conv_seg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.convs.0.conv.weight - torch.Size([256, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/04/10 15:44:50 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/04/10 15:44:50 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/04/10 15:44:50 - mmengine - INFO - Checkpoints will be saved to /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/fastvit-pspnet_ful.
2024/04/10 15:45:04 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 15:45:04 - mmengine - INFO - Iter(train) [   14/20000]  lr: 7.0000e-06  eta: 5:34:35  time: 0.4985  data_time: 0.0136  memory: 7186  grad_norm: 39.7809  loss: 1.8918  decode.loss_ce: 1.3422  decode.acc_seg: 30.2275  aux.loss_ce: 0.5496  aux.acc_seg: 11.6797
2024/04/10 15:45:47 - mmengine - INFO - Iter(train) [  100/20000]  lr: 5.0000e-05  eta: 3:08:00  time: 0.4989  data_time: 0.0137  memory: 4027  grad_norm: 25.4764  loss: 1.6093  decode.loss_ce: 1.1012  decode.acc_seg: 56.1334  aux.loss_ce: 0.5081  aux.acc_seg: 53.9106
2024/04/10 15:46:37 - mmengine - INFO - Iter(train) [  200/20000]  lr: 1.0000e-04  eta: 2:56:23  time: 0.5021  data_time: 0.0144  memory: 4027  grad_norm: 19.3579  loss: 1.1394  decode.loss_ce: 0.7411  decode.acc_seg: 81.2744  aux.loss_ce: 0.3983  aux.acc_seg: 75.1968
2024/04/10 15:47:27 - mmengine - INFO - Iter(train) [  300/20000]  lr: 1.5000e-04  eta: 2:51:23  time: 0.4973  data_time: 0.0137  memory: 4027  grad_norm: 20.7403  loss: 0.8663  decode.loss_ce: 0.5708  decode.acc_seg: 79.1758  aux.loss_ce: 0.2955  aux.acc_seg: 75.3999
2024/04/10 15:48:16 - mmengine - INFO - Iter(train) [  400/20000]  lr: 2.0000e-04  eta: 2:48:17  time: 0.4962  data_time: 0.0137  memory: 4027  grad_norm: 23.2886  loss: 0.8343  decode.loss_ce: 0.5496  decode.acc_seg: 86.2800  aux.loss_ce: 0.2847  aux.acc_seg: 63.5268
2024/04/10 15:49:06 - mmengine - INFO - Iter(train) [  500/20000]  lr: 2.5000e-04  eta: 2:46:03  time: 0.4928  data_time: 0.0124  memory: 4027  grad_norm: 15.2072  loss: 0.8130  decode.loss_ce: 0.5255  decode.acc_seg: 93.1062  aux.loss_ce: 0.2875  aux.acc_seg: 85.4424
2024/04/10 15:49:08 - mmengine - INFO - per class results:
2024/04/10 15:49:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 82.73 | 93.49 | 90.55 | 90.55  |   87.79   | 93.49  |
| monolayer  | 51.51 | 61.09 |  68.0 |  68.0  |   76.66   | 61.09  |
|  bilayer   | 24.28 | 25.34 | 39.07 | 39.07  |   85.23   | 25.34  |
| multilayer | 60.07 | 97.51 | 75.05 | 75.05  |    61.0   | 97.51  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 15:49:08 - mmengine - INFO - Iter(val) [15/15]    aAcc: 81.6800  mIoU: 54.6500  mAcc: 69.3600  mDice: 68.1700  mFscore: 68.1700  mPrecision: 77.6700  mRecall: 69.3600  data_time: 0.0607  time: 0.1532
2024/04/10 15:49:09 - mmengine - INFO - The best checkpoint with 54.6500 mIoU at 500 iter is saved to best_mIoU_iter_500.pth.
2024/04/10 15:49:58 - mmengine - INFO - Iter(train) [  600/20000]  lr: 3.0000e-04  eta: 2:44:39  time: 0.4978  data_time: 0.0137  memory: 5489  grad_norm: 25.6930  loss: 0.6653  decode.loss_ce: 0.4178  decode.acc_seg: 80.1625  aux.loss_ce: 0.2475  aux.acc_seg: 63.6193
2024/04/10 15:50:47 - mmengine - INFO - Iter(train) [  700/20000]  lr: 3.5000e-04  eta: 2:43:00  time: 0.4940  data_time: 0.0135  memory: 4026  grad_norm: 11.3858  loss: 0.6608  decode.loss_ce: 0.4231  decode.acc_seg: 76.0786  aux.loss_ce: 0.2377  aux.acc_seg: 74.2922
2024/04/10 15:51:37 - mmengine - INFO - Iter(train) [  800/20000]  lr: 4.0000e-04  eta: 2:41:36  time: 0.4936  data_time: 0.0137  memory: 4027  grad_norm: 15.0997  loss: 0.5542  decode.loss_ce: 0.3440  decode.acc_seg: 87.4910  aux.loss_ce: 0.2101  aux.acc_seg: 85.0204
2024/04/10 15:52:26 - mmengine - INFO - Iter(train) [  900/20000]  lr: 4.5000e-04  eta: 2:40:19  time: 0.4958  data_time: 0.0148  memory: 4027  grad_norm: 5.7579  loss: 0.5581  decode.loss_ce: 0.3538  decode.acc_seg: 85.7173  aux.loss_ce: 0.2043  aux.acc_seg: 76.0292
2024/04/10 15:53:15 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 15:53:15 - mmengine - INFO - Iter(train) [ 1000/20000]  lr: 5.0000e-04  eta: 2:39:05  time: 0.4908  data_time: 0.0120  memory: 4027  grad_norm: 9.8628  loss: 0.5331  decode.loss_ce: 0.3381  decode.acc_seg: 93.7893  aux.loss_ce: 0.1950  aux.acc_seg: 85.8058
2024/04/10 15:53:16 - mmengine - INFO - per class results:
2024/04/10 15:53:16 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 48.86 | 54.64 | 65.65 | 65.65  |   82.21   | 54.64  |
| monolayer  |  27.9 | 31.28 | 43.62 | 43.62  |   72.08   | 31.28  |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer | 16.73 | 95.37 | 28.66 | 28.66  |   16.86   | 95.37  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 15:53:16 - mmengine - INFO - Iter(val) [15/15]    aAcc: 49.1100  mIoU: 23.3700  mAcc: 45.3200  mDice: 34.4800  mFscore: 45.9800  mPrecision: 57.0500  mRecall: 45.3200  data_time: 0.0063  time: 0.0437
2024/04/10 15:54:05 - mmengine - INFO - Iter(train) [ 1100/20000]  lr: 5.0000e-04  eta: 2:37:56  time: 0.4897  data_time: 0.0124  memory: 4027  grad_norm: 7.4357  loss: 0.4825  decode.loss_ce: 0.3003  decode.acc_seg: 95.2276  aux.loss_ce: 0.1822  aux.acc_seg: 93.8904
2024/04/10 15:54:54 - mmengine - INFO - Iter(train) [ 1200/20000]  lr: 5.0000e-04  eta: 2:36:49  time: 0.4909  data_time: 0.0131  memory: 4027  grad_norm: 9.3861  loss: 0.4309  decode.loss_ce: 0.2700  decode.acc_seg: 95.2350  aux.loss_ce: 0.1609  aux.acc_seg: 93.1740
2024/04/10 15:55:43 - mmengine - INFO - Iter(train) [ 1300/20000]  lr: 5.0000e-04  eta: 2:35:46  time: 0.4890  data_time: 0.0119  memory: 4027  grad_norm: 10.8522  loss: 0.4882  decode.loss_ce: 0.3106  decode.acc_seg: 86.7186  aux.loss_ce: 0.1776  aux.acc_seg: 76.1940
2024/04/10 15:56:32 - mmengine - INFO - Iter(train) [ 1400/20000]  lr: 5.0000e-04  eta: 2:34:41  time: 0.4875  data_time: 0.0117  memory: 4027  grad_norm: 7.2261  loss: 0.4041  decode.loss_ce: 0.2415  decode.acc_seg: 82.4349  aux.loss_ce: 0.1626  aux.acc_seg: 81.4002
2024/04/10 15:57:21 - mmengine - INFO - Iter(train) [ 1500/20000]  lr: 5.0000e-04  eta: 2:33:43  time: 0.4958  data_time: 0.0145  memory: 4027  grad_norm: 4.8574  loss: 0.2383  decode.loss_ce: 0.1469  decode.acc_seg: 94.2659  aux.loss_ce: 0.0913  aux.acc_seg: 89.1609
2024/04/10 15:57:22 - mmengine - INFO - per class results:
2024/04/10 15:57:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 70.05 |  93.0 | 82.39 | 82.39  |   73.94   |  93.0  |
| monolayer  |  35.2 | 42.84 | 52.07 | 52.07  |   66.37   | 42.84  |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer |  80.6 | 85.52 | 89.26 | 89.26  |   93.34   | 85.52  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 15:57:22 - mmengine - INFO - Iter(val) [15/15]    aAcc: 74.1700  mIoU: 46.4600  mAcc: 55.3400  mDice: 55.9300  mFscore: 74.5700  mPrecision: 77.8800  mRecall: 55.3400  data_time: 0.0059  time: 0.0435
2024/04/10 15:58:11 - mmengine - INFO - Iter(train) [ 1600/20000]  lr: 5.0000e-04  eta: 2:32:43  time: 0.4890  data_time: 0.0122  memory: 4026  grad_norm: 9.8950  loss: 0.4270  decode.loss_ce: 0.2789  decode.acc_seg: 88.9523  aux.loss_ce: 0.1481  aux.acc_seg: 79.5309
2024/04/10 15:59:00 - mmengine - INFO - Iter(train) [ 1700/20000]  lr: 5.0000e-04  eta: 2:31:44  time: 0.4964  data_time: 0.0153  memory: 4027  grad_norm: 9.3966  loss: 0.3615  decode.loss_ce: 0.2255  decode.acc_seg: 94.9794  aux.loss_ce: 0.1360  aux.acc_seg: 91.4004
2024/04/10 15:59:49 - mmengine - INFO - Iter(train) [ 1800/20000]  lr: 5.0000e-04  eta: 2:30:46  time: 0.4945  data_time: 0.0148  memory: 4027  grad_norm: 6.0554  loss: 0.2733  decode.loss_ce: 0.1663  decode.acc_seg: 94.6857  aux.loss_ce: 0.1070  aux.acc_seg: 92.0341
2024/04/10 16:00:38 - mmengine - INFO - Iter(train) [ 1900/20000]  lr: 5.0000e-04  eta: 2:29:54  time: 0.4916  data_time: 0.0140  memory: 4026  grad_norm: 10.5456  loss: 0.3235  decode.loss_ce: 0.2173  decode.acc_seg: 96.1013  aux.loss_ce: 0.1062  aux.acc_seg: 94.6355
2024/04/10 16:01:27 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:01:27 - mmengine - INFO - Iter(train) [ 2000/20000]  lr: 5.0000e-04  eta: 2:28:58  time: 0.4882  data_time: 0.0125  memory: 4027  grad_norm: 10.6643  loss: 0.2786  decode.loss_ce: 0.1627  decode.acc_seg: 97.5833  aux.loss_ce: 0.1159  aux.acc_seg: 96.6097
2024/04/10 16:01:28 - mmengine - INFO - per class results:
2024/04/10 16:01:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 85.89 | 90.83 | 92.41 | 92.41  |   94.04   | 90.83  |
| monolayer  | 53.97 | 64.36 | 70.11 | 70.11  |   76.97   | 64.36  |
|  bilayer   |  22.9 | 26.48 | 37.27 | 37.27  |   62.93   | 26.48  |
| multilayer | 43.39 | 93.39 | 60.52 | 60.52  |   44.77   | 93.39  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:01:28 - mmengine - INFO - Iter(val) [15/15]    aAcc: 80.6700  mIoU: 51.5400  mAcc: 68.7700  mDice: 65.0800  mFscore: 65.0800  mPrecision: 69.6800  mRecall: 68.7700  data_time: 0.0063  time: 0.0444
2024/04/10 16:02:17 - mmengine - INFO - Iter(train) [ 2100/20000]  lr: 5.0000e-04  eta: 2:28:04  time: 0.4945  data_time: 0.0149  memory: 4027  grad_norm: 12.1628  loss: 0.3134  decode.loss_ce: 0.2055  decode.acc_seg: 89.8076  aux.loss_ce: 0.1079  aux.acc_seg: 89.8545
2024/04/10 16:03:06 - mmengine - INFO - Iter(train) [ 2200/20000]  lr: 5.0000e-04  eta: 2:27:11  time: 0.4909  data_time: 0.0140  memory: 4027  grad_norm: 6.1422  loss: 0.2642  decode.loss_ce: 0.1631  decode.acc_seg: 97.1917  aux.loss_ce: 0.1010  aux.acc_seg: 96.3706
2024/04/10 16:03:55 - mmengine - INFO - Iter(train) [ 2300/20000]  lr: 5.0000e-04  eta: 2:26:18  time: 0.4884  data_time: 0.0119  memory: 4027  grad_norm: 6.3083  loss: 0.2919  decode.loss_ce: 0.1817  decode.acc_seg: 96.7858  aux.loss_ce: 0.1102  aux.acc_seg: 95.0211
2024/04/10 16:04:44 - mmengine - INFO - Iter(train) [ 2400/20000]  lr: 5.0000e-04  eta: 2:25:24  time: 0.4941  data_time: 0.0143  memory: 4027  grad_norm: 1.9122  loss: 0.1803  decode.loss_ce: 0.1067  decode.acc_seg: 95.6857  aux.loss_ce: 0.0736  aux.acc_seg: 94.1042
2024/04/10 16:05:33 - mmengine - INFO - Iter(train) [ 2500/20000]  lr: 5.0000e-04  eta: 2:24:30  time: 0.4970  data_time: 0.0163  memory: 4026  grad_norm: 9.0279  loss: 0.2465  decode.loss_ce: 0.1664  decode.acc_seg: 96.3828  aux.loss_ce: 0.0801  aux.acc_seg: 94.3962
2024/04/10 16:05:33 - mmengine - INFO - Saving checkpoint at 2500 iterations
2024/04/10 16:05:35 - mmengine - INFO - per class results:
2024/04/10 16:05:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 55.86 | 62.47 | 71.68 | 71.68  |   84.06   | 62.47  |
| monolayer  |  4.2  |  4.5  |  8.05 |  8.05  |   38.03   |  4.5   |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    0.0    |  0.0   |
| multilayer | 16.41 | 99.93 | 28.19 | 28.19  |   16.41   | 99.93  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:05:35 - mmengine - INFO - Iter(val) [15/15]    aAcc: 47.0000  mIoU: 19.1100  mAcc: 41.7300  mDice: 26.9800  mFscore: 35.9700  mPrecision: 34.6200  mRecall: 41.7300  data_time: 0.0063  time: 0.0438
2024/04/10 16:06:24 - mmengine - INFO - Iter(train) [ 2600/20000]  lr: 5.0000e-04  eta: 2:23:37  time: 0.4885  data_time: 0.0125  memory: 4027  grad_norm: 3.2585  loss: 0.2859  decode.loss_ce: 0.1753  decode.acc_seg: 94.4964  aux.loss_ce: 0.1106  aux.acc_seg: 95.7633
2024/04/10 16:07:13 - mmengine - INFO - Iter(train) [ 2700/20000]  lr: 5.0000e-04  eta: 2:22:44  time: 0.4850  data_time: 0.0114  memory: 4027  grad_norm: 10.2570  loss: 0.3378  decode.loss_ce: 0.2146  decode.acc_seg: 95.7145  aux.loss_ce: 0.1232  aux.acc_seg: 90.1301
2024/04/10 16:08:02 - mmengine - INFO - Iter(train) [ 2800/20000]  lr: 5.0000e-04  eta: 2:21:50  time: 0.4891  data_time: 0.0136  memory: 4027  grad_norm: 11.1369  loss: 0.3484  decode.loss_ce: 0.2250  decode.acc_seg: 92.6983  aux.loss_ce: 0.1234  aux.acc_seg: 92.7823
2024/04/10 16:08:51 - mmengine - INFO - Iter(train) [ 2900/20000]  lr: 5.0000e-04  eta: 2:20:57  time: 0.4870  data_time: 0.0121  memory: 4026  grad_norm: 8.5941  loss: 0.2660  decode.loss_ce: 0.1739  decode.acc_seg: 82.6142  aux.loss_ce: 0.0921  aux.acc_seg: 80.1077
2024/04/10 16:09:39 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:09:39 - mmengine - INFO - Iter(train) [ 3000/20000]  lr: 5.0000e-04  eta: 2:20:04  time: 0.4906  data_time: 0.0134  memory: 4027  grad_norm: 11.1929  loss: 0.3306  decode.loss_ce: 0.2125  decode.acc_seg: 95.1652  aux.loss_ce: 0.1182  aux.acc_seg: 94.8898
2024/04/10 16:09:40 - mmengine - INFO - per class results:
2024/04/10 16:09:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 74.51 | 81.11 | 85.39 | 85.39  |   90.15   | 81.11  |
| monolayer  | 55.29 | 83.65 | 71.21 | 71.21  |   61.99   | 83.65  |
|  bilayer   | 10.14 | 10.14 | 18.41 | 18.41  |   99.99   | 10.14  |
| multilayer | 76.34 | 92.71 | 86.58 | 86.58  |   81.22   | 92.71  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:09:40 - mmengine - INFO - Iter(val) [15/15]    aAcc: 79.1600  mIoU: 54.0700  mAcc: 66.9000  mDice: 65.4000  mFscore: 65.4000  mPrecision: 83.3400  mRecall: 66.9000  data_time: 0.0059  time: 0.0434
2024/04/10 16:10:29 - mmengine - INFO - Iter(train) [ 3100/20000]  lr: 5.0000e-04  eta: 2:19:12  time: 0.4872  data_time: 0.0123  memory: 4027  grad_norm: 6.4443  loss: 0.2590  decode.loss_ce: 0.1620  decode.acc_seg: 87.2687  aux.loss_ce: 0.0970  aux.acc_seg: 84.7775
2024/04/10 16:11:18 - mmengine - INFO - Iter(train) [ 3200/20000]  lr: 5.0000e-04  eta: 2:18:19  time: 0.4887  data_time: 0.0127  memory: 4027  grad_norm: 3.3298  loss: 0.2052  decode.loss_ce: 0.1169  decode.acc_seg: 96.0723  aux.loss_ce: 0.0883  aux.acc_seg: 85.5926
2024/04/10 16:12:07 - mmengine - INFO - Iter(train) [ 3300/20000]  lr: 5.0000e-04  eta: 2:17:28  time: 0.4928  data_time: 0.0147  memory: 4027  grad_norm: 3.9246  loss: 0.2775  decode.loss_ce: 0.1717  decode.acc_seg: 93.4346  aux.loss_ce: 0.1058  aux.acc_seg: 89.1783
2024/04/10 16:12:56 - mmengine - INFO - Iter(train) [ 3400/20000]  lr: 5.0000e-04  eta: 2:16:36  time: 0.4919  data_time: 0.0133  memory: 4027  grad_norm: 4.8358  loss: 0.2441  decode.loss_ce: 0.1446  decode.acc_seg: 95.9655  aux.loss_ce: 0.0995  aux.acc_seg: 94.2119
2024/04/10 16:13:45 - mmengine - INFO - Iter(train) [ 3500/20000]  lr: 5.0000e-04  eta: 2:15:45  time: 0.4883  data_time: 0.0127  memory: 4026  grad_norm: 5.8471  loss: 0.2177  decode.loss_ce: 0.1294  decode.acc_seg: 94.6738  aux.loss_ce: 0.0882  aux.acc_seg: 87.2330
2024/04/10 16:13:45 - mmengine - INFO - per class results:
2024/04/10 16:13:45 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 75.06 | 80.39 | 85.75 | 85.75  |   91.88   | 80.39  |
| monolayer  | 50.18 | 77.26 | 66.83 | 66.83  |   58.88   | 77.26  |
|  bilayer   | 18.02 | 18.26 | 30.54 | 30.54  |   93.25   | 18.26  |
| multilayer | 64.68 | 93.14 | 78.56 | 78.56  |   67.92   | 93.14  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:13:45 - mmengine - INFO - Iter(val) [15/15]    aAcc: 77.4700  mIoU: 51.9900  mAcc: 67.2600  mDice: 65.4200  mFscore: 65.4200  mPrecision: 77.9800  mRecall: 67.2600  data_time: 0.0058  time: 0.0434
2024/04/10 16:14:34 - mmengine - INFO - Iter(train) [ 3600/20000]  lr: 5.0000e-04  eta: 2:14:54  time: 0.4942  data_time: 0.0148  memory: 4027  grad_norm: 11.7428  loss: 0.2665  decode.loss_ce: 0.1697  decode.acc_seg: 87.9352  aux.loss_ce: 0.0967  aux.acc_seg: 82.5644
2024/04/10 16:15:23 - mmengine - INFO - Iter(train) [ 3700/20000]  lr: 5.0000e-04  eta: 2:14:02  time: 0.4909  data_time: 0.0132  memory: 4027  grad_norm: 6.7432  loss: 0.2599  decode.loss_ce: 0.1713  decode.acc_seg: 95.1480  aux.loss_ce: 0.0886  aux.acc_seg: 94.8702
2024/04/10 16:16:12 - mmengine - INFO - Iter(train) [ 3800/20000]  lr: 5.0000e-04  eta: 2:13:11  time: 0.4874  data_time: 0.0123  memory: 4027  grad_norm: 1.8235  loss: 0.1457  decode.loss_ce: 0.0885  decode.acc_seg: 96.3706  aux.loss_ce: 0.0572  aux.acc_seg: 93.5356
2024/04/10 16:17:01 - mmengine - INFO - Iter(train) [ 3900/20000]  lr: 5.0000e-04  eta: 2:12:21  time: 0.4928  data_time: 0.0147  memory: 4027  grad_norm: 3.0642  loss: 0.1685  decode.loss_ce: 0.1009  decode.acc_seg: 94.5676  aux.loss_ce: 0.0676  aux.acc_seg: 92.8788
2024/04/10 16:17:50 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:17:50 - mmengine - INFO - Iter(train) [ 4000/20000]  lr: 5.0000e-04  eta: 2:11:30  time: 0.4897  data_time: 0.0134  memory: 4027  grad_norm: 3.7254  loss: 0.1882  decode.loss_ce: 0.1239  decode.acc_seg: 96.0905  aux.loss_ce: 0.0643  aux.acc_seg: 95.3814
2024/04/10 16:17:51 - mmengine - INFO - per class results:
2024/04/10 16:17:51 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background |  84.8 | 97.27 | 91.78 | 91.78  |   86.87   | 97.27  |
| monolayer  | 50.52 | 60.34 | 67.12 | 67.12  |   75.62   | 60.34  |
|  bilayer   | 13.61 | 13.73 | 23.96 | 23.96  |   93.98   | 13.73  |
| multilayer | 68.19 | 93.57 | 81.08 | 81.08  |   71.54   | 93.57  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:17:51 - mmengine - INFO - Iter(val) [15/15]    aAcc: 82.7900  mIoU: 54.2800  mAcc: 66.2300  mDice: 65.9800  mFscore: 65.9800  mPrecision: 82.0000  mRecall: 66.2300  data_time: 0.0063  time: 0.0438
2024/04/10 16:18:40 - mmengine - INFO - Iter(train) [ 4100/20000]  lr: 5.0000e-04  eta: 2:10:39  time: 0.4887  data_time: 0.0126  memory: 4027  grad_norm: 2.6671  loss: 0.1684  decode.loss_ce: 0.1017  decode.acc_seg: 96.9093  aux.loss_ce: 0.0667  aux.acc_seg: 94.0231
2024/04/10 16:19:29 - mmengine - INFO - Iter(train) [ 4200/20000]  lr: 5.0000e-04  eta: 2:09:48  time: 0.4912  data_time: 0.0135  memory: 4027  grad_norm: 9.0884  loss: 0.3658  decode.loss_ce: 0.2462  decode.acc_seg: 94.1777  aux.loss_ce: 0.1195  aux.acc_seg: 91.3450
2024/04/10 16:20:18 - mmengine - INFO - Iter(train) [ 4300/20000]  lr: 5.0000e-04  eta: 2:08:57  time: 0.4878  data_time: 0.0125  memory: 4027  grad_norm: 4.0015  loss: 0.2604  decode.loss_ce: 0.1744  decode.acc_seg: 95.2646  aux.loss_ce: 0.0860  aux.acc_seg: 91.6917
2024/04/10 16:21:06 - mmengine - INFO - Iter(train) [ 4400/20000]  lr: 5.0000e-04  eta: 2:08:06  time: 0.4873  data_time: 0.0127  memory: 4027  grad_norm: 5.8155  loss: 0.2088  decode.loss_ce: 0.1362  decode.acc_seg: 88.7486  aux.loss_ce: 0.0726  aux.acc_seg: 96.5088
2024/04/10 16:21:55 - mmengine - INFO - Iter(train) [ 4500/20000]  lr: 5.0000e-04  eta: 2:07:16  time: 0.4857  data_time: 0.0125  memory: 4027  grad_norm: 3.4663  loss: 0.1965  decode.loss_ce: 0.1180  decode.acc_seg: 97.1385  aux.loss_ce: 0.0785  aux.acc_seg: 93.4038
2024/04/10 16:21:56 - mmengine - INFO - per class results:
2024/04/10 16:21:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 64.21 | 87.35 | 78.21 | 78.21  |   70.79   | 87.35  |
| monolayer  |  5.06 |  5.48 |  9.63 |  9.63  |   39.74   |  5.48  |
|  bilayer   |  0.28 |  0.32 |  0.56 |  0.56  |    2.35   |  0.32  |
| multilayer |  37.2 | 96.85 | 54.23 | 54.23  |   37.66   | 96.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:21:56 - mmengine - INFO - Iter(val) [15/15]    aAcc: 61.8100  mIoU: 26.6900  mAcc: 47.5000  mDice: 35.6600  mFscore: 35.6600  mPrecision: 37.6400  mRecall: 47.5000  data_time: 0.0056  time: 0.0433
2024/04/10 16:22:45 - mmengine - INFO - Iter(train) [ 4600/20000]  lr: 5.0000e-04  eta: 2:06:25  time: 0.4937  data_time: 0.0146  memory: 4026  grad_norm: 6.2681  loss: 0.1832  decode.loss_ce: 0.1168  decode.acc_seg: 96.7530  aux.loss_ce: 0.0664  aux.acc_seg: 95.1693
2024/04/10 16:23:34 - mmengine - INFO - Iter(train) [ 4700/20000]  lr: 5.0000e-04  eta: 2:05:35  time: 0.4909  data_time: 0.0131  memory: 4027  grad_norm: 13.2002  loss: 0.2329  decode.loss_ce: 0.1473  decode.acc_seg: 96.0221  aux.loss_ce: 0.0855  aux.acc_seg: 94.1023
2024/04/10 16:24:23 - mmengine - INFO - Iter(train) [ 4800/20000]  lr: 5.0000e-04  eta: 2:04:45  time: 0.4922  data_time: 0.0145  memory: 4026  grad_norm: 1.6246  loss: 0.1301  decode.loss_ce: 0.0838  decode.acc_seg: 95.8116  aux.loss_ce: 0.0462  aux.acc_seg: 96.1366
2024/04/10 16:25:12 - mmengine - INFO - Iter(train) [ 4900/20000]  lr: 5.0000e-04  eta: 2:03:55  time: 0.4883  data_time: 0.0126  memory: 4027  grad_norm: 2.8510  loss: 0.1949  decode.loss_ce: 0.1296  decode.acc_seg: 98.2549  aux.loss_ce: 0.0653  aux.acc_seg: 98.2697
2024/04/10 16:26:01 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:26:01 - mmengine - INFO - Iter(train) [ 5000/20000]  lr: 5.0000e-04  eta: 2:03:05  time: 0.4890  data_time: 0.0132  memory: 4027  grad_norm: 5.3552  loss: 0.1611  decode.loss_ce: 0.0982  decode.acc_seg: 90.6706  aux.loss_ce: 0.0628  aux.acc_seg: 90.7695
2024/04/10 16:26:01 - mmengine - INFO - Saving checkpoint at 5000 iterations
2024/04/10 16:26:03 - mmengine - INFO - per class results:
2024/04/10 16:26:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 48.24 | 58.41 | 65.08 | 65.08  |   73.47   | 58.41  |
| monolayer  |  18.6 | 35.48 | 31.36 | 31.36  |    28.1   | 35.48  |
|  bilayer   |  0.0  |  0.0  |  0.01 |  0.01  |    0.2    |  0.0   |
| multilayer |  43.7 | 96.64 | 60.82 | 60.82  |   44.37   | 96.64  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:26:03 - mmengine - INFO - Iter(val) [15/15]    aAcc: 52.5900  mIoU: 27.6300  mAcc: 47.6300  mDice: 39.3200  mFscore: 39.3200  mPrecision: 36.5300  mRecall: 47.6300  data_time: 0.0047  time: 0.0423
2024/04/10 16:26:51 - mmengine - INFO - Iter(train) [ 5100/20000]  lr: 5.0000e-04  eta: 2:02:15  time: 0.4884  data_time: 0.0125  memory: 4027  grad_norm: 1.5939  loss: 0.1414  decode.loss_ce: 0.0887  decode.acc_seg: 96.2847  aux.loss_ce: 0.0527  aux.acc_seg: 96.3867
2024/04/10 16:27:40 - mmengine - INFO - Iter(train) [ 5200/20000]  lr: 5.0000e-04  eta: 2:01:25  time: 0.4942  data_time: 0.0144  memory: 4027  grad_norm: 1.4499  loss: 0.1435  decode.loss_ce: 0.0868  decode.acc_seg: 96.1747  aux.loss_ce: 0.0567  aux.acc_seg: 92.2371
2024/04/10 16:28:29 - mmengine - INFO - Iter(train) [ 5300/20000]  lr: 5.0000e-04  eta: 2:00:35  time: 0.4857  data_time: 0.0119  memory: 4027  grad_norm: 13.4323  loss: 0.2840  decode.loss_ce: 0.1988  decode.acc_seg: 96.5597  aux.loss_ce: 0.0852  aux.acc_seg: 93.7108
2024/04/10 16:29:18 - mmengine - INFO - Iter(train) [ 5400/20000]  lr: 5.0000e-04  eta: 1:59:45  time: 0.4932  data_time: 0.0137  memory: 4027  grad_norm: 2.7974  loss: 0.1605  decode.loss_ce: 0.0984  decode.acc_seg: 97.3914  aux.loss_ce: 0.0621  aux.acc_seg: 95.9222
2024/04/10 16:30:07 - mmengine - INFO - Iter(train) [ 5500/20000]  lr: 5.0000e-04  eta: 1:58:55  time: 0.4842  data_time: 0.0116  memory: 4026  grad_norm: 10.2679  loss: 0.1846  decode.loss_ce: 0.1102  decode.acc_seg: 96.0559  aux.loss_ce: 0.0743  aux.acc_seg: 89.8769
2024/04/10 16:30:08 - mmengine - INFO - per class results:
2024/04/10 16:30:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 74.14 |  97.8 | 85.15 | 85.15  |   75.39   |  97.8  |
| monolayer  |  19.1 | 20.03 | 32.07 | 32.07  |   80.36   | 20.03  |
|  bilayer   |  1.04 |  1.04 |  2.05 |  2.05  |   66.71   |  1.04  |
| multilayer | 51.77 | 97.64 | 68.23 | 68.23  |   52.43   | 97.64  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:30:08 - mmengine - INFO - Iter(val) [15/15]    aAcc: 72.0200  mIoU: 36.5100  mAcc: 54.1300  mDice: 46.8700  mFscore: 46.8700  mPrecision: 68.7200  mRecall: 54.1300  data_time: 0.0069  time: 0.0449
2024/04/10 16:30:57 - mmengine - INFO - Iter(train) [ 5600/20000]  lr: 5.0000e-04  eta: 1:58:05  time: 0.4885  data_time: 0.0128  memory: 4026  grad_norm: 6.8369  loss: 0.1893  decode.loss_ce: 0.1196  decode.acc_seg: 95.5169  aux.loss_ce: 0.0697  aux.acc_seg: 96.1996
2024/04/10 16:31:46 - mmengine - INFO - Iter(train) [ 5700/20000]  lr: 5.0000e-04  eta: 1:57:16  time: 0.4860  data_time: 0.0119  memory: 4027  grad_norm: 4.0599  loss: 0.1607  decode.loss_ce: 0.1023  decode.acc_seg: 92.5509  aux.loss_ce: 0.0583  aux.acc_seg: 88.3658
2024/04/10 16:32:35 - mmengine - INFO - Iter(train) [ 5800/20000]  lr: 5.0000e-04  eta: 1:56:26  time: 0.4850  data_time: 0.0113  memory: 4027  grad_norm: 5.8873  loss: 0.1638  decode.loss_ce: 0.0937  decode.acc_seg: 97.1859  aux.loss_ce: 0.0701  aux.acc_seg: 93.4690
2024/04/10 16:33:24 - mmengine - INFO - Iter(train) [ 5900/20000]  lr: 5.0000e-04  eta: 1:55:36  time: 0.4908  data_time: 0.0136  memory: 4026  grad_norm: 2.0138  loss: 0.1650  decode.loss_ce: 0.1019  decode.acc_seg: 98.1809  aux.loss_ce: 0.0631  aux.acc_seg: 97.8954
2024/04/10 16:34:13 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:34:13 - mmengine - INFO - Iter(train) [ 6000/20000]  lr: 5.0000e-04  eta: 1:54:47  time: 0.4912  data_time: 0.0139  memory: 4026  grad_norm: 1.7724  loss: 0.1626  decode.loss_ce: 0.1040  decode.acc_seg: 96.3627  aux.loss_ce: 0.0586  aux.acc_seg: 95.9822
2024/04/10 16:34:14 - mmengine - INFO - per class results:
2024/04/10 16:34:14 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 56.73 | 70.31 | 72.39 | 72.39  |   74.61   | 70.31  |
| monolayer  | 18.86 | 21.64 | 31.73 | 31.73  |   59.47   | 21.64  |
|  bilayer   |  2.94 |  5.54 |  5.7  |  5.7   |    5.88   |  5.54  |
| multilayer |  26.8 | 93.01 | 42.27 | 42.27  |   27.35   | 93.01  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:34:14 - mmengine - INFO - Iter(val) [15/15]    aAcc: 55.9300  mIoU: 26.3300  mAcc: 47.6200  mDice: 38.0200  mFscore: 38.0200  mPrecision: 41.8200  mRecall: 47.6200  data_time: 0.0050  time: 0.0427
2024/04/10 16:35:02 - mmengine - INFO - Iter(train) [ 6100/20000]  lr: 5.0000e-04  eta: 1:53:57  time: 0.4856  data_time: 0.0117  memory: 4027  grad_norm: 6.9624  loss: 0.2216  decode.loss_ce: 0.1572  decode.acc_seg: 97.0275  aux.loss_ce: 0.0644  aux.acc_seg: 96.5134
2024/04/10 16:35:51 - mmengine - INFO - Iter(train) [ 6200/20000]  lr: 5.0000e-04  eta: 1:53:07  time: 0.4858  data_time: 0.0124  memory: 4027  grad_norm: 1.1041  loss: 0.1198  decode.loss_ce: 0.0764  decode.acc_seg: 97.8604  aux.loss_ce: 0.0434  aux.acc_seg: 97.2216
2024/04/10 16:36:40 - mmengine - INFO - Iter(train) [ 6300/20000]  lr: 5.0000e-04  eta: 1:52:18  time: 0.4901  data_time: 0.0132  memory: 4027  grad_norm: 2.2322  loss: 0.1952  decode.loss_ce: 0.1208  decode.acc_seg: 97.1422  aux.loss_ce: 0.0744  aux.acc_seg: 96.3584
2024/04/10 16:37:29 - mmengine - INFO - Iter(train) [ 6400/20000]  lr: 5.0000e-04  eta: 1:51:28  time: 0.4878  data_time: 0.0127  memory: 4026  grad_norm: 2.5375  loss: 0.1548  decode.loss_ce: 0.1007  decode.acc_seg: 91.3038  aux.loss_ce: 0.0541  aux.acc_seg: 90.7844
2024/04/10 16:38:19 - mmengine - INFO - Iter(train) [ 6500/20000]  lr: 5.0000e-04  eta: 1:50:38  time: 0.4936  data_time: 0.0144  memory: 4026  grad_norm: 3.7678  loss: 0.1891  decode.loss_ce: 0.1270  decode.acc_seg: 92.0221  aux.loss_ce: 0.0621  aux.acc_seg: 88.5288
2024/04/10 16:38:19 - mmengine - INFO - per class results:
2024/04/10 16:38:19 - mmengine - INFO - 
+------------+------+-------+-------+--------+-----------+--------+
|   Class    | IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+------+-------+-------+--------+-----------+--------+
| Background | 1.15 |  1.16 |  2.28 |  2.28  |   85.51   |  1.16  |
| monolayer  | 0.11 |  0.11 |  0.22 |  0.22  |   14.74   |  0.11  |
|  bilayer   | 0.0  |  0.0  |  0.0  |  nan   |    0.0    |  0.0   |
| multilayer | 8.73 | 100.0 | 16.06 | 16.06  |    8.73   | 100.0  |
+------------+------+-------+-------+--------+-----------+--------+
2024/04/10 16:38:19 - mmengine - INFO - Iter(val) [15/15]    aAcc: 9.3500  mIoU: 2.5000  mAcc: 25.3200  mDice: 4.6400  mFscore: 6.1800  mPrecision: 27.2500  mRecall: 25.3200  data_time: 0.0063  time: 0.0443
2024/04/10 16:39:08 - mmengine - INFO - Iter(train) [ 6600/20000]  lr: 5.0000e-04  eta: 1:49:49  time: 0.4863  data_time: 0.0120  memory: 4027  grad_norm: 1.1738  loss: 0.1012  decode.loss_ce: 0.0644  decode.acc_seg: 96.9628  aux.loss_ce: 0.0368  aux.acc_seg: 95.8507
2024/04/10 16:39:57 - mmengine - INFO - Iter(train) [ 6700/20000]  lr: 5.0000e-04  eta: 1:48:59  time: 0.4924  data_time: 0.0145  memory: 4027  grad_norm: 2.5055  loss: 0.1553  decode.loss_ce: 0.1012  decode.acc_seg: 79.3191  aux.loss_ce: 0.0542  aux.acc_seg: 78.4331
2024/04/10 16:40:46 - mmengine - INFO - Iter(train) [ 6800/20000]  lr: 5.0000e-04  eta: 1:48:10  time: 0.4892  data_time: 0.0128  memory: 4026  grad_norm: 1.1190  loss: 0.1004  decode.loss_ce: 0.0607  decode.acc_seg: 97.1682  aux.loss_ce: 0.0398  aux.acc_seg: 94.5606
2024/04/10 16:41:35 - mmengine - INFO - Iter(train) [ 6900/20000]  lr: 5.0000e-04  eta: 1:47:21  time: 0.4938  data_time: 0.0144  memory: 4027  grad_norm: 3.5605  loss: 0.1474  decode.loss_ce: 0.0883  decode.acc_seg: 89.3577  aux.loss_ce: 0.0592  aux.acc_seg: 85.8253
2024/04/10 16:42:24 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:42:24 - mmengine - INFO - Iter(train) [ 7000/20000]  lr: 5.0000e-04  eta: 1:46:31  time: 0.4950  data_time: 0.0152  memory: 4027  grad_norm: 2.5023  loss: 0.1633  decode.loss_ce: 0.1047  decode.acc_seg: 97.2970  aux.loss_ce: 0.0587  aux.acc_seg: 95.7576
2024/04/10 16:42:25 - mmengine - INFO - per class results:
2024/04/10 16:42:25 - mmengine - INFO - 
+------------+------+-------+-------+--------+-----------+--------+
|   Class    | IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+------+-------+-------+--------+-----------+--------+
| Background | 0.92 |  0.92 |  1.83 |  1.83  |   88.03   |  0.92  |
| monolayer  | 1.12 |  1.13 |  2.22 |  2.22  |   95.31   |  1.13  |
|  bilayer   | 0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer | 8.7  | 99.79 | 16.01 | 16.01  |    8.7    | 99.79  |
+------------+------+-------+-------+--------+-----------+--------+
2024/04/10 16:42:25 - mmengine - INFO - Iter(val) [15/15]    aAcc: 9.4700  mIoU: 2.6900  mAcc: 25.4600  mDice: 5.0100  mFscore: 6.6900  mPrecision: 64.0100  mRecall: 25.4600  data_time: 0.0038  time: 0.0418
2024/04/10 16:43:14 - mmengine - INFO - Iter(train) [ 7100/20000]  lr: 5.0000e-04  eta: 1:45:42  time: 0.4884  data_time: 0.0117  memory: 4027  grad_norm: 2.5260  loss: 0.1284  decode.loss_ce: 0.0767  decode.acc_seg: 96.8179  aux.loss_ce: 0.0517  aux.acc_seg: 95.7763
2024/04/10 16:44:03 - mmengine - INFO - Iter(train) [ 7200/20000]  lr: 5.0000e-04  eta: 1:44:52  time: 0.4929  data_time: 0.0150  memory: 4027  grad_norm: 7.8277  loss: 0.1350  decode.loss_ce: 0.0841  decode.acc_seg: 92.1289  aux.loss_ce: 0.0509  aux.acc_seg: 90.2499
2024/04/10 16:44:52 - mmengine - INFO - Iter(train) [ 7300/20000]  lr: 5.0000e-04  eta: 1:44:03  time: 0.4914  data_time: 0.0142  memory: 4027  grad_norm: 4.7552  loss: 0.1716  decode.loss_ce: 0.1146  decode.acc_seg: 97.1538  aux.loss_ce: 0.0569  aux.acc_seg: 96.6345
2024/04/10 16:45:41 - mmengine - INFO - Iter(train) [ 7400/20000]  lr: 5.0000e-04  eta: 1:43:14  time: 0.4909  data_time: 0.0142  memory: 4027  grad_norm: 2.0559  loss: 0.1210  decode.loss_ce: 0.0692  decode.acc_seg: 97.4990  aux.loss_ce: 0.0518  aux.acc_seg: 96.4305
2024/04/10 16:46:30 - mmengine - INFO - Iter(train) [ 7500/20000]  lr: 5.0000e-04  eta: 1:42:25  time: 0.4917  data_time: 0.0145  memory: 4027  grad_norm: 1.8700  loss: 0.1202  decode.loss_ce: 0.0750  decode.acc_seg: 96.2843  aux.loss_ce: 0.0453  aux.acc_seg: 94.2533
2024/04/10 16:46:30 - mmengine - INFO - Saving checkpoint at 7500 iterations
2024/04/10 16:46:32 - mmengine - INFO - per class results:
2024/04/10 16:46:32 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 54.39 | 79.29 | 70.46 | 70.46  |   63.39   | 79.29  |
| monolayer  |  4.44 |  6.6  |  8.51 |  8.51  |   11.97   |  6.6   |
|  bilayer   |  0.18 |  0.19 |  0.37 |  0.37  |    5.91   |  0.19  |
| multilayer |  62.0 | 85.54 | 76.54 | 76.54  |   69.26   | 85.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:46:32 - mmengine - INFO - Iter(val) [15/15]    aAcc: 56.3300  mIoU: 30.2500  mAcc: 42.9100  mDice: 38.9700  mFscore: 38.9700  mPrecision: 37.6300  mRecall: 42.9100  data_time: 0.0048  time: 0.0424
2024/04/10 16:47:21 - mmengine - INFO - Iter(train) [ 7600/20000]  lr: 5.0000e-04  eta: 1:41:35  time: 0.4918  data_time: 0.0139  memory: 4027  grad_norm: 3.6349  loss: 0.1374  decode.loss_ce: 0.0821  decode.acc_seg: 97.6835  aux.loss_ce: 0.0552  aux.acc_seg: 94.5836
2024/04/10 16:48:10 - mmengine - INFO - Iter(train) [ 7700/20000]  lr: 5.0000e-04  eta: 1:40:46  time: 0.4885  data_time: 0.0132  memory: 4027  grad_norm: 1.3403  loss: 0.1300  decode.loss_ce: 0.0880  decode.acc_seg: 97.5478  aux.loss_ce: 0.0420  aux.acc_seg: 95.5728
2024/04/10 16:48:59 - mmengine - INFO - Iter(train) [ 7800/20000]  lr: 5.0000e-04  eta: 1:39:56  time: 0.4900  data_time: 0.0140  memory: 4026  grad_norm: 1.7058  loss: 0.1510  decode.loss_ce: 0.0947  decode.acc_seg: 97.8568  aux.loss_ce: 0.0564  aux.acc_seg: 96.8571
2024/04/10 16:49:48 - mmengine - INFO - Iter(train) [ 7900/20000]  lr: 5.0000e-04  eta: 1:39:07  time: 0.4894  data_time: 0.0134  memory: 4027  grad_norm: 2.3082  loss: 0.1464  decode.loss_ce: 0.0907  decode.acc_seg: 95.1790  aux.loss_ce: 0.0556  aux.acc_seg: 93.2958
2024/04/10 16:50:37 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:50:37 - mmengine - INFO - Iter(train) [ 8000/20000]  lr: 5.0000e-04  eta: 1:38:17  time: 0.4938  data_time: 0.0147  memory: 4027  grad_norm: 1.1775  loss: 0.1342  decode.loss_ce: 0.0893  decode.acc_seg: 93.0283  aux.loss_ce: 0.0449  aux.acc_seg: 92.0279
2024/04/10 16:50:37 - mmengine - INFO - per class results:
2024/04/10 16:50:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background |  84.9 | 92.85 | 91.84 | 91.84  |   90.84   | 92.85  |
| monolayer  | 69.45 | 83.98 | 81.97 | 81.97  |   80.06   | 83.98  |
|  bilayer   | 43.78 | 45.15 |  60.9 |  60.9  |   93.51   | 45.15  |
| multilayer | 84.41 | 91.67 | 91.54 | 91.54  |   91.42   | 91.67  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:50:37 - mmengine - INFO - Iter(val) [15/15]    aAcc: 87.9300  mIoU: 70.6300  mAcc: 78.4100  mDice: 81.5600  mFscore: 81.5600  mPrecision: 88.9600  mRecall: 78.4100  data_time: 0.0065  time: 0.0442
2024/04/10 16:50:37 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/fastvit-pspnet_ful/best_mIoU_iter_500.pth is removed
2024/04/10 16:50:38 - mmengine - INFO - The best checkpoint with 70.6300 mIoU at 8000 iter is saved to best_mIoU_iter_8000.pth.
2024/04/10 16:51:28 - mmengine - INFO - Iter(train) [ 8100/20000]  lr: 5.0000e-04  eta: 1:37:30  time: 0.4929  data_time: 0.0149  memory: 4027  grad_norm: 2.8663  loss: 0.1099  decode.loss_ce: 0.0664  decode.acc_seg: 97.5318  aux.loss_ce: 0.0435  aux.acc_seg: 96.5856
2024/04/10 16:52:17 - mmengine - INFO - Iter(train) [ 8200/20000]  lr: 5.0000e-04  eta: 1:36:41  time: 0.4907  data_time: 0.0134  memory: 4027  grad_norm: 3.8676  loss: 0.3445  decode.loss_ce: 0.2400  decode.acc_seg: 96.9246  aux.loss_ce: 0.1046  aux.acc_seg: 96.5742
2024/04/10 16:53:06 - mmengine - INFO - Iter(train) [ 8300/20000]  lr: 5.0000e-04  eta: 1:35:51  time: 0.4929  data_time: 0.0142  memory: 4027  grad_norm: 1.2840  loss: 0.1585  decode.loss_ce: 0.1019  decode.acc_seg: 98.2147  aux.loss_ce: 0.0566  aux.acc_seg: 97.2382
2024/04/10 16:53:55 - mmengine - INFO - Iter(train) [ 8400/20000]  lr: 5.0000e-04  eta: 1:35:02  time: 0.4877  data_time: 0.0126  memory: 4027  grad_norm: 1.3077  loss: 0.0926  decode.loss_ce: 0.0550  decode.acc_seg: 96.8143  aux.loss_ce: 0.0375  aux.acc_seg: 91.2489
2024/04/10 16:54:44 - mmengine - INFO - Iter(train) [ 8500/20000]  lr: 5.0000e-04  eta: 1:34:12  time: 0.4867  data_time: 0.0119  memory: 4027  grad_norm: 7.7190  loss: 0.2895  decode.loss_ce: 0.1872  decode.acc_seg: 97.9643  aux.loss_ce: 0.1023  aux.acc_seg: 96.3675
2024/04/10 16:54:44 - mmengine - INFO - per class results:
2024/04/10 16:54:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 65.83 | 79.59 |  79.4 |  79.4  |   79.21   | 79.59  |
| monolayer  |  2.59 |  2.83 |  5.04 |  5.04  |   22.91   |  2.83  |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer | 23.32 | 99.73 | 37.82 | 37.82  |   23.33   | 99.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:54:44 - mmengine - INFO - Iter(val) [15/15]    aAcc: 56.7200  mIoU: 22.9300  mAcc: 45.5400  mDice: 30.5600  mFscore: 40.7500  mPrecision: 41.8200  mRecall: 45.5400  data_time: 0.0039  time: 0.0415
2024/04/10 16:55:33 - mmengine - INFO - Iter(train) [ 8600/20000]  lr: 5.0000e-04  eta: 1:33:23  time: 0.4894  data_time: 0.0133  memory: 4027  grad_norm: 0.8504  loss: 0.1078  decode.loss_ce: 0.0653  decode.acc_seg: 97.3792  aux.loss_ce: 0.0425  aux.acc_seg: 96.2492
2024/04/10 16:56:22 - mmengine - INFO - Iter(train) [ 8700/20000]  lr: 5.0000e-04  eta: 1:32:33  time: 0.4896  data_time: 0.0129  memory: 4027  grad_norm: 1.3957  loss: 0.1506  decode.loss_ce: 0.0994  decode.acc_seg: 97.9799  aux.loss_ce: 0.0511  aux.acc_seg: 97.6417
2024/04/10 16:57:11 - mmengine - INFO - Iter(train) [ 8800/20000]  lr: 5.0000e-04  eta: 1:31:44  time: 0.4911  data_time: 0.0129  memory: 4027  grad_norm: 2.8146  loss: 0.1150  decode.loss_ce: 0.0679  decode.acc_seg: 97.9578  aux.loss_ce: 0.0471  aux.acc_seg: 95.3617
2024/04/10 16:58:00 - mmengine - INFO - Iter(train) [ 8900/20000]  lr: 5.0000e-04  eta: 1:30:54  time: 0.4895  data_time: 0.0126  memory: 4026  grad_norm: 1.7500  loss: 0.1383  decode.loss_ce: 0.0903  decode.acc_seg: 97.8282  aux.loss_ce: 0.0480  aux.acc_seg: 97.2737
2024/04/10 16:58:49 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 16:58:49 - mmengine - INFO - Iter(train) [ 9000/20000]  lr: 5.0000e-04  eta: 1:30:05  time: 0.4868  data_time: 0.0123  memory: 4027  grad_norm: 2.4188  loss: 0.1265  decode.loss_ce: 0.0750  decode.acc_seg: 97.1575  aux.loss_ce: 0.0516  aux.acc_seg: 90.6254
2024/04/10 16:58:49 - mmengine - INFO - per class results:
2024/04/10 16:58:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 85.71 | 97.78 | 92.31 | 92.31  |   87.41   | 97.78  |
| monolayer  | 55.26 | 58.22 | 71.19 | 71.19  |   91.57   | 58.22  |
|  bilayer   | 43.43 | 45.08 | 60.56 | 60.56  |   92.25   | 45.08  |
| multilayer |  56.9 | 94.82 | 72.53 | 72.53  |   58.73   | 94.82  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 16:58:49 - mmengine - INFO - Iter(val) [15/15]    aAcc: 84.2400  mIoU: 60.3300  mAcc: 73.9700  mDice: 74.1500  mFscore: 74.1500  mPrecision: 82.4900  mRecall: 73.9700  data_time: 0.0064  time: 0.0438
2024/04/10 16:59:38 - mmengine - INFO - Iter(train) [ 9100/20000]  lr: 5.0000e-04  eta: 1:29:16  time: 0.4876  data_time: 0.0123  memory: 4027  grad_norm: 10.9912  loss: 0.1954  decode.loss_ce: 0.1351  decode.acc_seg: 97.7867  aux.loss_ce: 0.0603  aux.acc_seg: 96.3699
2024/04/10 17:00:28 - mmengine - INFO - Iter(train) [ 9200/20000]  lr: 5.0000e-04  eta: 1:28:26  time: 0.4895  data_time: 0.0132  memory: 4027  grad_norm: 4.5288  loss: 0.1381  decode.loss_ce: 0.0999  decode.acc_seg: 98.3211  aux.loss_ce: 0.0382  aux.acc_seg: 97.6963
2024/04/10 17:01:16 - mmengine - INFO - Iter(train) [ 9300/20000]  lr: 5.0000e-04  eta: 1:27:37  time: 0.4867  data_time: 0.0124  memory: 4027  grad_norm: 1.3132  loss: 0.0822  decode.loss_ce: 0.0485  decode.acc_seg: 98.6413  aux.loss_ce: 0.0337  aux.acc_seg: 96.6050
2024/04/10 17:02:05 - mmengine - INFO - Iter(train) [ 9400/20000]  lr: 5.0000e-04  eta: 1:26:48  time: 0.4895  data_time: 0.0132  memory: 4027  grad_norm: 0.8775  loss: 0.0841  decode.loss_ce: 0.0525  decode.acc_seg: 98.7930  aux.loss_ce: 0.0316  aux.acc_seg: 98.5219
2024/04/10 17:02:54 - mmengine - INFO - Iter(train) [ 9500/20000]  lr: 5.0000e-04  eta: 1:25:58  time: 0.4886  data_time: 0.0143  memory: 4027  grad_norm: 0.8759  loss: 0.0739  decode.loss_ce: 0.0428  decode.acc_seg: 97.9463  aux.loss_ce: 0.0311  aux.acc_seg: 92.3996
2024/04/10 17:02:55 - mmengine - INFO - per class results:
2024/04/10 17:02:55 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background |  87.9 | 93.92 | 93.56 | 93.56  |    93.2   | 93.92  |
| monolayer  | 61.14 | 74.13 | 75.88 | 75.88  |   77.72   | 74.13  |
|  bilayer   | 29.02 | 40.11 | 44.99 | 44.99  |   51.22   | 40.11  |
| multilayer | 72.18 | 93.02 | 83.84 | 83.84  |   76.32   | 93.02  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:02:55 - mmengine - INFO - Iter(val) [15/15]    aAcc: 85.7900  mIoU: 62.5600  mAcc: 75.2900  mDice: 74.5700  mFscore: 74.5700  mPrecision: 74.6100  mRecall: 75.2900  data_time: 0.0053  time: 0.0429
2024/04/10 17:03:44 - mmengine - INFO - Iter(train) [ 9600/20000]  lr: 5.0000e-04  eta: 1:25:09  time: 0.4888  data_time: 0.0130  memory: 4027  grad_norm: 0.8857  loss: 0.1114  decode.loss_ce: 0.0719  decode.acc_seg: 98.9581  aux.loss_ce: 0.0394  aux.acc_seg: 98.5488
2024/04/10 17:04:33 - mmengine - INFO - Iter(train) [ 9700/20000]  lr: 5.0000e-04  eta: 1:24:20  time: 0.4906  data_time: 0.0145  memory: 4027  grad_norm: 2.8875  loss: 0.0976  decode.loss_ce: 0.0620  decode.acc_seg: 97.1981  aux.loss_ce: 0.0356  aux.acc_seg: 95.6366
2024/04/10 17:05:22 - mmengine - INFO - Iter(train) [ 9800/20000]  lr: 5.0000e-04  eta: 1:23:30  time: 0.4857  data_time: 0.0120  memory: 4027  grad_norm: 1.1151  loss: 0.0973  decode.loss_ce: 0.0622  decode.acc_seg: 98.3731  aux.loss_ce: 0.0351  aux.acc_seg: 98.0063
2024/04/10 17:06:11 - mmengine - INFO - Iter(train) [ 9900/20000]  lr: 5.0000e-04  eta: 1:22:41  time: 0.4915  data_time: 0.0134  memory: 4026  grad_norm: 14.4432  loss: 0.3483  decode.loss_ce: 0.2689  decode.acc_seg: 98.5002  aux.loss_ce: 0.0794  aux.acc_seg: 98.1838
2024/04/10 17:07:00 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 17:07:00 - mmengine - INFO - Iter(train) [10000/20000]  lr: 5.0000e-04  eta: 1:21:52  time: 0.4918  data_time: 0.0143  memory: 4027  grad_norm: 1.7270  loss: 0.1004  decode.loss_ce: 0.0623  decode.acc_seg: 97.5575  aux.loss_ce: 0.0382  aux.acc_seg: 96.3580
2024/04/10 17:07:00 - mmengine - INFO - Saving checkpoint at 10000 iterations
2024/04/10 17:07:01 - mmengine - INFO - per class results:
2024/04/10 17:07:01 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 68.46 | 95.26 | 81.28 | 81.28  |   70.88   | 95.26  |
| monolayer  | 12.67 | 13.79 | 22.49 | 22.49  |   60.85   | 13.79  |
|  bilayer   |  4.73 |  7.09 |  9.04 |  9.04  |   12.46   |  7.09  |
| multilayer | 65.33 | 90.15 | 79.03 | 79.03  |   70.35   | 90.15  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:07:01 - mmengine - INFO - Iter(val) [15/15]    aAcc: 68.5100  mIoU: 37.8000  mAcc: 51.5700  mDice: 47.9600  mFscore: 47.9600  mPrecision: 53.6400  mRecall: 51.5700  data_time: 0.0065  time: 0.0439
2024/04/10 17:07:50 - mmengine - INFO - Iter(train) [10100/20000]  lr: 5.0000e-04  eta: 1:21:02  time: 0.4870  data_time: 0.0119  memory: 4026  grad_norm: 1.3368  loss: 0.1122  decode.loss_ce: 0.0690  decode.acc_seg: 98.0235  aux.loss_ce: 0.0431  aux.acc_seg: 97.7968
2024/04/10 17:08:39 - mmengine - INFO - Iter(train) [10200/20000]  lr: 5.0000e-04  eta: 1:20:13  time: 0.4870  data_time: 0.0123  memory: 4027  grad_norm: 14.2608  loss: 0.2343  decode.loss_ce: 0.1544  decode.acc_seg: 97.0437  aux.loss_ce: 0.0799  aux.acc_seg: 92.3144
2024/04/10 17:09:28 - mmengine - INFO - Iter(train) [10300/20000]  lr: 5.0000e-04  eta: 1:19:24  time: 0.4945  data_time: 0.0161  memory: 4027  grad_norm: 1.2315  loss: 0.0867  decode.loss_ce: 0.0477  decode.acc_seg: 98.3448  aux.loss_ce: 0.0389  aux.acc_seg: 97.8102
2024/04/10 17:10:17 - mmengine - INFO - Iter(train) [10400/20000]  lr: 5.0000e-04  eta: 1:18:35  time: 0.4911  data_time: 0.0146  memory: 4027  grad_norm: 2.5284  loss: 0.1736  decode.loss_ce: 0.1121  decode.acc_seg: 96.7688  aux.loss_ce: 0.0615  aux.acc_seg: 91.9465
2024/04/10 17:11:06 - mmengine - INFO - Iter(train) [10500/20000]  lr: 5.0000e-04  eta: 1:17:45  time: 0.4887  data_time: 0.0131  memory: 4026  grad_norm: 4.8291  loss: 0.1230  decode.loss_ce: 0.0665  decode.acc_seg: 97.8394  aux.loss_ce: 0.0565  aux.acc_seg: 96.8210
2024/04/10 17:11:07 - mmengine - INFO - per class results:
2024/04/10 17:11:07 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 76.07 | 79.11 | 86.41 | 86.41  |   95.18   | 79.11  |
| monolayer  | 38.84 | 41.92 | 55.95 | 55.95  |   84.11   | 41.92  |
|  bilayer   |  0.89 |  0.89 |  1.76 |  1.76  |   99.97   |  0.89  |
| multilayer |  23.1 | 99.55 | 37.53 | 37.53  |   23.13   | 99.55  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:11:07 - mmengine - INFO - Iter(val) [15/15]    aAcc: 66.9200  mIoU: 34.7200  mAcc: 55.3600  mDice: 45.4100  mFscore: 45.4100  mPrecision: 75.6000  mRecall: 55.3600  data_time: 0.0069  time: 0.0444
2024/04/10 17:11:56 - mmengine - INFO - Iter(train) [10600/20000]  lr: 5.0000e-04  eta: 1:16:56  time: 0.4886  data_time: 0.0128  memory: 4027  grad_norm: 5.3725  loss: 0.1455  decode.loss_ce: 0.0876  decode.acc_seg: 98.3999  aux.loss_ce: 0.0580  aux.acc_seg: 96.9268
2024/04/10 17:12:45 - mmengine - INFO - Iter(train) [10700/20000]  lr: 5.0000e-04  eta: 1:16:07  time: 0.4903  data_time: 0.0125  memory: 4027  grad_norm: 6.3069  loss: 0.1239  decode.loss_ce: 0.0737  decode.acc_seg: 98.2752  aux.loss_ce: 0.0503  aux.acc_seg: 97.7094
2024/04/10 17:13:34 - mmengine - INFO - Iter(train) [10800/20000]  lr: 5.0000e-04  eta: 1:15:18  time: 0.4914  data_time: 0.0145  memory: 4027  grad_norm: 1.5028  loss: 0.0920  decode.loss_ce: 0.0564  decode.acc_seg: 97.9768  aux.loss_ce: 0.0357  aux.acc_seg: 96.8469
2024/04/10 17:14:23 - mmengine - INFO - Iter(train) [10900/20000]  lr: 5.0000e-04  eta: 1:14:28  time: 0.4908  data_time: 0.0131  memory: 4027  grad_norm: 2.4643  loss: 0.1388  decode.loss_ce: 0.0871  decode.acc_seg: 97.9197  aux.loss_ce: 0.0517  aux.acc_seg: 96.8475
2024/04/10 17:15:12 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 17:15:12 - mmengine - INFO - Iter(train) [11000/20000]  lr: 5.0000e-04  eta: 1:13:39  time: 0.4867  data_time: 0.0128  memory: 4027  grad_norm: 1.2057  loss: 0.0791  decode.loss_ce: 0.0454  decode.acc_seg: 98.1114  aux.loss_ce: 0.0337  aux.acc_seg: 97.7556
2024/04/10 17:15:12 - mmengine - INFO - per class results:
2024/04/10 17:15:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 84.87 | 94.52 | 91.82 | 91.82  |   89.26   | 94.52  |
| monolayer  |  6.59 |  6.65 | 12.37 | 12.37  |   88.76   |  6.65  |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer | 24.31 | 98.81 | 39.11 | 39.11  |   24.38   | 98.81  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:15:12 - mmengine - INFO - Iter(val) [15/15]    aAcc: 66.5400  mIoU: 28.9400  mAcc: 50.0000  mDice: 35.8300  mFscore: 47.7700  mPrecision: 67.4700  mRecall: 50.0000  data_time: 0.0069  time: 0.0444
2024/04/10 17:16:01 - mmengine - INFO - Iter(train) [11100/20000]  lr: 5.0000e-04  eta: 1:12:50  time: 0.4891  data_time: 0.0132  memory: 4027  grad_norm: 2.1217  loss: 0.1226  decode.loss_ce: 0.0699  decode.acc_seg: 98.2433  aux.loss_ce: 0.0528  aux.acc_seg: 96.9067
2024/04/10 17:16:50 - mmengine - INFO - Iter(train) [11200/20000]  lr: 5.0000e-04  eta: 1:12:01  time: 0.4887  data_time: 0.0133  memory: 4027  grad_norm: 1.3796  loss: 0.1351  decode.loss_ce: 0.0865  decode.acc_seg: 98.3499  aux.loss_ce: 0.0486  aux.acc_seg: 96.8494
2024/04/10 17:17:39 - mmengine - INFO - Iter(train) [11300/20000]  lr: 5.0000e-04  eta: 1:11:12  time: 0.4883  data_time: 0.0134  memory: 4027  grad_norm: 0.6494  loss: 0.0828  decode.loss_ce: 0.0546  decode.acc_seg: 98.4701  aux.loss_ce: 0.0282  aux.acc_seg: 98.1554
2024/04/10 17:18:28 - mmengine - INFO - Iter(train) [11400/20000]  lr: 5.0000e-04  eta: 1:10:22  time: 0.4974  data_time: 0.0150  memory: 4027  grad_norm: 1.9820  loss: 0.1201  decode.loss_ce: 0.0771  decode.acc_seg: 95.3297  aux.loss_ce: 0.0430  aux.acc_seg: 92.5754
2024/04/10 17:19:17 - mmengine - INFO - Iter(train) [11500/20000]  lr: 5.0000e-04  eta: 1:09:33  time: 0.4893  data_time: 0.0134  memory: 4027  grad_norm: 0.7689  loss: 0.0708  decode.loss_ce: 0.0449  decode.acc_seg: 96.9655  aux.loss_ce: 0.0259  aux.acc_seg: 96.0545
2024/04/10 17:19:18 - mmengine - INFO - per class results:
2024/04/10 17:19:18 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 60.83 | 63.73 | 75.65 | 75.65  |   93.06   | 63.73  |
| monolayer  | 10.54 | 10.75 | 19.07 | 19.07  |   83.96   | 10.75  |
|  bilayer   |  0.82 |  0.82 |  1.63 |  1.63  |   65.59   |  0.82  |
| multilayer | 15.41 | 99.58 | 26.71 | 26.71  |   15.42   | 99.58  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:19:18 - mmengine - INFO - Iter(val) [15/15]    aAcc: 49.4300  mIoU: 21.9000  mAcc: 43.7200  mDice: 30.7600  mFscore: 30.7600  mPrecision: 64.5100  mRecall: 43.7200  data_time: 0.0065  time: 0.0438
2024/04/10 17:20:07 - mmengine - INFO - Iter(train) [11600/20000]  lr: 5.0000e-04  eta: 1:08:44  time: 0.4884  data_time: 0.0128  memory: 4027  grad_norm: 5.7354  loss: 0.1666  decode.loss_ce: 0.1117  decode.acc_seg: 95.1297  aux.loss_ce: 0.0549  aux.acc_seg: 92.4538
2024/04/10 17:20:56 - mmengine - INFO - Iter(train) [11700/20000]  lr: 5.0000e-04  eta: 1:07:55  time: 0.4907  data_time: 0.0136  memory: 4027  grad_norm: 9.3477  loss: 0.2257  decode.loss_ce: 0.1426  decode.acc_seg: 94.1826  aux.loss_ce: 0.0831  aux.acc_seg: 94.2264
2024/04/10 17:21:45 - mmengine - INFO - Iter(train) [11800/20000]  lr: 5.0000e-04  eta: 1:07:06  time: 0.4869  data_time: 0.0131  memory: 4027  grad_norm: 2.9522  loss: 0.1334  decode.loss_ce: 0.0827  decode.acc_seg: 98.4841  aux.loss_ce: 0.0506  aux.acc_seg: 97.8690
2024/04/10 17:22:34 - mmengine - INFO - Iter(train) [11900/20000]  lr: 5.0000e-04  eta: 1:06:16  time: 0.4847  data_time: 0.0118  memory: 4027  grad_norm: 0.6457  loss: 0.0721  decode.loss_ce: 0.0441  decode.acc_seg: 98.0135  aux.loss_ce: 0.0280  aux.acc_seg: 97.4613
2024/04/10 17:23:22 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 17:23:22 - mmengine - INFO - Iter(train) [12000/20000]  lr: 5.0000e-04  eta: 1:05:27  time: 0.4843  data_time: 0.0116  memory: 4027  grad_norm: 0.5926  loss: 0.0775  decode.loss_ce: 0.0478  decode.acc_seg: 95.8914  aux.loss_ce: 0.0297  aux.acc_seg: 95.2470
2024/04/10 17:23:23 - mmengine - INFO - per class results:
2024/04/10 17:23:23 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 93.66 | 96.72 | 96.73 | 96.73  |   96.74   | 96.72  |
| monolayer  | 78.56 | 89.79 | 87.99 | 87.99  |   86.27   | 89.79  |
|  bilayer   | 52.14 | 59.61 | 68.54 | 68.54  |   80.62   | 59.61  |
| multilayer | 85.47 | 93.54 | 92.17 | 92.17  |   90.83   | 93.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:23:23 - mmengine - INFO - Iter(val) [15/15]    aAcc: 92.6900  mIoU: 77.4600  mAcc: 84.9100  mDice: 86.3600  mFscore: 86.3600  mPrecision: 88.6100  mRecall: 84.9100  data_time: 0.0059  time: 0.0435
2024/04/10 17:23:23 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/fastvit-pspnet_ful/best_mIoU_iter_8000.pth is removed
2024/04/10 17:23:24 - mmengine - INFO - The best checkpoint with 77.4600 mIoU at 12000 iter is saved to best_mIoU_iter_12000.pth.
2024/04/10 17:24:13 - mmengine - INFO - Iter(train) [12100/20000]  lr: 5.0000e-04  eta: 1:04:39  time: 0.4887  data_time: 0.0127  memory: 4027  grad_norm: 2.9147  loss: 0.1026  decode.loss_ce: 0.0620  decode.acc_seg: 98.2298  aux.loss_ce: 0.0406  aux.acc_seg: 97.9175
2024/04/10 17:25:02 - mmengine - INFO - Iter(train) [12200/20000]  lr: 5.0000e-04  eta: 1:03:50  time: 0.4878  data_time: 0.0127  memory: 4027  grad_norm: 1.1634  loss: 0.1247  decode.loss_ce: 0.0857  decode.acc_seg: 97.9908  aux.loss_ce: 0.0391  aux.acc_seg: 96.8644
2024/04/10 17:25:51 - mmengine - INFO - Iter(train) [12300/20000]  lr: 5.0000e-04  eta: 1:03:00  time: 0.4891  data_time: 0.0130  memory: 4027  grad_norm: 0.6383  loss: 0.0844  decode.loss_ce: 0.0532  decode.acc_seg: 98.7475  aux.loss_ce: 0.0312  aux.acc_seg: 97.9998
2024/04/10 17:26:40 - mmengine - INFO - Iter(train) [12400/20000]  lr: 5.0000e-04  eta: 1:02:11  time: 0.4905  data_time: 0.0128  memory: 4027  grad_norm: 1.4373  loss: 0.1218  decode.loss_ce: 0.0729  decode.acc_seg: 96.7971  aux.loss_ce: 0.0490  aux.acc_seg: 95.9805
2024/04/10 17:27:29 - mmengine - INFO - Iter(train) [12500/20000]  lr: 5.0000e-04  eta: 1:01:22  time: 0.4910  data_time: 0.0144  memory: 4027  grad_norm: 1.2976  loss: 0.1017  decode.loss_ce: 0.0610  decode.acc_seg: 98.3268  aux.loss_ce: 0.0407  aux.acc_seg: 95.4955
2024/04/10 17:27:29 - mmengine - INFO - Saving checkpoint at 12500 iterations
2024/04/10 17:27:31 - mmengine - INFO - per class results:
2024/04/10 17:27:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 11.26 | 11.58 | 20.24 | 20.24  |    80.5   | 11.58  |
| monolayer  |  1.76 |  1.78 |  3.45 |  3.45  |   55.82   |  1.78  |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    0.0    |  0.0   |
| multilayer |  9.39 | 98.54 | 17.16 | 17.16  |    9.4    | 98.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:27:31 - mmengine - INFO - Iter(val) [15/15]    aAcc: 15.8800  mIoU: 5.6000  mAcc: 27.9700  mDice: 10.2200  mFscore: 13.6200  mPrecision: 36.4300  mRecall: 27.9700  data_time: 0.0049  time: 0.0425
2024/04/10 17:28:20 - mmengine - INFO - Iter(train) [12600/20000]  lr: 5.0000e-04  eta: 1:00:33  time: 0.4895  data_time: 0.0133  memory: 4026  grad_norm: 0.7351  loss: 0.0928  decode.loss_ce: 0.0587  decode.acc_seg: 97.9181  aux.loss_ce: 0.0341  aux.acc_seg: 96.2265
2024/04/10 17:29:09 - mmengine - INFO - Iter(train) [12700/20000]  lr: 5.0000e-04  eta: 0:59:44  time: 0.4855  data_time: 0.0124  memory: 4027  grad_norm: 3.8564  loss: 0.1133  decode.loss_ce: 0.0697  decode.acc_seg: 98.6385  aux.loss_ce: 0.0436  aux.acc_seg: 95.0273
2024/04/10 17:29:58 - mmengine - INFO - Iter(train) [12800/20000]  lr: 5.0000e-04  eta: 0:58:55  time: 0.4870  data_time: 0.0121  memory: 4026  grad_norm: 1.0813  loss: 0.0917  decode.loss_ce: 0.0553  decode.acc_seg: 98.7417  aux.loss_ce: 0.0364  aux.acc_seg: 97.1871
2024/04/10 17:30:47 - mmengine - INFO - Iter(train) [12900/20000]  lr: 5.0000e-04  eta: 0:58:05  time: 0.4875  data_time: 0.0130  memory: 4027  grad_norm: 0.7162  loss: 0.0673  decode.loss_ce: 0.0426  decode.acc_seg: 97.9269  aux.loss_ce: 0.0247  aux.acc_seg: 96.9639
2024/04/10 17:31:36 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 17:31:36 - mmengine - INFO - Iter(train) [13000/20000]  lr: 5.0000e-04  eta: 0:57:16  time: 0.4975  data_time: 0.0164  memory: 4027  grad_norm: 6.6538  loss: 0.1011  decode.loss_ce: 0.0618  decode.acc_seg: 98.5261  aux.loss_ce: 0.0393  aux.acc_seg: 98.0336
2024/04/10 17:31:36 - mmengine - INFO - per class results:
2024/04/10 17:31:36 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 33.85 | 35.02 | 50.58 | 50.58  |   90.99   | 35.02  |
| monolayer  | 26.96 | 30.08 | 42.47 | 42.47  |   72.19   | 30.08  |
|  bilayer   |  8.98 | 26.48 | 16.48 | 16.48  |   11.96   | 26.48  |
| multilayer | 14.64 | 93.51 | 25.54 | 25.54  |   14.79   | 93.51  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:31:36 - mmengine - INFO - Iter(val) [15/15]    aAcc: 38.3100  mIoU: 21.1100  mAcc: 46.2700  mDice: 33.7700  mFscore: 33.7700  mPrecision: 47.4800  mRecall: 46.2700  data_time: 0.0063  time: 0.0440
2024/04/10 17:32:25 - mmengine - INFO - Iter(train) [13100/20000]  lr: 5.0000e-04  eta: 0:56:27  time: 0.4896  data_time: 0.0133  memory: 4027  grad_norm: 0.8583  loss: 0.0717  decode.loss_ce: 0.0411  decode.acc_seg: 98.9327  aux.loss_ce: 0.0306  aux.acc_seg: 98.6227
2024/04/10 17:33:14 - mmengine - INFO - Iter(train) [13200/20000]  lr: 5.0000e-04  eta: 0:55:38  time: 0.4909  data_time: 0.0135  memory: 4027  grad_norm: 5.0473  loss: 0.1671  decode.loss_ce: 0.1110  decode.acc_seg: 98.3178  aux.loss_ce: 0.0561  aux.acc_seg: 97.8329
2024/04/10 17:34:03 - mmengine - INFO - Iter(train) [13300/20000]  lr: 5.0000e-04  eta: 0:54:49  time: 0.4933  data_time: 0.0158  memory: 4027  grad_norm: 3.2426  loss: 0.0965  decode.loss_ce: 0.0609  decode.acc_seg: 98.7968  aux.loss_ce: 0.0357  aux.acc_seg: 98.5377
2024/04/10 17:34:52 - mmengine - INFO - Iter(train) [13400/20000]  lr: 5.0000e-04  eta: 0:53:59  time: 0.4900  data_time: 0.0132  memory: 4027  grad_norm: 4.4511  loss: 0.1389  decode.loss_ce: 0.0860  decode.acc_seg: 98.1675  aux.loss_ce: 0.0529  aux.acc_seg: 96.6959
2024/04/10 17:35:41 - mmengine - INFO - Iter(train) [13500/20000]  lr: 5.0000e-04  eta: 0:53:10  time: 0.4879  data_time: 0.0128  memory: 4027  grad_norm: 0.8412  loss: 0.0617  decode.loss_ce: 0.0390  decode.acc_seg: 99.0096  aux.loss_ce: 0.0227  aux.acc_seg: 98.5530
2024/04/10 17:35:42 - mmengine - INFO - per class results:
2024/04/10 17:35:42 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 59.51 | 99.97 | 74.62 | 74.62  |   59.52   | 99.97  |
| monolayer  |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer |  0.81 |  0.82 |  1.62 |  1.62  |   78.49   |  0.82  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:35:42 - mmengine - INFO - Iter(val) [15/15]    aAcc: 59.5400  mIoU: 15.0800  mAcc: 25.2000  mDice: 19.0600  mFscore: 38.1200  mPrecision: 69.0100  mRecall: 25.2000  data_time: 0.0062  time: 0.0441
2024/04/10 17:36:31 - mmengine - INFO - Iter(train) [13600/20000]  lr: 5.0000e-04  eta: 0:52:21  time: 0.4907  data_time: 0.0140  memory: 4027  grad_norm: 2.8028  loss: 0.0934  decode.loss_ce: 0.0493  decode.acc_seg: 97.7366  aux.loss_ce: 0.0442  aux.acc_seg: 95.6239
2024/04/10 17:37:19 - mmengine - INFO - Iter(train) [13700/20000]  lr: 5.0000e-04  eta: 0:51:32  time: 0.4906  data_time: 0.0143  memory: 4027  grad_norm: 0.4609  loss: 0.0786  decode.loss_ce: 0.0487  decode.acc_seg: 97.5837  aux.loss_ce: 0.0300  aux.acc_seg: 95.6997
2024/04/10 17:38:08 - mmengine - INFO - Iter(train) [13800/20000]  lr: 5.0000e-04  eta: 0:50:43  time: 0.4880  data_time: 0.0130  memory: 4027  grad_norm: 0.8696  loss: 0.1223  decode.loss_ce: 0.0817  decode.acc_seg: 98.5245  aux.loss_ce: 0.0406  aux.acc_seg: 97.6085
2024/04/10 17:38:57 - mmengine - INFO - Iter(train) [13900/20000]  lr: 5.0000e-04  eta: 0:49:54  time: 0.4897  data_time: 0.0131  memory: 4027  grad_norm: 0.7971  loss: 0.0846  decode.loss_ce: 0.0504  decode.acc_seg: 98.8233  aux.loss_ce: 0.0342  aux.acc_seg: 98.3176
2024/04/10 17:39:46 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 17:39:46 - mmengine - INFO - Iter(train) [14000/20000]  lr: 5.0000e-04  eta: 0:49:04  time: 0.4897  data_time: 0.0138  memory: 4027  grad_norm: 0.9416  loss: 0.0862  decode.loss_ce: 0.0532  decode.acc_seg: 97.9762  aux.loss_ce: 0.0330  aux.acc_seg: 96.8942
2024/04/10 17:39:47 - mmengine - INFO - per class results:
2024/04/10 17:39:47 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 69.18 | 72.16 | 81.78 | 81.78  |   94.36   | 72.16  |
| monolayer  | 20.86 | 22.08 | 34.52 | 34.52  |   79.06   | 22.08  |
|  bilayer   | 33.48 | 38.59 | 50.17 | 50.17  |   71.66   | 38.59  |
| multilayer | 19.41 |  99.6 | 32.51 | 32.51  |   19.43   |  99.6  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:39:47 - mmengine - INFO - Iter(val) [15/15]    aAcc: 59.4100  mIoU: 35.7300  mAcc: 58.1100  mDice: 49.7500  mFscore: 49.7500  mPrecision: 66.1300  mRecall: 58.1100  data_time: 0.0066  time: 0.0442
2024/04/10 17:40:36 - mmengine - INFO - Iter(train) [14100/20000]  lr: 5.0000e-04  eta: 0:48:15  time: 0.4934  data_time: 0.0151  memory: 4027  grad_norm: 0.7254  loss: 0.1125  decode.loss_ce: 0.0719  decode.acc_seg: 97.5651  aux.loss_ce: 0.0406  aux.acc_seg: 96.4151
2024/04/10 17:41:25 - mmengine - INFO - Iter(train) [14200/20000]  lr: 5.0000e-04  eta: 0:47:26  time: 0.4965  data_time: 0.0161  memory: 4027  grad_norm: 1.1391  loss: 0.0818  decode.loss_ce: 0.0525  decode.acc_seg: 98.6279  aux.loss_ce: 0.0292  aux.acc_seg: 95.5337
2024/04/10 17:42:14 - mmengine - INFO - Iter(train) [14300/20000]  lr: 5.0000e-04  eta: 0:46:37  time: 0.4908  data_time: 0.0133  memory: 4027  grad_norm: 3.5894  loss: 0.1134  decode.loss_ce: 0.0574  decode.acc_seg: 98.5747  aux.loss_ce: 0.0560  aux.acc_seg: 97.9764
2024/04/10 17:43:03 - mmengine - INFO - Iter(train) [14400/20000]  lr: 5.0000e-04  eta: 0:45:48  time: 0.4869  data_time: 0.0121  memory: 4027  grad_norm: 0.5908  loss: 0.0719  decode.loss_ce: 0.0436  decode.acc_seg: 98.3324  aux.loss_ce: 0.0284  aux.acc_seg: 97.7110
2024/04/10 17:43:52 - mmengine - INFO - Iter(train) [14500/20000]  lr: 5.0000e-04  eta: 0:44:59  time: 0.4859  data_time: 0.0125  memory: 4027  grad_norm: 0.6890  loss: 0.0720  decode.loss_ce: 0.0465  decode.acc_seg: 97.7465  aux.loss_ce: 0.0255  aux.acc_seg: 97.0744
2024/04/10 17:43:53 - mmengine - INFO - per class results:
2024/04/10 17:43:53 - mmengine - INFO - 
+------------+------+-------+-------+--------+-----------+--------+
|   Class    | IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+------+-------+-------+--------+-----------+--------+
| Background | 19.8 |  20.3 | 33.06 | 33.06  |   88.96   |  20.3  |
| monolayer  | 8.43 |  8.48 | 15.55 | 15.55  |   93.63   |  8.48  |
|  bilayer   | 7.88 | 35.29 | 14.61 | 14.61  |    9.21   | 35.29  |
| multilayer | 12.8 | 95.89 | 22.69 | 22.69  |   12.87   | 95.89  |
+------------+------+-------+-------+--------+-----------+--------+
2024/04/10 17:43:53 - mmengine - INFO - Iter(val) [15/15]    aAcc: 24.4400  mIoU: 12.2300  mAcc: 39.9900  mDice: 21.4800  mFscore: 21.4800  mPrecision: 51.1700  mRecall: 39.9900  data_time: 0.0062  time: 0.0437
2024/04/10 17:44:42 - mmengine - INFO - Iter(train) [14600/20000]  lr: 5.0000e-04  eta: 0:44:10  time: 0.4889  data_time: 0.0130  memory: 4027  grad_norm: 1.7998  loss: 0.0885  decode.loss_ce: 0.0539  decode.acc_seg: 98.7813  aux.loss_ce: 0.0346  aux.acc_seg: 98.4093
2024/04/10 17:45:31 - mmengine - INFO - Iter(train) [14700/20000]  lr: 5.0000e-04  eta: 0:43:21  time: 0.4866  data_time: 0.0117  memory: 4027  grad_norm: 3.7204  loss: 0.1741  decode.loss_ce: 0.1110  decode.acc_seg: 98.7212  aux.loss_ce: 0.0630  aux.acc_seg: 98.3092
2024/04/10 17:46:20 - mmengine - INFO - Iter(train) [14800/20000]  lr: 5.0000e-04  eta: 0:42:32  time: 0.4875  data_time: 0.0126  memory: 4027  grad_norm: 6.2443  loss: 0.1401  decode.loss_ce: 0.0867  decode.acc_seg: 98.6935  aux.loss_ce: 0.0534  aux.acc_seg: 98.0335
2024/04/10 17:47:08 - mmengine - INFO - Iter(train) [14900/20000]  lr: 5.0000e-04  eta: 0:41:42  time: 0.4873  data_time: 0.0123  memory: 4027  grad_norm: 14.8716  loss: 0.0935  decode.loss_ce: 0.0632  decode.acc_seg: 98.4176  aux.loss_ce: 0.0303  aux.acc_seg: 97.6208
2024/04/10 17:47:57 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 17:47:57 - mmengine - INFO - Iter(train) [15000/20000]  lr: 5.0000e-04  eta: 0:40:53  time: 0.4900  data_time: 0.0137  memory: 4027  grad_norm: 1.1148  loss: 0.0631  decode.loss_ce: 0.0356  decode.acc_seg: 98.6604  aux.loss_ce: 0.0275  aux.acc_seg: 98.0427
2024/04/10 17:47:57 - mmengine - INFO - Saving checkpoint at 15000 iterations
2024/04/10 17:47:59 - mmengine - INFO - per class results:
2024/04/10 17:47:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 75.06 | 88.99 | 85.75 | 85.75  |   82.74   | 88.99  |
| monolayer  |  2.82 |  2.86 |  5.48 |  5.48  |   65.76   |  2.86  |
|  bilayer   | 24.45 | 51.62 | 39.29 | 39.29  |   31.71   | 51.62  |
| multilayer | 29.76 | 93.31 | 45.87 | 45.87  |   30.41   | 93.31  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:47:59 - mmengine - INFO - Iter(val) [15/15]    aAcc: 64.4100  mIoU: 33.0200  mAcc: 59.2000  mDice: 44.1000  mFscore: 44.1000  mPrecision: 52.6500  mRecall: 59.2000  data_time: 0.0048  time: 0.0421
2024/04/10 17:48:48 - mmengine - INFO - Iter(train) [15100/20000]  lr: 5.0000e-04  eta: 0:40:04  time: 0.4872  data_time: 0.0127  memory: 4027  grad_norm: 2.3104  loss: 0.1165  decode.loss_ce: 0.0650  decode.acc_seg: 94.6211  aux.loss_ce: 0.0515  aux.acc_seg: 89.9510
2024/04/10 17:49:37 - mmengine - INFO - Iter(train) [15200/20000]  lr: 5.0000e-04  eta: 0:39:15  time: 0.4941  data_time: 0.0154  memory: 4027  grad_norm: 3.6190  loss: 0.1729  decode.loss_ce: 0.1180  decode.acc_seg: 98.3790  aux.loss_ce: 0.0548  aux.acc_seg: 95.9047
2024/04/10 17:50:26 - mmengine - INFO - Iter(train) [15300/20000]  lr: 5.0000e-04  eta: 0:38:26  time: 0.4881  data_time: 0.0129  memory: 4026  grad_norm: 3.2203  loss: 0.1248  decode.loss_ce: 0.0783  decode.acc_seg: 97.5710  aux.loss_ce: 0.0465  aux.acc_seg: 95.8823
2024/04/10 17:51:15 - mmengine - INFO - Iter(train) [15400/20000]  lr: 5.0000e-04  eta: 0:37:37  time: 0.4944  data_time: 0.0158  memory: 4027  grad_norm: 1.2216  loss: 0.0979  decode.loss_ce: 0.0623  decode.acc_seg: 98.5224  aux.loss_ce: 0.0356  aux.acc_seg: 97.6519
2024/04/10 17:52:04 - mmengine - INFO - Iter(train) [15500/20000]  lr: 5.0000e-04  eta: 0:36:48  time: 0.4960  data_time: 0.0150  memory: 4027  grad_norm: 3.3012  loss: 0.0972  decode.loss_ce: 0.0589  decode.acc_seg: 97.9760  aux.loss_ce: 0.0382  aux.acc_seg: 92.2876
2024/04/10 17:52:05 - mmengine - INFO - per class results:
2024/04/10 17:52:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 64.42 | 70.89 | 78.36 | 78.36  |    87.6   | 70.89  |
| monolayer  | 13.19 | 15.35 |  23.3 |  23.3  |   48.39   | 15.35  |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer |  19.8 | 99.52 | 33.05 | 33.05  |   19.82   | 99.52  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:52:05 - mmengine - INFO - Iter(val) [15/15]    aAcc: 54.8700  mIoU: 24.3500  mAcc: 46.4400  mDice: 33.6800  mFscore: 44.9100  mPrecision: 51.9300  mRecall: 46.4400  data_time: 0.0055  time: 0.0430
2024/04/10 17:52:54 - mmengine - INFO - Iter(train) [15600/20000]  lr: 5.0000e-04  eta: 0:35:59  time: 0.4885  data_time: 0.0125  memory: 4027  grad_norm: 1.0889  loss: 0.0709  decode.loss_ce: 0.0430  decode.acc_seg: 97.8495  aux.loss_ce: 0.0280  aux.acc_seg: 96.1207
2024/04/10 17:53:42 - mmengine - INFO - Iter(train) [15700/20000]  lr: 5.0000e-04  eta: 0:35:10  time: 0.4920  data_time: 0.0145  memory: 4027  grad_norm: 2.0379  loss: 0.1378  decode.loss_ce: 0.0786  decode.acc_seg: 98.7952  aux.loss_ce: 0.0591  aux.acc_seg: 98.2048
2024/04/10 17:54:31 - mmengine - INFO - Iter(train) [15800/20000]  lr: 5.0000e-04  eta: 0:34:20  time: 0.4904  data_time: 0.0133  memory: 4027  grad_norm: 2.4453  loss: 0.2181  decode.loss_ce: 0.1406  decode.acc_seg: 98.3632  aux.loss_ce: 0.0775  aux.acc_seg: 97.2431
2024/04/10 17:55:20 - mmengine - INFO - Iter(train) [15900/20000]  lr: 5.0000e-04  eta: 0:33:31  time: 0.4947  data_time: 0.0146  memory: 4027  grad_norm: 6.0796  loss: 0.1421  decode.loss_ce: 0.0900  decode.acc_seg: 98.4609  aux.loss_ce: 0.0521  aux.acc_seg: 98.1187
2024/04/10 17:56:09 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 17:56:09 - mmengine - INFO - Iter(train) [16000/20000]  lr: 5.0000e-04  eta: 0:32:42  time: 0.4879  data_time: 0.0126  memory: 4027  grad_norm: 1.5728  loss: 0.0874  decode.loss_ce: 0.0489  decode.acc_seg: 98.5925  aux.loss_ce: 0.0385  aux.acc_seg: 98.5262
2024/04/10 17:56:10 - mmengine - INFO - per class results:
2024/04/10 17:56:10 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 49.25 |  49.6 |  66.0 |  66.0  |   98.59   |  49.6  |
| monolayer  | 27.73 | 28.79 | 43.42 | 43.42  |    88.3   | 28.79  |
|  bilayer   | 37.12 | 39.44 | 54.15 | 54.15  |   86.33   | 39.44  |
| multilayer | 14.57 | 99.62 | 25.44 | 25.44  |   14.58   | 99.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 17:56:10 - mmengine - INFO - Iter(val) [15/15]    aAcc: 47.8300  mIoU: 32.1700  mAcc: 54.3600  mDice: 47.2500  mFscore: 47.2500  mPrecision: 71.9500  mRecall: 54.3600  data_time: 0.0075  time: 0.0451
2024/04/10 17:56:59 - mmengine - INFO - Iter(train) [16100/20000]  lr: 5.0000e-04  eta: 0:31:53  time: 0.4883  data_time: 0.0132  memory: 4027  grad_norm: 3.6972  loss: 0.1383  decode.loss_ce: 0.0948  decode.acc_seg: 98.2833  aux.loss_ce: 0.0434  aux.acc_seg: 96.9058
2024/04/10 17:57:48 - mmengine - INFO - Iter(train) [16200/20000]  lr: 5.0000e-04  eta: 0:31:04  time: 0.4943  data_time: 0.0148  memory: 4027  grad_norm: 13.9524  loss: 0.1550  decode.loss_ce: 0.1045  decode.acc_seg: 94.8458  aux.loss_ce: 0.0505  aux.acc_seg: 91.2141
2024/04/10 17:58:37 - mmengine - INFO - Iter(train) [16300/20000]  lr: 5.0000e-04  eta: 0:30:15  time: 0.4857  data_time: 0.0119  memory: 4027  grad_norm: 1.2417  loss: 0.0843  decode.loss_ce: 0.0530  decode.acc_seg: 98.7373  aux.loss_ce: 0.0313  aux.acc_seg: 97.4823
2024/04/10 17:59:26 - mmengine - INFO - Iter(train) [16400/20000]  lr: 5.0000e-04  eta: 0:29:26  time: 0.4902  data_time: 0.0133  memory: 4027  grad_norm: 1.0025  loss: 0.0755  decode.loss_ce: 0.0428  decode.acc_seg: 98.3065  aux.loss_ce: 0.0327  aux.acc_seg: 97.4872
2024/04/10 18:00:15 - mmengine - INFO - Iter(train) [16500/20000]  lr: 5.0000e-04  eta: 0:28:37  time: 0.4937  data_time: 0.0156  memory: 4027  grad_norm: 1.1551  loss: 0.0739  decode.loss_ce: 0.0466  decode.acc_seg: 99.1073  aux.loss_ce: 0.0273  aux.acc_seg: 98.3638
2024/04/10 18:00:15 - mmengine - INFO - per class results:
2024/04/10 18:00:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 82.85 | 90.76 | 90.62 | 90.62  |   90.47   | 90.76  |
| monolayer  | 35.83 | 37.61 | 52.76 | 52.76  |   88.32   | 37.61  |
|  bilayer   |  4.18 |  4.24 |  8.03 |  8.03  |   74.81   |  4.24  |
| multilayer | 30.14 | 99.94 | 46.31 | 46.31  |   30.14   | 99.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 18:00:15 - mmengine - INFO - Iter(val) [15/15]    aAcc: 72.9000  mIoU: 38.2500  mAcc: 58.1400  mDice: 49.4300  mFscore: 49.4300  mPrecision: 70.9400  mRecall: 58.1400  data_time: 0.0073  time: 0.0449
2024/04/10 18:01:04 - mmengine - INFO - Iter(train) [16600/20000]  lr: 5.0000e-04  eta: 0:27:48  time: 0.4866  data_time: 0.0125  memory: 4026  grad_norm: 1.5419  loss: 0.0825  decode.loss_ce: 0.0445  decode.acc_seg: 96.9797  aux.loss_ce: 0.0381  aux.acc_seg: 94.4715
2024/04/10 18:01:53 - mmengine - INFO - Iter(train) [16700/20000]  lr: 5.0000e-04  eta: 0:26:59  time: 0.4897  data_time: 0.0135  memory: 4027  grad_norm: 2.2886  loss: 0.1450  decode.loss_ce: 0.0914  decode.acc_seg: 98.6811  aux.loss_ce: 0.0536  aux.acc_seg: 97.9843
2024/04/10 18:02:42 - mmengine - INFO - Iter(train) [16800/20000]  lr: 5.0000e-04  eta: 0:26:09  time: 0.4928  data_time: 0.0149  memory: 4027  grad_norm: 1.9590  loss: 0.0526  decode.loss_ce: 0.0316  decode.acc_seg: 98.7623  aux.loss_ce: 0.0210  aux.acc_seg: 98.2483
2024/04/10 18:03:31 - mmengine - INFO - Iter(train) [16900/20000]  lr: 5.0000e-04  eta: 0:25:20  time: 0.4866  data_time: 0.0124  memory: 4027  grad_norm: 0.5699  loss: 0.0806  decode.loss_ce: 0.0501  decode.acc_seg: 93.4194  aux.loss_ce: 0.0304  aux.acc_seg: 91.9504
2024/04/10 18:04:20 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 18:04:20 - mmengine - INFO - Iter(train) [17000/20000]  lr: 5.0000e-04  eta: 0:24:31  time: 0.4870  data_time: 0.0124  memory: 4026  grad_norm: 2.1649  loss: 0.1091  decode.loss_ce: 0.0619  decode.acc_seg: 98.4497  aux.loss_ce: 0.0472  aux.acc_seg: 97.5324
2024/04/10 18:04:21 - mmengine - INFO - per class results:
2024/04/10 18:04:21 - mmengine - INFO - 
+------------+------+-------+-------+--------+-----------+--------+
|   Class    | IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+------+-------+-------+--------+-----------+--------+
| Background | 4.27 |  4.41 |  8.2  |  8.2   |    58.2   |  4.41  |
| monolayer  | 0.13 |  0.13 |  0.25 |  0.25  |   11.94   |  0.13  |
|  bilayer   | 0.09 |  0.12 |  0.18 |  0.18  |    0.38   |  0.12  |
| multilayer | 9.18 | 99.53 | 16.82 | 16.82  |    9.19   | 99.53  |
+------------+------+-------+-------+--------+-----------+--------+
2024/04/10 18:04:21 - mmengine - INFO - Iter(val) [15/15]    aAcc: 11.2600  mIoU: 3.4200  mAcc: 26.0500  mDice: 6.3600  mFscore: 6.3600  mPrecision: 19.9300  mRecall: 26.0500  data_time: 0.0063  time: 0.0438
2024/04/10 18:05:10 - mmengine - INFO - Iter(train) [17100/20000]  lr: 5.0000e-04  eta: 0:23:42  time: 0.4890  data_time: 0.0132  memory: 4026  grad_norm: 1.0297  loss: 0.0797  decode.loss_ce: 0.0464  decode.acc_seg: 98.9715  aux.loss_ce: 0.0333  aux.acc_seg: 90.9543
2024/04/10 18:05:59 - mmengine - INFO - Iter(train) [17200/20000]  lr: 5.0000e-04  eta: 0:22:53  time: 0.4866  data_time: 0.0111  memory: 4027  grad_norm: 0.5918  loss: 0.1022  decode.loss_ce: 0.0669  decode.acc_seg: 98.1093  aux.loss_ce: 0.0353  aux.acc_seg: 97.0449
2024/04/10 18:06:48 - mmengine - INFO - Iter(train) [17300/20000]  lr: 5.0000e-04  eta: 0:22:04  time: 0.4875  data_time: 0.0130  memory: 4027  grad_norm: 1.8217  loss: 0.0916  decode.loss_ce: 0.0572  decode.acc_seg: 98.6597  aux.loss_ce: 0.0344  aux.acc_seg: 98.3256
2024/04/10 18:07:37 - mmengine - INFO - Iter(train) [17400/20000]  lr: 5.0000e-04  eta: 0:21:15  time: 0.4901  data_time: 0.0128  memory: 4027  grad_norm: 4.3914  loss: 0.1526  decode.loss_ce: 0.1029  decode.acc_seg: 98.7684  aux.loss_ce: 0.0497  aux.acc_seg: 97.3664
2024/04/10 18:08:26 - mmengine - INFO - Iter(train) [17500/20000]  lr: 5.0000e-04  eta: 0:20:26  time: 0.4916  data_time: 0.0144  memory: 4027  grad_norm: 1.7070  loss: 0.0847  decode.loss_ce: 0.0532  decode.acc_seg: 98.9023  aux.loss_ce: 0.0315  aux.acc_seg: 97.5506
2024/04/10 18:08:26 - mmengine - INFO - Saving checkpoint at 17500 iterations
2024/04/10 18:08:27 - mmengine - INFO - per class results:
2024/04/10 18:08:27 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 77.47 | 84.12 |  87.3 |  87.3  |   90.74   | 84.12  |
| monolayer  |  0.29 |  0.29 |  0.58 |  0.58  |   68.96   |  0.29  |
|  bilayer   |  0.8  |  0.83 |  1.58 |  1.58  |   18.92   |  0.83  |
| multilayer | 19.23 | 99.23 | 32.25 | 32.25  |   19.26   | 99.23  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 18:08:27 - mmengine - INFO - Iter(val) [15/15]    aAcc: 58.7300  mIoU: 24.4500  mAcc: 46.1200  mDice: 30.4300  mFscore: 30.4300  mPrecision: 49.4700  mRecall: 46.1200  data_time: 0.0051  time: 0.0426
2024/04/10 18:09:16 - mmengine - INFO - Iter(train) [17600/20000]  lr: 5.0000e-04  eta: 0:19:37  time: 0.4902  data_time: 0.0146  memory: 4027  grad_norm: 1.1076  loss: 0.0671  decode.loss_ce: 0.0395  decode.acc_seg: 98.9388  aux.loss_ce: 0.0276  aux.acc_seg: 98.7293
2024/04/10 18:10:05 - mmengine - INFO - Iter(train) [17700/20000]  lr: 5.0000e-04  eta: 0:18:48  time: 0.4929  data_time: 0.0144  memory: 4027  grad_norm: 1.3036  loss: 0.0808  decode.loss_ce: 0.0468  decode.acc_seg: 97.7915  aux.loss_ce: 0.0340  aux.acc_seg: 96.3196
2024/04/10 18:10:54 - mmengine - INFO - Iter(train) [17800/20000]  lr: 5.0000e-04  eta: 0:17:59  time: 0.4893  data_time: 0.0134  memory: 4027  grad_norm: 0.7330  loss: 0.0580  decode.loss_ce: 0.0331  decode.acc_seg: 98.8149  aux.loss_ce: 0.0248  aux.acc_seg: 97.1688
2024/04/10 18:11:43 - mmengine - INFO - Iter(train) [17900/20000]  lr: 5.0000e-04  eta: 0:17:10  time: 0.4894  data_time: 0.0143  memory: 4027  grad_norm: 7.4155  loss: 0.1030  decode.loss_ce: 0.0621  decode.acc_seg: 99.0692  aux.loss_ce: 0.0408  aux.acc_seg: 98.3598
2024/04/10 18:12:32 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 18:12:32 - mmengine - INFO - Iter(train) [18000/20000]  lr: 5.0000e-04  eta: 0:16:21  time: 0.4876  data_time: 0.0124  memory: 4027  grad_norm: 1.5297  loss: 0.0710  decode.loss_ce: 0.0421  decode.acc_seg: 96.3471  aux.loss_ce: 0.0289  aux.acc_seg: 96.0396
2024/04/10 18:12:33 - mmengine - INFO - per class results:
2024/04/10 18:12:33 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 93.11 | 98.32 | 96.43 | 96.43  |   94.62   | 98.32  |
| monolayer  | 77.07 |  84.2 | 87.05 | 87.05  |   90.11   |  84.2  |
|  bilayer   | 45.32 | 46.82 | 62.37 | 62.37  |   93.37   | 46.82  |
| multilayer | 78.49 | 98.07 | 87.95 | 87.95  |   79.72   | 98.07  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 18:12:33 - mmengine - INFO - Iter(val) [15/15]    aAcc: 91.8800  mIoU: 73.5000  mAcc: 81.8500  mDice: 83.4500  mFscore: 83.4500  mPrecision: 89.4500  mRecall: 81.8500  data_time: 0.0064  time: 0.0441
2024/04/10 18:13:22 - mmengine - INFO - Iter(train) [18100/20000]  lr: 5.0000e-04  eta: 0:15:32  time: 0.4899  data_time: 0.0134  memory: 4027  grad_norm: 1.3022  loss: 0.0800  decode.loss_ce: 0.0512  decode.acc_seg: 98.5288  aux.loss_ce: 0.0288  aux.acc_seg: 97.4671
2024/04/10 18:14:11 - mmengine - INFO - Iter(train) [18200/20000]  lr: 5.0000e-04  eta: 0:14:43  time: 0.4883  data_time: 0.0130  memory: 4027  grad_norm: 1.2541  loss: 0.0716  decode.loss_ce: 0.0439  decode.acc_seg: 97.3896  aux.loss_ce: 0.0278  aux.acc_seg: 95.4793
2024/04/10 18:15:00 - mmengine - INFO - Iter(train) [18300/20000]  lr: 5.0000e-04  eta: 0:13:53  time: 0.4913  data_time: 0.0143  memory: 4027  grad_norm: 1.3015  loss: 0.0555  decode.loss_ce: 0.0315  decode.acc_seg: 98.7556  aux.loss_ce: 0.0240  aux.acc_seg: 97.8529
2024/04/10 18:15:49 - mmengine - INFO - Iter(train) [18400/20000]  lr: 5.0000e-04  eta: 0:13:04  time: 0.4889  data_time: 0.0125  memory: 4027  grad_norm: 1.6740  loss: 0.0743  decode.loss_ce: 0.0465  decode.acc_seg: 98.8722  aux.loss_ce: 0.0277  aux.acc_seg: 98.3783
2024/04/10 18:16:38 - mmengine - INFO - Iter(train) [18500/20000]  lr: 5.0000e-04  eta: 0:12:15  time: 0.4953  data_time: 0.0155  memory: 4027  grad_norm: 1.3372  loss: 0.0688  decode.loss_ce: 0.0406  decode.acc_seg: 98.5793  aux.loss_ce: 0.0282  aux.acc_seg: 96.9302
2024/04/10 18:16:38 - mmengine - INFO - per class results:
2024/04/10 18:16:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 42.73 | 45.53 | 59.88 | 59.88  |   87.42   | 45.53  |
| monolayer  |  0.35 |  0.35 |  0.7  |  0.7   |   32.17   |  0.35  |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    0.0    |  0.0   |
| multilayer | 12.56 | 99.86 | 22.32 | 22.32  |   12.56   | 99.86  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 18:16:38 - mmengine - INFO - Iter(val) [15/15]    aAcc: 35.8000  mIoU: 13.9100  mAcc: 36.4300  mDice: 20.7200  mFscore: 27.6300  mPrecision: 33.0400  mRecall: 36.4300  data_time: 0.0067  time: 0.0439
2024/04/10 18:17:27 - mmengine - INFO - Iter(train) [18600/20000]  lr: 5.0000e-04  eta: 0:11:26  time: 0.4886  data_time: 0.0128  memory: 4027  grad_norm: 2.6839  loss: 0.0831  decode.loss_ce: 0.0544  decode.acc_seg: 98.8303  aux.loss_ce: 0.0287  aux.acc_seg: 98.9040
2024/04/10 18:18:17 - mmengine - INFO - Iter(train) [18700/20000]  lr: 5.0000e-04  eta: 0:10:37  time: 0.4893  data_time: 0.0138  memory: 4027  grad_norm: 0.5128  loss: 0.0677  decode.loss_ce: 0.0429  decode.acc_seg: 98.9113  aux.loss_ce: 0.0248  aux.acc_seg: 98.0773
2024/04/10 18:19:05 - mmengine - INFO - Iter(train) [18800/20000]  lr: 5.0000e-04  eta: 0:09:48  time: 0.4881  data_time: 0.0133  memory: 4027  grad_norm: 1.0891  loss: 0.0608  decode.loss_ce: 0.0371  decode.acc_seg: 98.7566  aux.loss_ce: 0.0237  aux.acc_seg: 98.3357
2024/04/10 18:19:54 - mmengine - INFO - Iter(train) [18900/20000]  lr: 5.0000e-04  eta: 0:08:59  time: 0.4920  data_time: 0.0139  memory: 4026  grad_norm: 0.9919  loss: 0.1231  decode.loss_ce: 0.0764  decode.acc_seg: 98.8178  aux.loss_ce: 0.0467  aux.acc_seg: 98.3979
2024/04/10 18:20:43 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 18:20:43 - mmengine - INFO - Iter(train) [19000/20000]  lr: 5.0000e-04  eta: 0:08:10  time: 0.4921  data_time: 0.0145  memory: 4027  grad_norm: 2.5058  loss: 0.1145  decode.loss_ce: 0.0697  decode.acc_seg: 98.8096  aux.loss_ce: 0.0448  aux.acc_seg: 97.1307
2024/04/10 18:20:44 - mmengine - INFO - per class results:
2024/04/10 18:20:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 16.22 | 16.36 | 27.91 | 27.91  |    95.0   | 16.36  |
| monolayer  |  0.0  |  0.0  |  0.0  |  nan   |    0.0    |  0.0   |
|  bilayer   |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |
| multilayer |  9.55 | 99.28 | 17.43 | 17.43  |    9.56   | 99.28  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 18:20:44 - mmengine - INFO - Iter(val) [15/15]    aAcc: 18.3100  mIoU: 6.4400  mAcc: 28.9100  mDice: 11.3400  mFscore: 22.6700  mPrecision: 34.8500  mRecall: 28.9100  data_time: 0.0054  time: 0.0426
2024/04/10 18:21:33 - mmengine - INFO - Iter(train) [19100/20000]  lr: 5.0000e-04  eta: 0:07:21  time: 0.4867  data_time: 0.0126  memory: 4027  grad_norm: 0.7202  loss: 0.0670  decode.loss_ce: 0.0405  decode.acc_seg: 98.5275  aux.loss_ce: 0.0265  aux.acc_seg: 96.0050
2024/04/10 18:22:22 - mmengine - INFO - Iter(train) [19200/20000]  lr: 5.0000e-04  eta: 0:06:32  time: 0.4852  data_time: 0.0127  memory: 4027  grad_norm: 1.8967  loss: 0.1104  decode.loss_ce: 0.0816  decode.acc_seg: 99.1508  aux.loss_ce: 0.0287  aux.acc_seg: 98.8834
2024/04/10 18:23:11 - mmengine - INFO - Iter(train) [19300/20000]  lr: 5.0000e-04  eta: 0:05:43  time: 0.4885  data_time: 0.0134  memory: 4027  grad_norm: 0.8234  loss: 0.0651  decode.loss_ce: 0.0362  decode.acc_seg: 98.7338  aux.loss_ce: 0.0289  aux.acc_seg: 97.3385
2024/04/10 18:24:00 - mmengine - INFO - Iter(train) [19400/20000]  lr: 5.0000e-04  eta: 0:04:54  time: 0.4895  data_time: 0.0139  memory: 4027  grad_norm: 1.0870  loss: 0.0857  decode.loss_ce: 0.0561  decode.acc_seg: 99.1581  aux.loss_ce: 0.0296  aux.acc_seg: 98.6755
2024/04/10 18:24:49 - mmengine - INFO - Iter(train) [19500/20000]  lr: 5.0000e-04  eta: 0:04:05  time: 0.4925  data_time: 0.0147  memory: 4027  grad_norm: 2.4279  loss: 0.0568  decode.loss_ce: 0.0305  decode.acc_seg: 98.1222  aux.loss_ce: 0.0262  aux.acc_seg: 97.2811
2024/04/10 18:24:50 - mmengine - INFO - per class results:
2024/04/10 18:24:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 83.39 |  96.6 | 90.94 | 90.94  |   85.91   |  96.6  |
| monolayer  | 38.03 | 41.09 |  55.1 |  55.1  |    83.6   | 41.09  |
|  bilayer   | 11.81 | 11.96 | 21.13 | 21.13  |   90.36   | 11.96  |
| multilayer | 43.84 | 98.52 | 60.96 | 60.96  |   44.13   | 98.52  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 18:24:50 - mmengine - INFO - Iter(val) [15/15]    aAcc: 77.5800  mIoU: 44.2700  mAcc: 62.0400  mDice: 57.0300  mFscore: 57.0300  mPrecision: 76.0000  mRecall: 62.0400  data_time: 0.0067  time: 0.0446
2024/04/10 18:25:39 - mmengine - INFO - Iter(train) [19600/20000]  lr: 5.0000e-04  eta: 0:03:16  time: 0.4882  data_time: 0.0115  memory: 4027  grad_norm: 0.4352  loss: 0.0817  decode.loss_ce: 0.0515  decode.acc_seg: 90.2581  aux.loss_ce: 0.0302  aux.acc_seg: 89.2801
2024/04/10 18:26:28 - mmengine - INFO - Iter(train) [19700/20000]  lr: 5.0000e-04  eta: 0:02:27  time: 0.4954  data_time: 0.0161  memory: 4027  grad_norm: 0.6573  loss: 0.0747  decode.loss_ce: 0.0462  decode.acc_seg: 98.9753  aux.loss_ce: 0.0284  aux.acc_seg: 98.5175
2024/04/10 18:27:17 - mmengine - INFO - Iter(train) [19800/20000]  lr: 5.0000e-04  eta: 0:01:38  time: 0.4839  data_time: 0.0111  memory: 4027  grad_norm: 1.6594  loss: 0.0758  decode.loss_ce: 0.0455  decode.acc_seg: 98.9397  aux.loss_ce: 0.0303  aux.acc_seg: 95.2094
2024/04/10 18:28:05 - mmengine - INFO - Iter(train) [19900/20000]  lr: 5.0000e-04  eta: 0:00:49  time: 0.4959  data_time: 0.0164  memory: 4027  grad_norm: 2.3483  loss: 0.2038  decode.loss_ce: 0.1373  decode.acc_seg: 99.2348  aux.loss_ce: 0.0665  aux.acc_seg: 99.0643
2024/04/10 18:28:54 - mmengine - INFO - Exp name: fastvit_pspnet_ful_20240410_154431
2024/04/10 18:28:54 - mmengine - INFO - Iter(train) [20000/20000]  lr: 5.0000e-04  eta: 0:00:00  time: 0.4867  data_time: 0.0129  memory: 4027  grad_norm: 1.2267  loss: 0.0826  decode.loss_ce: 0.0496  decode.acc_seg: 98.1908  aux.loss_ce: 0.0330  aux.acc_seg: 97.0722
2024/04/10 18:28:54 - mmengine - INFO - Saving checkpoint at 20000 iterations
2024/04/10 18:28:56 - mmengine - INFO - per class results:
2024/04/10 18:28:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 72.33 | 77.33 | 83.94 | 83.94  |   91.78   | 77.33  |
| monolayer  | 30.61 | 35.41 | 46.88 | 46.88  |   69.32   | 35.41  |
|  bilayer   |  38.0 | 40.43 | 55.07 | 55.07  |   86.32   | 40.43  |
| multilayer | 25.48 |  99.8 | 40.62 | 40.62  |    25.5   |  99.8  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/10 18:28:56 - mmengine - INFO - Iter(val) [15/15]    aAcc: 66.1700  mIoU: 41.6100  mAcc: 63.2500  mDice: 56.6300  mFscore: 56.6300  mPrecision: 68.2300  mRecall: 63.2500  data_time: 0.0065  time: 0.0440
