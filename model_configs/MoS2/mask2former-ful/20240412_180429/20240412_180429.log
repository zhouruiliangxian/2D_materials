2024/04/12 18:04:32 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0,1: NVIDIA RTX A2000 12GB
    CUDA_HOME: /home/zhouruiliang/.conda/envs/mmseg
    NVCC: Cuda compilation tools, release 11.6, V11.6.124
    GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 4.9.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: True
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 0
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 2
------------------------------------------------------------

2024/04/12 18:04:32 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
crop_size = (
    640,
    640,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = 'MoS2_data/'
dataset_type = 'MoSdata'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=2500,
        max_keep_ckpts=1,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'pytorch'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            640,
            640,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=4,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=90000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=0)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/test', seg_map_path='ann_dir/test'),
        data_root='MoS2_data/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MoSdata'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=500)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        data_prefix=dict(
            img_path='img_dir/train', seg_map_path='ann_dir/train'),
        data_root='MoS2_data/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    2048,
                    1024,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    640,
                    640,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='MoSdata'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            1024,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        640,
        640,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),
        data_root='MoS2_data/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MoSdata'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_head_dirs/mask2former-ful'

2024/04/12 18:04:34 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2024/04/12 18:04:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2024/04/12 18:04:35 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
2024/04/12 18:04:35 - mmengine - INFO - load model from: torchvision://resnet50
2024/04/12 18:04:35 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
2024/04/12 18:04:36 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([5, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/04/12 18:04:36 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/04/12 18:04:36 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/04/12 18:04:36 - mmengine - INFO - Checkpoints will be saved to /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful.
2024/04/12 18:05:13 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 18:05:13 - mmengine - INFO - Iter(train) [   27/20000]  base_lr: 9.9974e-05 lr: 9.9974e-06  eta: 7:36:37  time: 1.1373  data_time: 0.0107  memory: 7967  grad_norm: 150.6493  loss: 77.5304  decode.loss_cls: 1.6195  decode.loss_mask: 3.3731  decode.loss_dice: 3.1344  decode.d0.loss_cls: 3.0785  decode.d0.loss_mask: 2.7944  decode.d0.loss_dice: 2.8948  decode.d1.loss_cls: 1.4295  decode.d1.loss_mask: 2.7941  decode.d1.loss_dice: 2.9838  decode.d2.loss_cls: 1.3998  decode.d2.loss_mask: 2.7839  decode.d2.loss_dice: 2.8999  decode.d3.loss_cls: 1.4540  decode.d3.loss_mask: 2.9074  decode.d3.loss_dice: 2.8908  decode.d4.loss_cls: 1.4581  decode.d4.loss_mask: 3.0867  decode.d4.loss_dice: 2.9900  decode.d5.loss_cls: 1.5459  decode.d5.loss_mask: 3.0345  decode.d5.loss_dice: 2.9593  decode.d6.loss_cls: 1.5677  decode.d6.loss_mask: 3.3264  decode.d6.loss_dice: 2.9505  decode.d7.loss_cls: 1.6071  decode.d7.loss_mask: 3.3463  decode.d7.loss_dice: 3.1050  decode.d8.loss_cls: 1.6221  decode.d8.loss_mask: 3.3583  decode.d8.loss_dice: 3.1347
2024/04/12 18:06:36 - mmengine - INFO - Iter(train) [  100/20000]  base_lr: 9.9901e-05 lr: 9.9901e-06  eta: 6:40:47  time: 1.1530  data_time: 0.0121  memory: 7967  grad_norm: 340.9886  loss: 43.3209  decode.loss_cls: 1.2030  decode.loss_mask: 1.4349  decode.loss_dice: 1.5405  decode.d0.loss_cls: 2.8863  decode.d0.loss_mask: 1.4811  decode.d0.loss_dice: 1.8344  decode.d1.loss_cls: 1.0829  decode.d1.loss_mask: 1.4087  decode.d1.loss_dice: 1.5169  decode.d2.loss_cls: 1.0531  decode.d2.loss_mask: 1.4952  decode.d2.loss_dice: 1.4786  decode.d3.loss_cls: 1.0877  decode.d3.loss_mask: 1.5779  decode.d3.loss_dice: 1.4559  decode.d4.loss_cls: 1.2160  decode.d4.loss_mask: 1.4250  decode.d4.loss_dice: 1.4372  decode.d5.loss_cls: 1.1831  decode.d5.loss_mask: 1.4568  decode.d5.loss_dice: 1.5359  decode.d6.loss_cls: 1.1939  decode.d6.loss_mask: 1.4853  decode.d6.loss_dice: 1.4742  decode.d7.loss_cls: 1.1914  decode.d7.loss_mask: 1.4508  decode.d7.loss_dice: 1.5718  decode.d8.loss_cls: 1.2016  decode.d8.loss_mask: 1.4592  decode.d8.loss_dice: 1.5015
2024/04/12 18:08:32 - mmengine - INFO - Iter(train) [  200/20000]  base_lr: 9.9801e-05 lr: 9.9801e-06  eta: 6:30:34  time: 1.1600  data_time: 0.0118  memory: 7967  grad_norm: 288.8672  loss: 38.7511  decode.loss_cls: 0.8543  decode.loss_mask: 1.4907  decode.loss_dice: 1.4076  decode.d0.loss_cls: 2.6861  decode.d0.loss_mask: 1.3655  decode.d0.loss_dice: 1.7594  decode.d1.loss_cls: 0.7554  decode.d1.loss_mask: 1.4522  decode.d1.loss_dice: 1.4812  decode.d2.loss_cls: 0.6868  decode.d2.loss_mask: 1.5218  decode.d2.loss_dice: 1.4636  decode.d3.loss_cls: 0.7607  decode.d3.loss_mask: 1.4535  decode.d3.loss_dice: 1.4218  decode.d4.loss_cls: 0.7586  decode.d4.loss_mask: 1.4928  decode.d4.loss_dice: 1.4490  decode.d5.loss_cls: 0.7547  decode.d5.loss_mask: 1.4607  decode.d5.loss_dice: 1.4584  decode.d6.loss_cls: 0.7791  decode.d6.loss_mask: 1.4218  decode.d6.loss_dice: 1.4327  decode.d7.loss_cls: 0.7918  decode.d7.loss_mask: 1.3840  decode.d7.loss_dice: 1.3793  decode.d8.loss_cls: 0.8134  decode.d8.loss_mask: 1.4463  decode.d8.loss_dice: 1.3679
2024/04/12 18:10:28 - mmengine - INFO - Iter(train) [  300/20000]  base_lr: 9.9701e-05 lr: 9.9701e-06  eta: 6:26:05  time: 1.1654  data_time: 0.0116  memory: 7964  grad_norm: 400.1471  loss: 33.2127  decode.loss_cls: 0.5744  decode.loss_mask: 1.3916  decode.loss_dice: 1.2476  decode.d0.loss_cls: 2.4629  decode.d0.loss_mask: 1.3101  decode.d0.loss_dice: 1.4148  decode.d1.loss_cls: 0.4875  decode.d1.loss_mask: 1.3894  decode.d1.loss_dice: 1.3070  decode.d2.loss_cls: 0.5080  decode.d2.loss_mask: 1.3377  decode.d2.loss_dice: 1.1880  decode.d3.loss_cls: 0.5047  decode.d3.loss_mask: 1.3561  decode.d3.loss_dice: 1.2405  decode.d4.loss_cls: 0.4782  decode.d4.loss_mask: 1.3600  decode.d4.loss_dice: 1.2613  decode.d5.loss_cls: 0.5637  decode.d5.loss_mask: 1.2985  decode.d5.loss_dice: 1.2225  decode.d6.loss_cls: 0.5226  decode.d6.loss_mask: 1.3672  decode.d6.loss_dice: 1.2167  decode.d7.loss_cls: 0.5395  decode.d7.loss_mask: 1.2987  decode.d7.loss_dice: 1.1903  decode.d8.loss_cls: 0.5822  decode.d8.loss_mask: 1.3812  decode.d8.loss_dice: 1.2096
2024/04/12 18:12:25 - mmengine - INFO - Iter(train) [  400/20000]  base_lr: 9.9601e-05 lr: 9.9601e-06  eta: 6:23:03  time: 1.1618  data_time: 0.0121  memory: 7963  grad_norm: 216.8069  loss: 33.7921  decode.loss_cls: 0.5565  decode.loss_mask: 1.4157  decode.loss_dice: 1.1871  decode.d0.loss_cls: 2.3179  decode.d0.loss_mask: 1.3742  decode.d0.loss_dice: 1.3406  decode.d1.loss_cls: 0.5602  decode.d1.loss_mask: 1.3635  decode.d1.loss_dice: 1.2034  decode.d2.loss_cls: 0.5265  decode.d2.loss_mask: 1.4471  decode.d2.loss_dice: 1.2409  decode.d3.loss_cls: 0.4982  decode.d3.loss_mask: 1.4231  decode.d3.loss_dice: 1.2126  decode.d4.loss_cls: 0.5441  decode.d4.loss_mask: 1.4547  decode.d4.loss_dice: 1.2250  decode.d5.loss_cls: 0.5571  decode.d5.loss_mask: 1.4525  decode.d5.loss_dice: 1.2266  decode.d6.loss_cls: 0.5599  decode.d6.loss_mask: 1.4706  decode.d6.loss_dice: 1.1930  decode.d7.loss_cls: 0.5836  decode.d7.loss_mask: 1.4787  decode.d7.loss_dice: 1.1789  decode.d8.loss_cls: 0.5501  decode.d8.loss_mask: 1.4567  decode.d8.loss_dice: 1.1931
2024/04/12 18:14:21 - mmengine - INFO - Iter(train) [  500/20000]  base_lr: 9.9501e-05 lr: 9.9501e-06  eta: 6:20:22  time: 1.1576  data_time: 0.0117  memory: 7967  grad_norm: 258.0461  loss: 29.4416  decode.loss_cls: 0.4533  decode.loss_mask: 1.2633  decode.loss_dice: 1.0669  decode.d0.loss_cls: 2.0356  decode.d0.loss_mask: 1.2512  decode.d0.loss_dice: 1.1615  decode.d1.loss_cls: 0.3999  decode.d1.loss_mask: 1.2898  decode.d1.loss_dice: 1.0845  decode.d2.loss_cls: 0.4427  decode.d2.loss_mask: 1.2361  decode.d2.loss_dice: 1.0485  decode.d3.loss_cls: 0.4063  decode.d3.loss_mask: 1.2908  decode.d3.loss_dice: 1.0710  decode.d4.loss_cls: 0.4458  decode.d4.loss_mask: 1.2700  decode.d4.loss_dice: 1.0537  decode.d5.loss_cls: 0.4554  decode.d5.loss_mask: 1.2705  decode.d5.loss_dice: 1.0451  decode.d6.loss_cls: 0.4944  decode.d6.loss_mask: 1.2497  decode.d6.loss_dice: 1.0589  decode.d7.loss_cls: 0.5040  decode.d7.loss_mask: 1.2515  decode.d7.loss_dice: 1.0318  decode.d8.loss_cls: 0.4997  decode.d8.loss_mask: 1.2670  decode.d8.loss_dice: 1.0425
2024/04/12 18:14:25 - mmengine - INFO - per class results:
2024/04/12 18:14:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 88.86 | 92.78 |  94.1 |  94.1  |   95.47   | 92.78  |
| monolayer  | 80.24 | 93.94 | 89.04 | 89.04  |   84.62   | 93.94  |
|  bilayer   | 22.43 | 24.41 | 36.64 | 36.64  |   73.48   | 24.41  |
| multilayer | 72.06 | 94.21 | 83.76 | 83.76  |    75.4   | 94.21  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 18:14:25 - mmengine - INFO - Iter(val) [8/8]    aAcc: 89.7100  mIoU: 65.9000  mAcc: 76.3300  mDice: 75.8900  mFscore: 75.8900  mPrecision: 82.2400  mRecall: 76.3300  data_time: 0.2061  time: 0.5049
2024/04/12 18:14:26 - mmengine - INFO - The best checkpoint with 65.9000 mIoU at 500 iter is saved to best_mIoU_iter_500.pth.
2024/04/12 18:16:22 - mmengine - INFO - Iter(train) [  600/20000]  base_lr: 9.9401e-05 lr: 9.9401e-06  eta: 6:18:25  time: 1.1563  data_time: 0.0110  memory: 7967  grad_norm: 211.2979  loss: 29.2036  decode.loss_cls: 0.4391  decode.loss_mask: 1.2434  decode.loss_dice: 1.0916  decode.d0.loss_cls: 1.8344  decode.d0.loss_mask: 1.2451  decode.d0.loss_dice: 1.1985  decode.d1.loss_cls: 0.5058  decode.d1.loss_mask: 1.2085  decode.d1.loss_dice: 1.1022  decode.d2.loss_cls: 0.5258  decode.d2.loss_mask: 1.1569  decode.d2.loss_dice: 1.0562  decode.d3.loss_cls: 0.5099  decode.d3.loss_mask: 1.1863  decode.d3.loss_dice: 1.0496  decode.d4.loss_cls: 0.4979  decode.d4.loss_mask: 1.1830  decode.d4.loss_dice: 1.0811  decode.d5.loss_cls: 0.5120  decode.d5.loss_mask: 1.1670  decode.d5.loss_dice: 1.0736  decode.d6.loss_cls: 0.5038  decode.d6.loss_mask: 1.2064  decode.d6.loss_dice: 1.0781  decode.d7.loss_cls: 0.4866  decode.d7.loss_mask: 1.1926  decode.d7.loss_dice: 1.0940  decode.d8.loss_cls: 0.4863  decode.d8.loss_mask: 1.2162  decode.d8.loss_dice: 1.0720
2024/04/12 18:18:18 - mmengine - INFO - Iter(train) [  700/20000]  base_lr: 9.9301e-05 lr: 9.9301e-06  eta: 6:15:59  time: 1.1617  data_time: 0.0117  memory: 7967  grad_norm: 308.4521  loss: 32.1359  decode.loss_cls: 0.4648  decode.loss_mask: 1.4179  decode.loss_dice: 1.1770  decode.d0.loss_cls: 1.6887  decode.d0.loss_mask: 1.3078  decode.d0.loss_dice: 1.3456  decode.d1.loss_cls: 0.5832  decode.d1.loss_mask: 1.3441  decode.d1.loss_dice: 1.2472  decode.d2.loss_cls: 0.5757  decode.d2.loss_mask: 1.3603  decode.d2.loss_dice: 1.2383  decode.d3.loss_cls: 0.5400  decode.d3.loss_mask: 1.3678  decode.d3.loss_dice: 1.2153  decode.d4.loss_cls: 0.5037  decode.d4.loss_mask: 1.3364  decode.d4.loss_dice: 1.1610  decode.d5.loss_cls: 0.5506  decode.d5.loss_mask: 1.3248  decode.d5.loss_dice: 1.2213  decode.d6.loss_cls: 0.5551  decode.d6.loss_mask: 1.3335  decode.d6.loss_dice: 1.1543  decode.d7.loss_cls: 0.5377  decode.d7.loss_mask: 1.3595  decode.d7.loss_dice: 1.1760  decode.d8.loss_cls: 0.5037  decode.d8.loss_mask: 1.3635  decode.d8.loss_dice: 1.1811
2024/04/12 18:20:14 - mmengine - INFO - Iter(train) [  800/20000]  base_lr: 9.9201e-05 lr: 9.9201e-06  eta: 6:13:49  time: 1.1660  data_time: 0.0128  memory: 7967  grad_norm: 268.4713  loss: 28.9179  decode.loss_cls: 0.3315  decode.loss_mask: 1.3152  decode.loss_dice: 1.1738  decode.d0.loss_cls: 1.4501  decode.d0.loss_mask: 1.3259  decode.d0.loss_dice: 1.2061  decode.d1.loss_cls: 0.3866  decode.d1.loss_mask: 1.2917  decode.d1.loss_dice: 1.1240  decode.d2.loss_cls: 0.3789  decode.d2.loss_mask: 1.3003  decode.d2.loss_dice: 1.1005  decode.d3.loss_cls: 0.3338  decode.d3.loss_mask: 1.3084  decode.d3.loss_dice: 1.1027  decode.d4.loss_cls: 0.3198  decode.d4.loss_mask: 1.3183  decode.d4.loss_dice: 1.1068  decode.d5.loss_cls: 0.3289  decode.d5.loss_mask: 1.2840  decode.d5.loss_dice: 1.1354  decode.d6.loss_cls: 0.3570  decode.d6.loss_mask: 1.2759  decode.d6.loss_dice: 1.1213  decode.d7.loss_cls: 0.2787  decode.d7.loss_mask: 1.3342  decode.d7.loss_dice: 1.1342  decode.d8.loss_cls: 0.3023  decode.d8.loss_mask: 1.3375  decode.d8.loss_dice: 1.1542
2024/04/12 18:22:10 - mmengine - INFO - Iter(train) [  900/20000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 6:11:33  time: 1.1574  data_time: 0.0116  memory: 7967  grad_norm: 223.6688  loss: 27.1446  decode.loss_cls: 0.3001  decode.loss_mask: 1.2550  decode.loss_dice: 1.0644  decode.d0.loss_cls: 1.2993  decode.d0.loss_mask: 1.2518  decode.d0.loss_dice: 1.0915  decode.d1.loss_cls: 0.3790  decode.d1.loss_mask: 1.2677  decode.d1.loss_dice: 1.0832  decode.d2.loss_cls: 0.3695  decode.d2.loss_mask: 1.2430  decode.d2.loss_dice: 1.0508  decode.d3.loss_cls: 0.3276  decode.d3.loss_mask: 1.2368  decode.d3.loss_dice: 1.0398  decode.d4.loss_cls: 0.3109  decode.d4.loss_mask: 1.2685  decode.d4.loss_dice: 1.0335  decode.d5.loss_cls: 0.3206  decode.d5.loss_mask: 1.2428  decode.d5.loss_dice: 1.0219  decode.d6.loss_cls: 0.3083  decode.d6.loss_mask: 1.2165  decode.d6.loss_dice: 1.0450  decode.d7.loss_cls: 0.2801  decode.d7.loss_mask: 1.2550  decode.d7.loss_dice: 1.0345  decode.d8.loss_cls: 0.2872  decode.d8.loss_mask: 1.2329  decode.d8.loss_dice: 1.0273
2024/04/12 18:24:06 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 18:24:06 - mmengine - INFO - Iter(train) [ 1000/20000]  base_lr: 9.9000e-05 lr: 9.9000e-06  eta: 6:09:25  time: 1.1588  data_time: 0.0120  memory: 7967  grad_norm: 266.0952  loss: 26.8051  decode.loss_cls: 0.3887  decode.loss_mask: 1.1500  decode.loss_dice: 0.9295  decode.d0.loss_cls: 1.1868  decode.d0.loss_mask: 1.2213  decode.d0.loss_dice: 1.1314  decode.d1.loss_cls: 0.4289  decode.d1.loss_mask: 1.2304  decode.d1.loss_dice: 1.0709  decode.d2.loss_cls: 0.4123  decode.d2.loss_mask: 1.2087  decode.d2.loss_dice: 0.9896  decode.d3.loss_cls: 0.4114  decode.d3.loss_mask: 1.1956  decode.d3.loss_dice: 0.9906  decode.d4.loss_cls: 0.4254  decode.d4.loss_mask: 1.1782  decode.d4.loss_dice: 0.9757  decode.d5.loss_cls: 0.4295  decode.d5.loss_mask: 1.2051  decode.d5.loss_dice: 0.9705  decode.d6.loss_cls: 0.4055  decode.d6.loss_mask: 1.1753  decode.d6.loss_dice: 0.9660  decode.d7.loss_cls: 0.3731  decode.d7.loss_mask: 1.2061  decode.d7.loss_dice: 0.9704  decode.d8.loss_cls: 0.3857  decode.d8.loss_mask: 1.2016  decode.d8.loss_dice: 0.9910
2024/04/12 18:24:08 - mmengine - INFO - per class results:
2024/04/12 18:24:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 84.28 | 88.92 | 91.47 | 91.47  |   94.17   | 88.92  |
| monolayer  | 64.98 | 85.74 | 78.77 | 78.77  |   72.86   | 85.74  |
|  bilayer   | 53.22 | 59.65 | 69.47 | 69.47  |   83.14   | 59.65  |
| multilayer | 86.86 | 93.15 | 92.97 | 92.97  |   92.79   | 93.15  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 18:24:08 - mmengine - INFO - Iter(val) [8/8]    aAcc: 86.9400  mIoU: 72.3400  mAcc: 81.8700  mDice: 83.1700  mFscore: 83.1700  mPrecision: 85.7400  mRecall: 81.8700  data_time: 0.0129  time: 0.2325
2024/04/12 18:24:08 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful/best_mIoU_iter_500.pth is removed
2024/04/12 18:24:09 - mmengine - INFO - The best checkpoint with 72.3400 mIoU at 1000 iter is saved to best_mIoU_iter_1000.pth.
2024/04/12 18:26:05 - mmengine - INFO - Iter(train) [ 1100/20000]  base_lr: 9.8900e-05 lr: 9.8900e-06  eta: 6:07:31  time: 1.1653  data_time: 0.0128  memory: 7967  grad_norm: 198.2630  loss: 27.5158  decode.loss_cls: 0.2385  decode.loss_mask: 1.3633  decode.loss_dice: 1.0638  decode.d0.loss_cls: 0.9944  decode.d0.loss_mask: 1.3451  decode.d0.loss_dice: 1.0638  decode.d1.loss_cls: 0.2205  decode.d1.loss_mask: 1.4302  decode.d1.loss_dice: 1.1675  decode.d2.loss_cls: 0.2272  decode.d2.loss_mask: 1.3875  decode.d2.loss_dice: 1.1106  decode.d3.loss_cls: 0.2454  decode.d3.loss_mask: 1.3375  decode.d3.loss_dice: 1.0476  decode.d4.loss_cls: 0.2371  decode.d4.loss_mask: 1.3191  decode.d4.loss_dice: 1.0606  decode.d5.loss_cls: 0.2299  decode.d5.loss_mask: 1.3423  decode.d5.loss_dice: 1.0858  decode.d6.loss_cls: 0.2737  decode.d6.loss_mask: 1.3234  decode.d6.loss_dice: 1.0649  decode.d7.loss_cls: 0.2260  decode.d7.loss_mask: 1.3625  decode.d7.loss_dice: 1.0848  decode.d8.loss_cls: 0.2301  decode.d8.loss_mask: 1.3697  decode.d8.loss_dice: 1.0631
2024/04/12 18:28:01 - mmengine - INFO - Iter(train) [ 1200/20000]  base_lr: 9.8800e-05 lr: 9.8800e-06  eta: 6:05:21  time: 1.1597  data_time: 0.0112  memory: 7963  grad_norm: 250.7488  loss: 23.1840  decode.loss_cls: 0.3147  decode.loss_mask: 1.0498  decode.loss_dice: 0.8818  decode.d0.loss_cls: 0.9188  decode.d0.loss_mask: 1.1091  decode.d0.loss_dice: 1.0573  decode.d1.loss_cls: 0.3382  decode.d1.loss_mask: 1.0353  decode.d1.loss_dice: 0.9432  decode.d2.loss_cls: 0.3313  decode.d2.loss_mask: 1.0051  decode.d2.loss_dice: 0.8983  decode.d3.loss_cls: 0.2816  decode.d3.loss_mask: 1.0438  decode.d3.loss_dice: 0.8745  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 1.0542  decode.d4.loss_dice: 0.8944  decode.d5.loss_cls: 0.2528  decode.d5.loss_mask: 1.0477  decode.d5.loss_dice: 0.9015  decode.d6.loss_cls: 0.2500  decode.d6.loss_mask: 1.0577  decode.d6.loss_dice: 0.9178  decode.d7.loss_cls: 0.2499  decode.d7.loss_mask: 1.0874  decode.d7.loss_dice: 0.9202  decode.d8.loss_cls: 0.2626  decode.d8.loss_mask: 1.0648  decode.d8.loss_dice: 0.9042
2024/04/12 18:29:57 - mmengine - INFO - Iter(train) [ 1300/20000]  base_lr: 9.8700e-05 lr: 9.8700e-06  eta: 6:03:16  time: 1.1594  data_time: 0.0112  memory: 7967  grad_norm: 204.2276  loss: 21.0204  decode.loss_cls: 0.2040  decode.loss_mask: 0.9415  decode.loss_dice: 0.8583  decode.d0.loss_cls: 0.7749  decode.d0.loss_mask: 1.0122  decode.d0.loss_dice: 0.9481  decode.d1.loss_cls: 0.2345  decode.d1.loss_mask: 0.9618  decode.d1.loss_dice: 0.8782  decode.d2.loss_cls: 0.2368  decode.d2.loss_mask: 0.9510  decode.d2.loss_dice: 0.8685  decode.d3.loss_cls: 0.2512  decode.d3.loss_mask: 0.9701  decode.d3.loss_dice: 0.8466  decode.d4.loss_cls: 0.2850  decode.d4.loss_mask: 0.9308  decode.d4.loss_dice: 0.8379  decode.d5.loss_cls: 0.2348  decode.d5.loss_mask: 0.9454  decode.d5.loss_dice: 0.8492  decode.d6.loss_cls: 0.2462  decode.d6.loss_mask: 0.9345  decode.d6.loss_dice: 0.8501  decode.d7.loss_cls: 0.2297  decode.d7.loss_mask: 0.9343  decode.d7.loss_dice: 0.8524  decode.d8.loss_cls: 0.2078  decode.d8.loss_mask: 0.9219  decode.d8.loss_dice: 0.8228
2024/04/12 18:31:53 - mmengine - INFO - Iter(train) [ 1400/20000]  base_lr: 9.8600e-05 lr: 9.8600e-06  eta: 6:01:10  time: 1.1594  data_time: 0.0113  memory: 7968  grad_norm: 246.7380  loss: 32.0406  decode.loss_cls: 0.3344  decode.loss_mask: 1.4840  decode.loss_dice: 1.2983  decode.d0.loss_cls: 0.7948  decode.d0.loss_mask: 1.4830  decode.d0.loss_dice: 1.3133  decode.d1.loss_cls: 0.3970  decode.d1.loss_mask: 1.4933  decode.d1.loss_dice: 1.3566  decode.d2.loss_cls: 0.4079  decode.d2.loss_mask: 1.4114  decode.d2.loss_dice: 1.3042  decode.d3.loss_cls: 0.3545  decode.d3.loss_mask: 1.4340  decode.d3.loss_dice: 1.2729  decode.d4.loss_cls: 0.3861  decode.d4.loss_mask: 1.4283  decode.d4.loss_dice: 1.2836  decode.d5.loss_cls: 0.3911  decode.d5.loss_mask: 1.4925  decode.d5.loss_dice: 1.3163  decode.d6.loss_cls: 0.3787  decode.d6.loss_mask: 1.5149  decode.d6.loss_dice: 1.3176  decode.d7.loss_cls: 0.3732  decode.d7.loss_mask: 1.5095  decode.d7.loss_dice: 1.3320  decode.d8.loss_cls: 0.3514  decode.d8.loss_mask: 1.5116  decode.d8.loss_dice: 1.3140
2024/04/12 18:33:49 - mmengine - INFO - Iter(train) [ 1500/20000]  base_lr: 9.8500e-05 lr: 9.8500e-06  eta: 5:59:09  time: 1.1824  data_time: 0.0143  memory: 7971  grad_norm: 416.9512  loss: 22.8102  decode.loss_cls: 0.1607  decode.loss_mask: 1.1429  decode.loss_dice: 0.9003  decode.d0.loss_cls: 0.6440  decode.d0.loss_mask: 1.2257  decode.d0.loss_dice: 0.9631  decode.d1.loss_cls: 0.1885  decode.d1.loss_mask: 1.2026  decode.d1.loss_dice: 0.9084  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 1.1538  decode.d2.loss_dice: 0.9070  decode.d3.loss_cls: 0.1670  decode.d3.loss_mask: 1.1401  decode.d3.loss_dice: 0.9076  decode.d4.loss_cls: 0.1516  decode.d4.loss_mask: 1.1609  decode.d4.loss_dice: 0.9171  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 1.1462  decode.d5.loss_dice: 0.8982  decode.d6.loss_cls: 0.1544  decode.d6.loss_mask: 1.1332  decode.d6.loss_dice: 0.8922  decode.d7.loss_cls: 0.1480  decode.d7.loss_mask: 1.1476  decode.d7.loss_dice: 0.9023  decode.d8.loss_cls: 0.1660  decode.d8.loss_mask: 1.1376  decode.d8.loss_dice: 0.8931
2024/04/12 18:33:51 - mmengine - INFO - per class results:
2024/04/12 18:33:51 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 93.53 | 98.27 | 96.66 | 96.66  |    95.1   | 98.27  |
| monolayer  | 77.32 | 85.83 | 87.21 | 87.21  |   88.65   | 85.83  |
|  bilayer   | 53.24 | 63.19 | 69.48 | 69.48  |   77.17   | 63.19  |
| multilayer |  87.0 | 91.94 | 93.05 | 93.05  |   94.18   | 91.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 18:33:51 - mmengine - INFO - Iter(val) [8/8]    aAcc: 92.6000  mIoU: 77.7700  mAcc: 84.8100  mDice: 86.6000  mFscore: 86.6000  mPrecision: 88.7700  mRecall: 84.8100  data_time: 0.0083  time: 0.2288
2024/04/12 18:33:51 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful/best_mIoU_iter_1000.pth is removed
2024/04/12 18:33:52 - mmengine - INFO - The best checkpoint with 77.7700 mIoU at 1500 iter is saved to best_mIoU_iter_1500.pth.
2024/04/12 18:35:49 - mmengine - INFO - Iter(train) [ 1600/20000]  base_lr: 9.8400e-05 lr: 9.8400e-06  eta: 5:57:35  time: 1.1750  data_time: 0.0118  memory: 7963  grad_norm: 212.8001  loss: 24.5519  decode.loss_cls: 0.2092  decode.loss_mask: 1.1191  decode.loss_dice: 1.0545  decode.d0.loss_cls: 0.5955  decode.d0.loss_mask: 1.1731  decode.d0.loss_dice: 1.1822  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 1.0895  decode.d1.loss_dice: 1.0481  decode.d2.loss_cls: 0.2864  decode.d2.loss_mask: 1.0998  decode.d2.loss_dice: 1.0888  decode.d3.loss_cls: 0.2246  decode.d3.loss_mask: 1.1316  decode.d3.loss_dice: 1.0574  decode.d4.loss_cls: 0.2333  decode.d4.loss_mask: 1.1200  decode.d4.loss_dice: 1.0637  decode.d5.loss_cls: 0.2270  decode.d5.loss_mask: 1.0995  decode.d5.loss_dice: 1.0432  decode.d6.loss_cls: 0.2092  decode.d6.loss_mask: 1.1158  decode.d6.loss_dice: 1.0433  decode.d7.loss_cls: 0.2040  decode.d7.loss_mask: 1.1214  decode.d7.loss_dice: 1.0726  decode.d8.loss_cls: 0.2210  decode.d8.loss_mask: 1.1113  decode.d8.loss_dice: 1.0508
2024/04/12 18:37:46 - mmengine - INFO - Iter(train) [ 1700/20000]  base_lr: 9.8299e-05 lr: 9.8299e-06  eta: 5:55:43  time: 1.1660  data_time: 0.0124  memory: 7968  grad_norm: 220.9307  loss: 22.7086  decode.loss_cls: 0.2366  decode.loss_mask: 1.1126  decode.loss_dice: 0.8586  decode.d0.loss_cls: 0.5617  decode.d0.loss_mask: 1.1606  decode.d0.loss_dice: 0.9374  decode.d1.loss_cls: 0.2402  decode.d1.loss_mask: 1.1152  decode.d1.loss_dice: 0.8697  decode.d2.loss_cls: 0.2271  decode.d2.loss_mask: 1.1264  decode.d2.loss_dice: 0.8736  decode.d3.loss_cls: 0.2449  decode.d3.loss_mask: 1.1409  decode.d3.loss_dice: 0.8455  decode.d4.loss_cls: 0.2531  decode.d4.loss_mask: 1.1152  decode.d4.loss_dice: 0.8729  decode.d5.loss_cls: 0.2192  decode.d5.loss_mask: 1.1315  decode.d5.loss_dice: 0.9061  decode.d6.loss_cls: 0.2302  decode.d6.loss_mask: 1.1119  decode.d6.loss_dice: 0.8853  decode.d7.loss_cls: 0.2327  decode.d7.loss_mask: 1.1143  decode.d7.loss_dice: 0.8920  decode.d8.loss_cls: 0.2290  decode.d8.loss_mask: 1.1106  decode.d8.loss_dice: 0.8537
2024/04/12 18:39:44 - mmengine - INFO - Iter(train) [ 1800/20000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 5:54:03  time: 1.2033  data_time: 0.0148  memory: 7963  grad_norm: 206.0418  loss: 25.1162  decode.loss_cls: 0.3477  decode.loss_mask: 1.1437  decode.loss_dice: 1.0045  decode.d0.loss_cls: 0.6830  decode.d0.loss_mask: 1.1286  decode.d0.loss_dice: 1.0544  decode.d1.loss_cls: 0.4493  decode.d1.loss_mask: 1.1008  decode.d1.loss_dice: 1.0172  decode.d2.loss_cls: 0.3517  decode.d2.loss_mask: 1.1088  decode.d2.loss_dice: 0.9937  decode.d3.loss_cls: 0.3386  decode.d3.loss_mask: 1.0900  decode.d3.loss_dice: 0.9821  decode.d4.loss_cls: 0.3673  decode.d4.loss_mask: 1.0841  decode.d4.loss_dice: 0.9872  decode.d5.loss_cls: 0.3745  decode.d5.loss_mask: 1.1197  decode.d5.loss_dice: 1.0202  decode.d6.loss_cls: 0.3882  decode.d6.loss_mask: 1.0869  decode.d6.loss_dice: 1.0051  decode.d7.loss_cls: 0.3998  decode.d7.loss_mask: 1.0647  decode.d7.loss_dice: 0.9816  decode.d8.loss_cls: 0.3546  decode.d8.loss_mask: 1.1041  decode.d8.loss_dice: 0.9843
2024/04/12 18:41:45 - mmengine - INFO - Iter(train) [ 1900/20000]  base_lr: 9.8099e-05 lr: 9.8099e-06  eta: 5:52:39  time: 1.1971  data_time: 0.0115  memory: 7967  grad_norm: 292.4920  loss: 24.7441  decode.loss_cls: 0.2080  decode.loss_mask: 1.2132  decode.loss_dice: 0.9936  decode.d0.loss_cls: 0.4887  decode.d0.loss_mask: 1.3372  decode.d0.loss_dice: 1.0989  decode.d1.loss_cls: 0.2200  decode.d1.loss_mask: 1.2366  decode.d1.loss_dice: 1.0525  decode.d2.loss_cls: 0.1828  decode.d2.loss_mask: 1.2182  decode.d2.loss_dice: 1.0293  decode.d3.loss_cls: 0.1675  decode.d3.loss_mask: 1.2504  decode.d3.loss_dice: 1.0183  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 1.2416  decode.d4.loss_dice: 1.0215  decode.d5.loss_cls: 0.1606  decode.d5.loss_mask: 1.2478  decode.d5.loss_dice: 0.9760  decode.d6.loss_cls: 0.1501  decode.d6.loss_mask: 1.2678  decode.d6.loss_dice: 1.0036  decode.d7.loss_cls: 0.1999  decode.d7.loss_mask: 1.2429  decode.d7.loss_dice: 0.9809  decode.d8.loss_cls: 0.2072  decode.d8.loss_mask: 1.2121  decode.d8.loss_dice: 0.9536
2024/04/12 18:43:41 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 18:43:41 - mmengine - INFO - Iter(train) [ 2000/20000]  base_lr: 9.7999e-05 lr: 9.7999e-06  eta: 5:50:41  time: 1.1675  data_time: 0.0131  memory: 7968  grad_norm: 198.3886  loss: 26.2963  decode.loss_cls: 0.1630  decode.loss_mask: 1.3488  decode.loss_dice: 1.0739  decode.d0.loss_cls: 0.4292  decode.d0.loss_mask: 1.4002  decode.d0.loss_dice: 1.1082  decode.d1.loss_cls: 0.2280  decode.d1.loss_mask: 1.3245  decode.d1.loss_dice: 1.0707  decode.d2.loss_cls: 0.2240  decode.d2.loss_mask: 1.2964  decode.d2.loss_dice: 1.0683  decode.d3.loss_cls: 0.1986  decode.d3.loss_mask: 1.3081  decode.d3.loss_dice: 1.0792  decode.d4.loss_cls: 0.2083  decode.d4.loss_mask: 1.3012  decode.d4.loss_dice: 1.0827  decode.d5.loss_cls: 0.2061  decode.d5.loss_mask: 1.3216  decode.d5.loss_dice: 1.0703  decode.d6.loss_cls: 0.1894  decode.d6.loss_mask: 1.3329  decode.d6.loss_dice: 1.0832  decode.d7.loss_cls: 0.1944  decode.d7.loss_mask: 1.3479  decode.d7.loss_dice: 1.0842  decode.d8.loss_cls: 0.1571  decode.d8.loss_mask: 1.3436  decode.d8.loss_dice: 1.0523
2024/04/12 18:43:43 - mmengine - INFO - per class results:
2024/04/12 18:43:43 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 94.07 | 98.87 | 96.94 | 96.94  |   95.09   | 98.87  |
| monolayer  | 77.67 |  85.3 | 87.43 | 87.43  |   89.67   |  85.3  |
|  bilayer   |  50.6 | 61.52 |  67.2 |  67.2  |   74.04   | 61.52  |
| multilayer | 86.49 | 91.74 | 92.76 | 92.76  |    93.8   | 91.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 18:43:43 - mmengine - INFO - Iter(val) [8/8]    aAcc: 92.7100  mIoU: 77.2100  mAcc: 84.3600  mDice: 86.0800  mFscore: 86.0800  mPrecision: 88.1500  mRecall: 84.3600  data_time: 0.0140  time: 0.2345
2024/04/12 18:45:40 - mmengine - INFO - Iter(train) [ 2100/20000]  base_lr: 9.7899e-05 lr: 9.7899e-06  eta: 5:48:44  time: 1.1650  data_time: 0.0123  memory: 7963  grad_norm: 214.2697  loss: 21.3841  decode.loss_cls: 0.1620  decode.loss_mask: 1.0375  decode.loss_dice: 0.8694  decode.d0.loss_cls: 0.4513  decode.d0.loss_mask: 1.0836  decode.d0.loss_dice: 0.9540  decode.d1.loss_cls: 0.2106  decode.d1.loss_mask: 1.0089  decode.d1.loss_dice: 0.8935  decode.d2.loss_cls: 0.2156  decode.d2.loss_mask: 1.0177  decode.d2.loss_dice: 0.8521  decode.d3.loss_cls: 0.2171  decode.d3.loss_mask: 1.0399  decode.d3.loss_dice: 0.8480  decode.d4.loss_cls: 0.2288  decode.d4.loss_mask: 1.0784  decode.d4.loss_dice: 0.8665  decode.d5.loss_cls: 0.2056  decode.d5.loss_mask: 1.0673  decode.d5.loss_dice: 0.8741  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 1.0256  decode.d6.loss_dice: 0.8396  decode.d7.loss_cls: 0.1699  decode.d7.loss_mask: 1.0468  decode.d7.loss_dice: 0.8399  decode.d8.loss_cls: 0.1766  decode.d8.loss_mask: 1.0564  decode.d8.loss_dice: 0.8779
2024/04/12 18:47:37 - mmengine - INFO - Iter(train) [ 2200/20000]  base_lr: 9.7798e-05 lr: 9.7798e-06  eta: 5:46:48  time: 1.1679  data_time: 0.0129  memory: 7967  grad_norm: 241.2551  loss: 24.6663  decode.loss_cls: 0.2934  decode.loss_mask: 1.0382  decode.loss_dice: 1.0611  decode.d0.loss_cls: 0.4993  decode.d0.loss_mask: 1.0963  decode.d0.loss_dice: 1.1895  decode.d1.loss_cls: 0.2755  decode.d1.loss_mask: 1.0507  decode.d1.loss_dice: 1.1434  decode.d2.loss_cls: 0.3042  decode.d2.loss_mask: 1.0520  decode.d2.loss_dice: 1.1264  decode.d3.loss_cls: 0.3058  decode.d3.loss_mask: 1.0712  decode.d3.loss_dice: 1.1011  decode.d4.loss_cls: 0.2709  decode.d4.loss_mask: 1.0581  decode.d4.loss_dice: 1.1230  decode.d5.loss_cls: 0.2889  decode.d5.loss_mask: 1.0217  decode.d5.loss_dice: 1.0897  decode.d6.loss_cls: 0.2850  decode.d6.loss_mask: 1.0206  decode.d6.loss_dice: 1.0874  decode.d7.loss_cls: 0.2972  decode.d7.loss_mask: 1.0412  decode.d7.loss_dice: 1.0543  decode.d8.loss_cls: 0.2933  decode.d8.loss_mask: 1.0454  decode.d8.loss_dice: 1.0816
2024/04/12 18:49:34 - mmengine - INFO - Iter(train) [ 2300/20000]  base_lr: 9.7698e-05 lr: 9.7698e-06  eta: 5:44:48  time: 1.1587  data_time: 0.0125  memory: 7971  grad_norm: 177.2273  loss: 23.5494  decode.loss_cls: 0.2562  decode.loss_mask: 0.9830  decode.loss_dice: 1.1017  decode.d0.loss_cls: 0.4791  decode.d0.loss_mask: 1.0233  decode.d0.loss_dice: 1.1883  decode.d1.loss_cls: 0.2149  decode.d1.loss_mask: 1.0126  decode.d1.loss_dice: 1.1000  decode.d2.loss_cls: 0.2212  decode.d2.loss_mask: 1.0097  decode.d2.loss_dice: 1.0860  decode.d3.loss_cls: 0.1412  decode.d3.loss_mask: 0.9935  decode.d3.loss_dice: 1.1321  decode.d4.loss_cls: 0.2080  decode.d4.loss_mask: 0.9713  decode.d4.loss_dice: 1.0939  decode.d5.loss_cls: 0.2467  decode.d5.loss_mask: 0.9842  decode.d5.loss_dice: 1.0784  decode.d6.loss_cls: 0.2406  decode.d6.loss_mask: 0.9888  decode.d6.loss_dice: 1.0905  decode.d7.loss_cls: 0.2735  decode.d7.loss_mask: 0.9919  decode.d7.loss_dice: 1.0753  decode.d8.loss_cls: 0.2559  decode.d8.loss_mask: 1.0072  decode.d8.loss_dice: 1.1003
2024/04/12 18:51:30 - mmengine - INFO - Iter(train) [ 2400/20000]  base_lr: 9.7598e-05 lr: 9.7598e-06  eta: 5:42:48  time: 1.1653  data_time: 0.0118  memory: 7964  grad_norm: 194.8229  loss: 18.6436  decode.loss_cls: 0.1056  decode.loss_mask: 0.9337  decode.loss_dice: 0.8057  decode.d0.loss_cls: 0.2873  decode.d0.loss_mask: 0.9912  decode.d0.loss_dice: 0.8497  decode.d1.loss_cls: 0.1074  decode.d1.loss_mask: 0.9468  decode.d1.loss_dice: 0.8221  decode.d2.loss_cls: 0.1271  decode.d2.loss_mask: 0.9295  decode.d2.loss_dice: 0.7824  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 0.9291  decode.d3.loss_dice: 0.7892  decode.d4.loss_cls: 0.0961  decode.d4.loss_mask: 0.9124  decode.d4.loss_dice: 0.7942  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.9207  decode.d5.loss_dice: 0.7781  decode.d6.loss_cls: 0.1039  decode.d6.loss_mask: 0.9244  decode.d6.loss_dice: 0.8039  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.9380  decode.d7.loss_dice: 0.7978  decode.d8.loss_cls: 0.1034  decode.d8.loss_mask: 0.9589  decode.d8.loss_dice: 0.8057
2024/04/12 18:53:27 - mmengine - INFO - Iter(train) [ 2500/20000]  base_lr: 9.7497e-05 lr: 9.7497e-06  eta: 5:40:48  time: 1.1656  data_time: 0.0120  memory: 7967  grad_norm: 179.5016  loss: 19.3105  decode.loss_cls: 0.1107  decode.loss_mask: 0.9699  decode.loss_dice: 0.8415  decode.d0.loss_cls: 0.3133  decode.d0.loss_mask: 1.0222  decode.d0.loss_dice: 0.9194  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 1.0049  decode.d1.loss_dice: 0.8479  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.9834  decode.d2.loss_dice: 0.8189  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 0.9610  decode.d3.loss_dice: 0.8249  decode.d4.loss_cls: 0.1002  decode.d4.loss_mask: 0.9677  decode.d4.loss_dice: 0.8010  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.9593  decode.d5.loss_dice: 0.7999  decode.d6.loss_cls: 0.1198  decode.d6.loss_mask: 0.9573  decode.d6.loss_dice: 0.8032  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.9948  decode.d7.loss_dice: 0.8460  decode.d8.loss_cls: 0.1129  decode.d8.loss_mask: 0.9610  decode.d8.loss_dice: 0.8165
2024/04/12 18:53:27 - mmengine - INFO - Saving checkpoint at 2500 iterations
2024/04/12 18:53:30 - mmengine - INFO - per class results:
2024/04/12 18:53:30 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 93.65 | 98.47 | 96.72 | 96.72  |   95.04   | 98.47  |
| monolayer  | 80.54 | 86.47 | 89.22 | 89.22  |   92.16   | 86.47  |
|  bilayer   | 72.56 | 84.73 |  84.1 |  84.1  |   83.47   | 84.73  |
| multilayer | 86.88 | 89.91 | 92.98 | 92.98  |   96.27   | 89.91  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 18:53:30 - mmengine - INFO - Iter(val) [8/8]    aAcc: 93.8100  mIoU: 83.4100  mAcc: 89.8900  mDice: 90.7500  mFscore: 90.7500  mPrecision: 91.7300  mRecall: 89.8900  data_time: 0.0084  time: 0.2292
2024/04/12 18:53:30 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful/best_mIoU_iter_1500.pth is removed
2024/04/12 18:53:31 - mmengine - INFO - The best checkpoint with 83.4100 mIoU at 2500 iter is saved to best_mIoU_iter_2500.pth.
2024/04/12 18:55:30 - mmengine - INFO - Iter(train) [ 2600/20000]  base_lr: 9.7397e-05 lr: 9.7397e-06  eta: 5:39:09  time: 1.1596  data_time: 0.0126  memory: 7963  grad_norm: 315.5833  loss: 22.6800  decode.loss_cls: 0.2398  decode.loss_mask: 1.0406  decode.loss_dice: 0.9801  decode.d0.loss_cls: 0.4349  decode.d0.loss_mask: 1.0797  decode.d0.loss_dice: 1.0539  decode.d1.loss_cls: 0.2869  decode.d1.loss_mask: 1.0186  decode.d1.loss_dice: 0.9860  decode.d2.loss_cls: 0.2276  decode.d2.loss_mask: 1.0312  decode.d2.loss_dice: 0.9616  decode.d3.loss_cls: 0.2020  decode.d3.loss_mask: 1.0186  decode.d3.loss_dice: 0.9517  decode.d4.loss_cls: 0.2271  decode.d4.loss_mask: 1.0112  decode.d4.loss_dice: 0.9308  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 1.0188  decode.d5.loss_dice: 0.9580  decode.d6.loss_cls: 0.2095  decode.d6.loss_mask: 1.0567  decode.d6.loss_dice: 0.9724  decode.d7.loss_cls: 0.2101  decode.d7.loss_mask: 1.0764  decode.d7.loss_dice: 0.9835  decode.d8.loss_cls: 0.2570  decode.d8.loss_mask: 1.0649  decode.d8.loss_dice: 0.9866
2024/04/12 18:57:26 - mmengine - INFO - Iter(train) [ 2700/20000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 5:37:08  time: 1.1603  data_time: 0.0114  memory: 7967  grad_norm: 241.3717  loss: 21.6934  decode.loss_cls: 0.1788  decode.loss_mask: 0.9777  decode.loss_dice: 0.9468  decode.d0.loss_cls: 0.3201  decode.d0.loss_mask: 1.0632  decode.d0.loss_dice: 1.0384  decode.d1.loss_cls: 0.1370  decode.d1.loss_mask: 1.0305  decode.d1.loss_dice: 1.0188  decode.d2.loss_cls: 0.1956  decode.d2.loss_mask: 1.0066  decode.d2.loss_dice: 0.9890  decode.d3.loss_cls: 0.1515  decode.d3.loss_mask: 1.0142  decode.d3.loss_dice: 1.0037  decode.d4.loss_cls: 0.1564  decode.d4.loss_mask: 1.0071  decode.d4.loss_dice: 0.9820  decode.d5.loss_cls: 0.1081  decode.d5.loss_mask: 1.0049  decode.d5.loss_dice: 0.9777  decode.d6.loss_cls: 0.1509  decode.d6.loss_mask: 1.0046  decode.d6.loss_dice: 0.9860  decode.d7.loss_cls: 0.1649  decode.d7.loss_mask: 1.0038  decode.d7.loss_dice: 0.9824  decode.d8.loss_cls: 0.1536  decode.d8.loss_mask: 0.9770  decode.d8.loss_dice: 0.9621
2024/04/12 18:59:22 - mmengine - INFO - Iter(train) [ 2800/20000]  base_lr: 9.7197e-05 lr: 9.7197e-06  eta: 5:35:08  time: 1.1648  data_time: 0.0121  memory: 7963  grad_norm: 373.2062  loss: 18.0842  decode.loss_cls: 0.0880  decode.loss_mask: 0.8909  decode.loss_dice: 0.7759  decode.d0.loss_cls: 0.3063  decode.d0.loss_mask: 0.9283  decode.d0.loss_dice: 0.8614  decode.d1.loss_cls: 0.0992  decode.d1.loss_mask: 0.9140  decode.d1.loss_dice: 0.7971  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.9141  decode.d2.loss_dice: 0.8059  decode.d3.loss_cls: 0.1046  decode.d3.loss_mask: 0.9006  decode.d3.loss_dice: 0.7964  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.9115  decode.d4.loss_dice: 0.7881  decode.d5.loss_cls: 0.1064  decode.d5.loss_mask: 0.8778  decode.d5.loss_dice: 0.7764  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.8980  decode.d6.loss_dice: 0.7909  decode.d7.loss_cls: 0.1119  decode.d7.loss_mask: 0.8872  decode.d7.loss_dice: 0.7731  decode.d8.loss_cls: 0.0910  decode.d8.loss_mask: 0.8855  decode.d8.loss_dice: 0.7746
2024/04/12 19:01:19 - mmengine - INFO - Iter(train) [ 2900/20000]  base_lr: 9.7096e-05 lr: 9.7096e-06  eta: 5:33:08  time: 1.1607  data_time: 0.0110  memory: 7963  grad_norm: 278.9157  loss: 19.1032  decode.loss_cls: 0.0832  decode.loss_mask: 0.9697  decode.loss_dice: 0.7881  decode.d0.loss_cls: 0.3515  decode.d0.loss_mask: 1.0486  decode.d0.loss_dice: 0.8461  decode.d1.loss_cls: 0.1274  decode.d1.loss_mask: 0.9871  decode.d1.loss_dice: 0.8392  decode.d2.loss_cls: 0.1428  decode.d2.loss_mask: 0.9824  decode.d2.loss_dice: 0.7760  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.9912  decode.d3.loss_dice: 0.7786  decode.d4.loss_cls: 0.0987  decode.d4.loss_mask: 0.9878  decode.d4.loss_dice: 0.7731  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.9886  decode.d5.loss_dice: 0.7824  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.9854  decode.d6.loss_dice: 0.7797  decode.d7.loss_cls: 0.0939  decode.d7.loss_mask: 0.9841  decode.d7.loss_dice: 0.7786  decode.d8.loss_cls: 0.0991  decode.d8.loss_mask: 0.9799  decode.d8.loss_dice: 0.7859
2024/04/12 19:03:15 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 19:03:15 - mmengine - INFO - Iter(train) [ 3000/20000]  base_lr: 9.6996e-05 lr: 9.6996e-06  eta: 5:31:07  time: 1.1568  data_time: 0.0120  memory: 7963  grad_norm: 288.0839  loss: 18.8178  decode.loss_cls: 0.0980  decode.loss_mask: 0.9368  decode.loss_dice: 0.8366  decode.d0.loss_cls: 0.2937  decode.d0.loss_mask: 0.9461  decode.d0.loss_dice: 0.8739  decode.d1.loss_cls: 0.1117  decode.d1.loss_mask: 0.9340  decode.d1.loss_dice: 0.8715  decode.d2.loss_cls: 0.1151  decode.d2.loss_mask: 0.9206  decode.d2.loss_dice: 0.8287  decode.d3.loss_cls: 0.1064  decode.d3.loss_mask: 0.9348  decode.d3.loss_dice: 0.8395  decode.d4.loss_cls: 0.0813  decode.d4.loss_mask: 0.9308  decode.d4.loss_dice: 0.8160  decode.d5.loss_cls: 0.1002  decode.d5.loss_mask: 0.9227  decode.d5.loss_dice: 0.8056  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.9195  decode.d6.loss_dice: 0.8132  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 0.9142  decode.d7.loss_dice: 0.8368  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.9265  decode.d8.loss_dice: 0.8109
2024/04/12 19:03:17 - mmengine - INFO - per class results:
2024/04/12 19:03:17 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.34 | 98.22 | 98.14 | 98.14  |   98.06   | 98.22  |
| monolayer  | 86.83 | 92.63 | 92.95 | 92.95  |   93.26   | 92.63  |
|  bilayer   | 74.08 | 86.14 | 85.11 | 85.11  |    84.1   | 86.14  |
| multilayer | 87.04 | 92.86 | 93.07 | 93.07  |   93.29   | 92.86  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 19:03:17 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.6400  mIoU: 86.0700  mAcc: 92.4600  mDice: 92.3200  mFscore: 92.3200  mPrecision: 92.1800  mRecall: 92.4600  data_time: 0.0135  time: 0.2336
2024/04/12 19:03:17 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful/best_mIoU_iter_2500.pth is removed
2024/04/12 19:03:18 - mmengine - INFO - The best checkpoint with 86.0700 mIoU at 3000 iter is saved to best_mIoU_iter_3000.pth.
2024/04/12 19:05:15 - mmengine - INFO - Iter(train) [ 3100/20000]  base_lr: 9.6896e-05 lr: 9.6896e-06  eta: 5:29:20  time: 1.1593  data_time: 0.0115  memory: 7963  grad_norm: 202.6138  loss: 19.8789  decode.loss_cls: 0.1472  decode.loss_mask: 0.9041  decode.loss_dice: 0.8758  decode.d0.loss_cls: 0.3104  decode.d0.loss_mask: 0.9457  decode.d0.loss_dice: 0.9369  decode.d1.loss_cls: 0.2137  decode.d1.loss_mask: 0.9184  decode.d1.loss_dice: 0.9019  decode.d2.loss_cls: 0.1826  decode.d2.loss_mask: 0.9063  decode.d2.loss_dice: 0.9028  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.9086  decode.d3.loss_dice: 0.9320  decode.d4.loss_cls: 0.1548  decode.d4.loss_mask: 0.9076  decode.d4.loss_dice: 0.9178  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.9108  decode.d5.loss_dice: 0.8880  decode.d6.loss_cls: 0.1221  decode.d6.loss_mask: 0.9100  decode.d6.loss_dice: 0.9183  decode.d7.loss_cls: 0.1176  decode.d7.loss_mask: 0.9232  decode.d7.loss_dice: 0.9098  decode.d8.loss_cls: 0.1486  decode.d8.loss_mask: 0.9080  decode.d8.loss_dice: 0.8847
2024/04/12 19:07:12 - mmengine - INFO - Iter(train) [ 3200/20000]  base_lr: 9.6795e-05 lr: 9.6795e-06  eta: 5:27:19  time: 1.1646  data_time: 0.0113  memory: 7968  grad_norm: 213.5471  loss: 17.7253  decode.loss_cls: 0.1144  decode.loss_mask: 0.8074  decode.loss_dice: 0.7800  decode.d0.loss_cls: 0.2902  decode.d0.loss_mask: 0.8488  decode.d0.loss_dice: 0.8998  decode.d1.loss_cls: 0.1808  decode.d1.loss_mask: 0.7961  decode.d1.loss_dice: 0.8120  decode.d2.loss_cls: 0.2037  decode.d2.loss_mask: 0.8055  decode.d2.loss_dice: 0.8167  decode.d3.loss_cls: 0.1389  decode.d3.loss_mask: 0.8232  decode.d3.loss_dice: 0.8171  decode.d4.loss_cls: 0.1317  decode.d4.loss_mask: 0.8071  decode.d4.loss_dice: 0.7992  decode.d5.loss_cls: 0.1174  decode.d5.loss_mask: 0.7983  decode.d5.loss_dice: 0.7979  decode.d6.loss_cls: 0.1398  decode.d6.loss_mask: 0.8094  decode.d6.loss_dice: 0.7932  decode.d7.loss_cls: 0.1004  decode.d7.loss_mask: 0.8140  decode.d7.loss_dice: 0.8089  decode.d8.loss_cls: 0.1091  decode.d8.loss_mask: 0.7916  decode.d8.loss_dice: 0.7723
2024/04/12 19:09:08 - mmengine - INFO - Iter(train) [ 3300/20000]  base_lr: 9.6695e-05 lr: 9.6695e-06  eta: 5:25:20  time: 1.1600  data_time: 0.0121  memory: 7971  grad_norm: 290.7333  loss: 24.5315  decode.loss_cls: 0.2618  decode.loss_mask: 1.2678  decode.loss_dice: 0.9510  decode.d0.loss_cls: 0.3987  decode.d0.loss_mask: 1.2501  decode.d0.loss_dice: 1.0277  decode.d1.loss_cls: 0.2688  decode.d1.loss_mask: 1.2362  decode.d1.loss_dice: 0.9890  decode.d2.loss_cls: 0.2664  decode.d2.loss_mask: 1.1750  decode.d2.loss_dice: 0.9459  decode.d3.loss_cls: 0.2504  decode.d3.loss_mask: 1.2150  decode.d3.loss_dice: 0.9436  decode.d4.loss_cls: 0.3399  decode.d4.loss_mask: 1.1492  decode.d4.loss_dice: 0.9183  decode.d5.loss_cls: 0.3020  decode.d5.loss_mask: 1.1910  decode.d5.loss_dice: 0.9336  decode.d6.loss_cls: 0.3054  decode.d6.loss_mask: 1.1930  decode.d6.loss_dice: 0.8933  decode.d7.loss_cls: 0.2371  decode.d7.loss_mask: 1.2433  decode.d7.loss_dice: 0.9478  decode.d8.loss_cls: 0.2246  decode.d8.loss_mask: 1.2596  decode.d8.loss_dice: 0.9459
2024/04/12 19:11:05 - mmengine - INFO - Iter(train) [ 3400/20000]  base_lr: 9.6594e-05 lr: 9.6594e-06  eta: 5:23:21  time: 1.1662  data_time: 0.0118  memory: 7971  grad_norm: 211.0857  loss: 17.8893  decode.loss_cls: 0.0948  decode.loss_mask: 0.8872  decode.loss_dice: 0.8351  decode.d0.loss_cls: 0.2239  decode.d0.loss_mask: 0.9708  decode.d0.loss_dice: 0.8519  decode.d1.loss_cls: 0.1098  decode.d1.loss_mask: 0.8721  decode.d1.loss_dice: 0.7798  decode.d2.loss_cls: 0.0930  decode.d2.loss_mask: 0.8977  decode.d2.loss_dice: 0.8003  decode.d3.loss_cls: 0.1294  decode.d3.loss_mask: 0.8659  decode.d3.loss_dice: 0.8072  decode.d4.loss_cls: 0.0901  decode.d4.loss_mask: 0.8704  decode.d4.loss_dice: 0.7829  decode.d5.loss_cls: 0.1016  decode.d5.loss_mask: 0.8809  decode.d5.loss_dice: 0.7837  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.8566  decode.d6.loss_dice: 0.7610  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.8462  decode.d7.loss_dice: 0.7714  decode.d8.loss_cls: 0.0993  decode.d8.loss_mask: 0.8738  decode.d8.loss_dice: 0.7914
2024/04/12 19:13:01 - mmengine - INFO - Iter(train) [ 3500/20000]  base_lr: 9.6494e-05 lr: 9.6494e-06  eta: 5:21:22  time: 1.1639  data_time: 0.0120  memory: 7968  grad_norm: 226.0086  loss: 18.9505  decode.loss_cls: 0.1956  decode.loss_mask: 0.8343  decode.loss_dice: 0.8529  decode.d0.loss_cls: 0.2407  decode.d0.loss_mask: 0.9219  decode.d0.loss_dice: 0.9602  decode.d1.loss_cls: 0.1586  decode.d1.loss_mask: 0.8641  decode.d1.loss_dice: 0.8745  decode.d2.loss_cls: 0.1753  decode.d2.loss_mask: 0.8482  decode.d2.loss_dice: 0.8529  decode.d3.loss_cls: 0.1843  decode.d3.loss_mask: 0.8504  decode.d3.loss_dice: 0.8372  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.8407  decode.d4.loss_dice: 0.8463  decode.d5.loss_cls: 0.1808  decode.d5.loss_mask: 0.8437  decode.d5.loss_dice: 0.8424  decode.d6.loss_cls: 0.1795  decode.d6.loss_mask: 0.8534  decode.d6.loss_dice: 0.8312  decode.d7.loss_cls: 0.1674  decode.d7.loss_mask: 0.8391  decode.d7.loss_dice: 0.8408  decode.d8.loss_cls: 0.1884  decode.d8.loss_mask: 0.8273  decode.d8.loss_dice: 0.8502
2024/04/12 19:13:03 - mmengine - INFO - per class results:
2024/04/12 19:13:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 92.29 | 97.47 | 95.99 | 95.99  |   94.56   | 97.47  |
| monolayer  | 76.58 | 84.53 | 86.73 | 86.73  |   89.05   | 84.53  |
|  bilayer   | 62.35 | 72.56 | 76.81 | 76.81  |   81.58   | 72.56  |
| multilayer | 85.62 | 92.74 | 92.25 | 92.25  |   91.76   | 92.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 19:13:03 - mmengine - INFO - Iter(val) [8/8]    aAcc: 92.3200  mIoU: 79.2100  mAcc: 86.8300  mDice: 87.9500  mFscore: 87.9500  mPrecision: 89.2400  mRecall: 86.8300  data_time: 0.0101  time: 0.2301
2024/04/12 19:14:59 - mmengine - INFO - Iter(train) [ 3600/20000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 5:19:24  time: 1.1594  data_time: 0.0116  memory: 7968  grad_norm: 206.5532  loss: 19.9511  decode.loss_cls: 0.1574  decode.loss_mask: 0.9228  decode.loss_dice: 0.8717  decode.d0.loss_cls: 0.3263  decode.d0.loss_mask: 0.9330  decode.d0.loss_dice: 0.8598  decode.d1.loss_cls: 0.1802  decode.d1.loss_mask: 0.9708  decode.d1.loss_dice: 0.8652  decode.d2.loss_cls: 0.1954  decode.d2.loss_mask: 0.9142  decode.d2.loss_dice: 0.8587  decode.d3.loss_cls: 0.1898  decode.d3.loss_mask: 0.9480  decode.d3.loss_dice: 0.8629  decode.d4.loss_cls: 0.2376  decode.d4.loss_mask: 0.9374  decode.d4.loss_dice: 0.8489  decode.d5.loss_cls: 0.1916  decode.d5.loss_mask: 0.9382  decode.d5.loss_dice: 0.8667  decode.d6.loss_cls: 0.1771  decode.d6.loss_mask: 0.9256  decode.d6.loss_dice: 0.8435  decode.d7.loss_cls: 0.2311  decode.d7.loss_mask: 0.9324  decode.d7.loss_dice: 0.8173  decode.d8.loss_cls: 0.1970  decode.d8.loss_mask: 0.9238  decode.d8.loss_dice: 0.8267
2024/04/12 19:16:56 - mmengine - INFO - Iter(train) [ 3700/20000]  base_lr: 9.6293e-05 lr: 9.6293e-06  eta: 5:17:24  time: 1.1694  data_time: 0.0128  memory: 7967  grad_norm: 216.9522  loss: 17.9984  decode.loss_cls: 0.1343  decode.loss_mask: 0.8661  decode.loss_dice: 0.7976  decode.d0.loss_cls: 0.1941  decode.d0.loss_mask: 0.9470  decode.d0.loss_dice: 0.8893  decode.d1.loss_cls: 0.0914  decode.d1.loss_mask: 0.8899  decode.d1.loss_dice: 0.7624  decode.d2.loss_cls: 0.0897  decode.d2.loss_mask: 0.8892  decode.d2.loss_dice: 0.7938  decode.d3.loss_cls: 0.0937  decode.d3.loss_mask: 0.8703  decode.d3.loss_dice: 0.7875  decode.d4.loss_cls: 0.0945  decode.d4.loss_mask: 0.8829  decode.d4.loss_dice: 0.7829  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.8811  decode.d5.loss_dice: 0.7945  decode.d6.loss_cls: 0.0987  decode.d6.loss_mask: 0.8868  decode.d6.loss_dice: 0.7901  decode.d7.loss_cls: 0.1103  decode.d7.loss_mask: 0.8940  decode.d7.loss_dice: 0.7979  decode.d8.loss_cls: 0.1141  decode.d8.loss_mask: 0.8853  decode.d8.loss_dice: 0.7907
2024/04/12 19:18:52 - mmengine - INFO - Iter(train) [ 3800/20000]  base_lr: 9.6193e-05 lr: 9.6193e-06  eta: 5:15:24  time: 1.1646  data_time: 0.0122  memory: 7967  grad_norm: 206.3076  loss: 18.3882  decode.loss_cls: 0.1244  decode.loss_mask: 0.9042  decode.loss_dice: 0.7821  decode.d0.loss_cls: 0.2259  decode.d0.loss_mask: 0.9270  decode.d0.loss_dice: 0.8317  decode.d1.loss_cls: 0.1321  decode.d1.loss_mask: 0.9109  decode.d1.loss_dice: 0.8082  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 0.8991  decode.d2.loss_dice: 0.7889  decode.d3.loss_cls: 0.1229  decode.d3.loss_mask: 0.8858  decode.d3.loss_dice: 0.7648  decode.d4.loss_cls: 0.1332  decode.d4.loss_mask: 0.8962  decode.d4.loss_dice: 0.7742  decode.d5.loss_cls: 0.1473  decode.d5.loss_mask: 0.8956  decode.d5.loss_dice: 0.8133  decode.d6.loss_cls: 0.1184  decode.d6.loss_mask: 0.9142  decode.d6.loss_dice: 0.7894  decode.d7.loss_cls: 0.1170  decode.d7.loss_mask: 0.9045  decode.d7.loss_dice: 0.8104  decode.d8.loss_cls: 0.1292  decode.d8.loss_mask: 0.9045  decode.d8.loss_dice: 0.7825
2024/04/12 19:20:48 - mmengine - INFO - Iter(train) [ 3900/20000]  base_lr: 9.6092e-05 lr: 9.6092e-06  eta: 5:13:26  time: 1.1611  data_time: 0.0111  memory: 7967  grad_norm: 279.3753  loss: 21.7364  decode.loss_cls: 0.2003  decode.loss_mask: 1.0876  decode.loss_dice: 0.9477  decode.d0.loss_cls: 0.2750  decode.d0.loss_mask: 1.1482  decode.d0.loss_dice: 1.0004  decode.d1.loss_cls: 0.1560  decode.d1.loss_mask: 1.0745  decode.d1.loss_dice: 0.9769  decode.d2.loss_cls: 0.1584  decode.d2.loss_mask: 1.0280  decode.d2.loss_dice: 0.9000  decode.d3.loss_cls: 0.1136  decode.d3.loss_mask: 1.0293  decode.d3.loss_dice: 0.9080  decode.d4.loss_cls: 0.1344  decode.d4.loss_mask: 1.0532  decode.d4.loss_dice: 0.8847  decode.d5.loss_cls: 0.1306  decode.d5.loss_mask: 1.0576  decode.d5.loss_dice: 0.9110  decode.d6.loss_cls: 0.1558  decode.d6.loss_mask: 1.0573  decode.d6.loss_dice: 0.9032  decode.d7.loss_cls: 0.2257  decode.d7.loss_mask: 1.0654  decode.d7.loss_dice: 0.9071  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 1.1080  decode.d8.loss_dice: 0.9334
2024/04/12 19:22:45 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 19:22:45 - mmengine - INFO - Iter(train) [ 4000/20000]  base_lr: 9.5992e-05 lr: 9.5992e-06  eta: 5:11:29  time: 1.1605  data_time: 0.0118  memory: 7968  grad_norm: 248.4830  loss: 16.8592  decode.loss_cls: 0.1023  decode.loss_mask: 0.8248  decode.loss_dice: 0.7476  decode.d0.loss_cls: 0.2247  decode.d0.loss_mask: 0.8578  decode.d0.loss_dice: 0.7794  decode.d1.loss_cls: 0.1471  decode.d1.loss_mask: 0.8119  decode.d1.loss_dice: 0.7297  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.8039  decode.d2.loss_dice: 0.7334  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 0.8105  decode.d3.loss_dice: 0.7332  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.8205  decode.d4.loss_dice: 0.7563  decode.d5.loss_cls: 0.0925  decode.d5.loss_mask: 0.8289  decode.d5.loss_dice: 0.7511  decode.d6.loss_cls: 0.1077  decode.d6.loss_mask: 0.8106  decode.d6.loss_dice: 0.7441  decode.d7.loss_cls: 0.1068  decode.d7.loss_mask: 0.8229  decode.d7.loss_dice: 0.7442  decode.d8.loss_cls: 0.1045  decode.d8.loss_mask: 0.8201  decode.d8.loss_dice: 0.7414
2024/04/12 19:22:47 - mmengine - INFO - per class results:
2024/04/12 19:22:47 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.05 | 98.74 | 97.99 | 97.99  |   97.24   | 98.74  |
| monolayer  | 86.34 | 91.15 | 92.67 | 92.67  |   94.24   | 91.15  |
|  bilayer   | 74.82 | 86.05 |  85.6 |  85.6  |   85.15   | 86.05  |
| multilayer | 86.84 | 92.47 | 92.96 | 92.96  |   93.46   | 92.47  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 19:22:47 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.5200  mIoU: 86.0200  mAcc: 92.1000  mDice: 92.3000  mFscore: 92.3000  mPrecision: 92.5200  mRecall: 92.1000  data_time: 0.0168  time: 0.2362
2024/04/12 19:24:43 - mmengine - INFO - Iter(train) [ 4100/20000]  base_lr: 9.5891e-05 lr: 9.5891e-06  eta: 5:09:30  time: 1.1629  data_time: 0.0115  memory: 7967  grad_norm: 167.0894  loss: 14.7623  decode.loss_cls: 0.0993  decode.loss_mask: 0.6598  decode.loss_dice: 0.6805  decode.d0.loss_cls: 0.1432  decode.d0.loss_mask: 0.7521  decode.d0.loss_dice: 0.7492  decode.d1.loss_cls: 0.1501  decode.d1.loss_mask: 0.6777  decode.d1.loss_dice: 0.7127  decode.d2.loss_cls: 0.1179  decode.d2.loss_mask: 0.6759  decode.d2.loss_dice: 0.6806  decode.d3.loss_cls: 0.0880  decode.d3.loss_mask: 0.6679  decode.d3.loss_dice: 0.6917  decode.d4.loss_cls: 0.1223  decode.d4.loss_mask: 0.6691  decode.d4.loss_dice: 0.6904  decode.d5.loss_cls: 0.0907  decode.d5.loss_mask: 0.6700  decode.d5.loss_dice: 0.6738  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.6642  decode.d6.loss_dice: 0.6732  decode.d7.loss_cls: 0.0954  decode.d7.loss_mask: 0.6665  decode.d7.loss_dice: 0.6709  decode.d8.loss_cls: 0.1063  decode.d8.loss_mask: 0.6647  decode.d8.loss_dice: 0.6852
2024/04/12 19:26:40 - mmengine - INFO - Iter(train) [ 4200/20000]  base_lr: 9.5791e-05 lr: 9.5791e-06  eta: 5:07:33  time: 1.1664  data_time: 0.0118  memory: 7967  grad_norm: 219.9626  loss: 18.7911  decode.loss_cls: 0.1838  decode.loss_mask: 0.7993  decode.loss_dice: 0.8734  decode.d0.loss_cls: 0.3206  decode.d0.loss_mask: 0.8559  decode.d0.loss_dice: 0.9713  decode.d1.loss_cls: 0.2417  decode.d1.loss_mask: 0.8228  decode.d1.loss_dice: 0.8849  decode.d2.loss_cls: 0.1851  decode.d2.loss_mask: 0.8256  decode.d2.loss_dice: 0.8532  decode.d3.loss_cls: 0.1479  decode.d3.loss_mask: 0.8142  decode.d3.loss_dice: 0.8412  decode.d4.loss_cls: 0.1174  decode.d4.loss_mask: 0.8301  decode.d4.loss_dice: 0.8484  decode.d5.loss_cls: 0.1332  decode.d5.loss_mask: 0.8334  decode.d5.loss_dice: 0.8585  decode.d6.loss_cls: 0.1744  decode.d6.loss_mask: 0.8254  decode.d6.loss_dice: 0.8292  decode.d7.loss_cls: 0.1653  decode.d7.loss_mask: 0.8221  decode.d7.loss_dice: 0.8531  decode.d8.loss_cls: 0.1510  decode.d8.loss_mask: 0.8299  decode.d8.loss_dice: 0.8989
2024/04/12 19:28:36 - mmengine - INFO - Iter(train) [ 4300/20000]  base_lr: 9.5691e-05 lr: 9.5691e-06  eta: 5:05:35  time: 1.1640  data_time: 0.0113  memory: 7967  grad_norm: 221.7565  loss: 19.8632  decode.loss_cls: 0.1656  decode.loss_mask: 0.9766  decode.loss_dice: 0.8396  decode.d0.loss_cls: 0.2128  decode.d0.loss_mask: 0.9975  decode.d0.loss_dice: 0.9193  decode.d1.loss_cls: 0.1767  decode.d1.loss_mask: 0.9455  decode.d1.loss_dice: 0.8057  decode.d2.loss_cls: 0.1692  decode.d2.loss_mask: 0.9593  decode.d2.loss_dice: 0.8297  decode.d3.loss_cls: 0.1664  decode.d3.loss_mask: 0.9473  decode.d3.loss_dice: 0.8254  decode.d4.loss_cls: 0.2135  decode.d4.loss_mask: 0.9780  decode.d4.loss_dice: 0.8405  decode.d5.loss_cls: 0.1907  decode.d5.loss_mask: 0.9528  decode.d5.loss_dice: 0.8305  decode.d6.loss_cls: 0.1935  decode.d6.loss_mask: 0.9412  decode.d6.loss_dice: 0.8549  decode.d7.loss_cls: 0.1851  decode.d7.loss_mask: 0.9418  decode.d7.loss_dice: 0.8458  decode.d8.loss_cls: 0.1708  decode.d8.loss_mask: 0.9433  decode.d8.loss_dice: 0.8440
2024/04/12 19:30:33 - mmengine - INFO - Iter(train) [ 4400/20000]  base_lr: 9.5590e-05 lr: 9.5590e-06  eta: 5:03:36  time: 1.1619  data_time: 0.0117  memory: 7963  grad_norm: 253.5435  loss: 16.5913  decode.loss_cls: 0.1293  decode.loss_mask: 0.7500  decode.loss_dice: 0.6969  decode.d0.loss_cls: 0.2776  decode.d0.loss_mask: 0.8019  decode.d0.loss_dice: 0.7618  decode.d1.loss_cls: 0.1700  decode.d1.loss_mask: 0.7994  decode.d1.loss_dice: 0.7605  decode.d2.loss_cls: 0.1389  decode.d2.loss_mask: 0.8061  decode.d2.loss_dice: 0.7692  decode.d3.loss_cls: 0.1443  decode.d3.loss_mask: 0.7929  decode.d3.loss_dice: 0.7360  decode.d4.loss_cls: 0.1508  decode.d4.loss_mask: 0.7612  decode.d4.loss_dice: 0.7103  decode.d5.loss_cls: 0.0940  decode.d5.loss_mask: 0.7785  decode.d5.loss_dice: 0.7309  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.7925  decode.d6.loss_dice: 0.7226  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 0.7925  decode.d7.loss_dice: 0.7061  decode.d8.loss_cls: 0.1106  decode.d8.loss_mask: 0.7830  decode.d8.loss_dice: 0.7194
2024/04/12 19:32:29 - mmengine - INFO - Iter(train) [ 4500/20000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 5:01:38  time: 1.1677  data_time: 0.0120  memory: 7971  grad_norm: 164.9187  loss: 13.8695  decode.loss_cls: 0.0614  decode.loss_mask: 0.6539  decode.loss_dice: 0.5847  decode.d0.loss_cls: 0.2037  decode.d0.loss_mask: 0.7250  decode.d0.loss_dice: 0.6314  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.6609  decode.d1.loss_dice: 0.6201  decode.d2.loss_cls: 0.0949  decode.d2.loss_mask: 0.6598  decode.d2.loss_dice: 0.6215  decode.d3.loss_cls: 0.1006  decode.d3.loss_mask: 0.6815  decode.d3.loss_dice: 0.6283  decode.d4.loss_cls: 0.0945  decode.d4.loss_mask: 0.6730  decode.d4.loss_dice: 0.5941  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.6706  decode.d5.loss_dice: 0.6158  decode.d6.loss_cls: 0.0968  decode.d6.loss_mask: 0.6797  decode.d6.loss_dice: 0.6196  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.6613  decode.d7.loss_dice: 0.6147  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.6601  decode.d8.loss_dice: 0.5951
2024/04/12 19:32:31 - mmengine - INFO - per class results:
2024/04/12 19:32:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.19 | 98.42 | 98.06 | 98.06  |    97.7   | 98.42  |
| monolayer  | 86.53 |  91.7 | 92.78 | 92.78  |   93.88   |  91.7  |
|  bilayer   | 75.01 | 87.95 | 85.72 | 85.72  |   83.61   | 87.95  |
| multilayer |  86.6 | 92.37 | 92.82 | 92.82  |   93.28   | 92.37  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 19:32:31 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.5600  mIoU: 86.0800  mAcc: 92.6100  mDice: 92.3400  mFscore: 92.3400  mPrecision: 92.1100  mRecall: 92.6100  data_time: 0.0136  time: 0.2332
2024/04/12 19:32:31 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful/best_mIoU_iter_3000.pth is removed
2024/04/12 19:32:32 - mmengine - INFO - The best checkpoint with 86.0800 mIoU at 4500 iter is saved to best_mIoU_iter_4500.pth.
2024/04/12 19:34:30 - mmengine - INFO - Iter(train) [ 4600/20000]  base_lr: 9.5389e-05 lr: 9.5389e-06  eta: 4:59:49  time: 1.1574  data_time: 0.0113  memory: 7967  grad_norm: 255.6838  loss: 15.5646  decode.loss_cls: 0.0759  decode.loss_mask: 0.7486  decode.loss_dice: 0.6975  decode.d0.loss_cls: 0.2516  decode.d0.loss_mask: 0.8074  decode.d0.loss_dice: 0.7598  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.7367  decode.d1.loss_dice: 0.6707  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 0.7731  decode.d2.loss_dice: 0.6790  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.7784  decode.d3.loss_dice: 0.6830  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.7505  decode.d4.loss_dice: 0.6665  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.7301  decode.d5.loss_dice: 0.6848  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.7403  decode.d6.loss_dice: 0.6903  decode.d7.loss_cls: 0.0946  decode.d7.loss_mask: 0.7465  decode.d7.loss_dice: 0.6719  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.7548  decode.d8.loss_dice: 0.6762
2024/04/12 19:36:26 - mmengine - INFO - Iter(train) [ 4700/20000]  base_lr: 9.5288e-05 lr: 9.5288e-06  eta: 4:57:50  time: 1.1592  data_time: 0.0113  memory: 7967  grad_norm: 227.0765  loss: 17.4533  decode.loss_cls: 0.0979  decode.loss_mask: 0.8175  decode.loss_dice: 0.8169  decode.d0.loss_cls: 0.2113  decode.d0.loss_mask: 0.9274  decode.d0.loss_dice: 0.9102  decode.d1.loss_cls: 0.1251  decode.d1.loss_mask: 0.8419  decode.d1.loss_dice: 0.8121  decode.d2.loss_cls: 0.1122  decode.d2.loss_mask: 0.8315  decode.d2.loss_dice: 0.8180  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.7928  decode.d3.loss_dice: 0.7757  decode.d4.loss_cls: 0.1063  decode.d4.loss_mask: 0.7873  decode.d4.loss_dice: 0.7676  decode.d5.loss_cls: 0.0906  decode.d5.loss_mask: 0.7829  decode.d5.loss_dice: 0.7773  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.7952  decode.d6.loss_dice: 0.7893  decode.d7.loss_cls: 0.1051  decode.d7.loss_mask: 0.8196  decode.d7.loss_dice: 0.8047  decode.d8.loss_cls: 0.0909  decode.d8.loss_mask: 0.8160  decode.d8.loss_dice: 0.8308
2024/04/12 19:38:23 - mmengine - INFO - Iter(train) [ 4800/20000]  base_lr: 9.5188e-05 lr: 9.5188e-06  eta: 4:55:52  time: 1.1657  data_time: 0.0126  memory: 7967  grad_norm: 268.6183  loss: 17.9525  decode.loss_cls: 0.0802  decode.loss_mask: 0.9264  decode.loss_dice: 0.7678  decode.d0.loss_cls: 0.2152  decode.d0.loss_mask: 0.9789  decode.d0.loss_dice: 0.8045  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.9351  decode.d1.loss_dice: 0.7483  decode.d2.loss_cls: 0.0966  decode.d2.loss_mask: 0.9508  decode.d2.loss_dice: 0.7572  decode.d3.loss_cls: 0.0996  decode.d3.loss_mask: 0.9507  decode.d3.loss_dice: 0.7489  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.9389  decode.d4.loss_dice: 0.7222  decode.d5.loss_cls: 0.0932  decode.d5.loss_mask: 0.9280  decode.d5.loss_dice: 0.7364  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.9282  decode.d6.loss_dice: 0.7558  decode.d7.loss_cls: 0.0946  decode.d7.loss_mask: 0.9361  decode.d7.loss_dice: 0.7630  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.9264  decode.d8.loss_dice: 0.7525
2024/04/12 19:40:19 - mmengine - INFO - Iter(train) [ 4900/20000]  base_lr: 9.5087e-05 lr: 9.5087e-06  eta: 4:53:54  time: 1.1635  data_time: 0.0113  memory: 7968  grad_norm: 172.0867  loss: 15.4762  decode.loss_cls: 0.1110  decode.loss_mask: 0.7284  decode.loss_dice: 0.6843  decode.d0.loss_cls: 0.1736  decode.d0.loss_mask: 0.7738  decode.d0.loss_dice: 0.7545  decode.d1.loss_cls: 0.1261  decode.d1.loss_mask: 0.7319  decode.d1.loss_dice: 0.7079  decode.d2.loss_cls: 0.1145  decode.d2.loss_mask: 0.7248  decode.d2.loss_dice: 0.6947  decode.d3.loss_cls: 0.1271  decode.d3.loss_mask: 0.7266  decode.d3.loss_dice: 0.6749  decode.d4.loss_cls: 0.1138  decode.d4.loss_mask: 0.7271  decode.d4.loss_dice: 0.6816  decode.d5.loss_cls: 0.1184  decode.d5.loss_mask: 0.7265  decode.d5.loss_dice: 0.6929  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.7274  decode.d6.loss_dice: 0.6498  decode.d7.loss_cls: 0.1186  decode.d7.loss_mask: 0.7262  decode.d7.loss_dice: 0.6746  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.7288  decode.d8.loss_dice: 0.6942
2024/04/12 19:42:15 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 19:42:15 - mmengine - INFO - Iter(train) [ 5000/20000]  base_lr: 9.4987e-05 lr: 9.4987e-06  eta: 4:51:56  time: 1.1604  data_time: 0.0118  memory: 7963  grad_norm: 229.1160  loss: 16.3014  decode.loss_cls: 0.0628  decode.loss_mask: 0.8473  decode.loss_dice: 0.6981  decode.d0.loss_cls: 0.1723  decode.d0.loss_mask: 0.9150  decode.d0.loss_dice: 0.7826  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.8374  decode.d1.loss_dice: 0.7032  decode.d2.loss_cls: 0.0814  decode.d2.loss_mask: 0.8294  decode.d2.loss_dice: 0.6937  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.8459  decode.d3.loss_dice: 0.7228  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.8435  decode.d4.loss_dice: 0.7097  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 0.8455  decode.d5.loss_dice: 0.7087  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.8314  decode.d6.loss_dice: 0.6800  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.8399  decode.d7.loss_dice: 0.6865  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.8394  decode.d8.loss_dice: 0.6974
2024/04/12 19:42:15 - mmengine - INFO - Saving checkpoint at 5000 iterations
2024/04/12 19:42:19 - mmengine - INFO - per class results:
2024/04/12 19:42:19 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.32 | 98.67 | 98.12 | 98.12  |   97.58   | 98.67  |
| monolayer  | 85.74 | 90.96 | 92.32 | 92.32  |   93.73   | 90.96  |
|  bilayer   | 71.92 |  87.6 | 83.67 | 83.67  |   80.08   |  87.6  |
| multilayer | 84.69 | 89.82 | 91.71 | 91.71  |   93.68   | 89.82  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 19:42:19 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.2800  mIoU: 84.6700  mAcc: 91.7600  mDice: 91.4600  mFscore: 91.4600  mPrecision: 91.2700  mRecall: 91.7600  data_time: 0.0105  time: 0.2311
2024/04/12 19:44:15 - mmengine - INFO - Iter(train) [ 5100/20000]  base_lr: 9.4886e-05 lr: 9.4886e-06  eta: 4:49:58  time: 1.1589  data_time: 0.0118  memory: 7967  grad_norm: 339.8826  loss: 16.5889  decode.loss_cls: 0.0916  decode.loss_mask: 0.8862  decode.loss_dice: 0.6637  decode.d0.loss_cls: 0.2641  decode.d0.loss_mask: 0.9184  decode.d0.loss_dice: 0.7256  decode.d1.loss_cls: 0.1541  decode.d1.loss_mask: 0.8484  decode.d1.loss_dice: 0.6491  decode.d2.loss_cls: 0.1023  decode.d2.loss_mask: 0.8990  decode.d2.loss_dice: 0.6477  decode.d3.loss_cls: 0.1000  decode.d3.loss_mask: 0.8820  decode.d3.loss_dice: 0.6447  decode.d4.loss_cls: 0.1110  decode.d4.loss_mask: 0.8855  decode.d4.loss_dice: 0.6286  decode.d5.loss_cls: 0.1148  decode.d5.loss_mask: 0.8818  decode.d5.loss_dice: 0.6139  decode.d6.loss_cls: 0.1133  decode.d6.loss_mask: 0.8848  decode.d6.loss_dice: 0.6370  decode.d7.loss_cls: 0.0881  decode.d7.loss_mask: 0.8767  decode.d7.loss_dice: 0.6568  decode.d8.loss_cls: 0.0859  decode.d8.loss_mask: 0.8740  decode.d8.loss_dice: 0.6596
2024/04/12 19:46:12 - mmengine - INFO - Iter(train) [ 5200/20000]  base_lr: 9.4786e-05 lr: 9.4786e-06  eta: 4:48:00  time: 1.1593  data_time: 0.0127  memory: 7968  grad_norm: 237.8282  loss: 17.2767  decode.loss_cls: 0.1369  decode.loss_mask: 0.8465  decode.loss_dice: 0.6950  decode.d0.loss_cls: 0.2730  decode.d0.loss_mask: 0.9260  decode.d0.loss_dice: 0.7234  decode.d1.loss_cls: 0.1691  decode.d1.loss_mask: 0.8809  decode.d1.loss_dice: 0.7213  decode.d2.loss_cls: 0.2100  decode.d2.loss_mask: 0.8841  decode.d2.loss_dice: 0.6984  decode.d3.loss_cls: 0.1425  decode.d3.loss_mask: 0.8720  decode.d3.loss_dice: 0.6983  decode.d4.loss_cls: 0.1354  decode.d4.loss_mask: 0.8673  decode.d4.loss_dice: 0.7026  decode.d5.loss_cls: 0.1395  decode.d5.loss_mask: 0.8463  decode.d5.loss_dice: 0.6812  decode.d6.loss_cls: 0.1152  decode.d6.loss_mask: 0.8404  decode.d6.loss_dice: 0.6817  decode.d7.loss_cls: 0.1109  decode.d7.loss_mask: 0.8569  decode.d7.loss_dice: 0.7125  decode.d8.loss_cls: 0.1227  decode.d8.loss_mask: 0.8768  decode.d8.loss_dice: 0.7097
2024/04/12 19:48:08 - mmengine - INFO - Iter(train) [ 5300/20000]  base_lr: 9.4685e-05 lr: 9.4685e-06  eta: 4:46:02  time: 1.1716  data_time: 0.0121  memory: 7967  grad_norm: 238.5368  loss: 14.9140  decode.loss_cls: 0.0648  decode.loss_mask: 0.7983  decode.loss_dice: 0.6359  decode.d0.loss_cls: 0.1764  decode.d0.loss_mask: 0.7947  decode.d0.loss_dice: 0.6851  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.7969  decode.d1.loss_dice: 0.6126  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.7930  decode.d2.loss_dice: 0.6125  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.7923  decode.d3.loss_dice: 0.6164  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.7885  decode.d4.loss_dice: 0.5846  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.7949  decode.d5.loss_dice: 0.6499  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.7866  decode.d6.loss_dice: 0.6075  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.7842  decode.d7.loss_dice: 0.6215  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.7978  decode.d8.loss_dice: 0.6209
2024/04/12 19:50:04 - mmengine - INFO - Iter(train) [ 5400/20000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 4:44:04  time: 1.1624  data_time: 0.0113  memory: 7967  grad_norm: 196.2574  loss: 16.4069  decode.loss_cls: 0.0774  decode.loss_mask: 0.8412  decode.loss_dice: 0.7192  decode.d0.loss_cls: 0.1975  decode.d0.loss_mask: 0.8778  decode.d0.loss_dice: 0.7636  decode.d1.loss_cls: 0.0495  decode.d1.loss_mask: 0.8349  decode.d1.loss_dice: 0.7125  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.8496  decode.d2.loss_dice: 0.7206  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.8313  decode.d3.loss_dice: 0.7092  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.8396  decode.d4.loss_dice: 0.7067  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.8335  decode.d5.loss_dice: 0.7158  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 0.8277  decode.d6.loss_dice: 0.7033  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.8331  decode.d7.loss_dice: 0.6968  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.8351  decode.d8.loss_dice: 0.7083
2024/04/12 19:52:01 - mmengine - INFO - Iter(train) [ 5500/20000]  base_lr: 9.4484e-05 lr: 9.4484e-06  eta: 4:42:06  time: 1.1681  data_time: 0.0120  memory: 7967  grad_norm: 214.3597  loss: 17.2036  decode.loss_cls: 0.0787  decode.loss_mask: 0.8517  decode.loss_dice: 0.8198  decode.d0.loss_cls: 0.2523  decode.d0.loss_mask: 0.8971  decode.d0.loss_dice: 0.8235  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.8358  decode.d1.loss_dice: 0.7668  decode.d2.loss_cls: 0.0852  decode.d2.loss_mask: 0.8377  decode.d2.loss_dice: 0.7540  decode.d3.loss_cls: 0.0667  decode.d3.loss_mask: 0.8424  decode.d3.loss_dice: 0.7668  decode.d4.loss_cls: 0.0915  decode.d4.loss_mask: 0.8318  decode.d4.loss_dice: 0.7530  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 0.8297  decode.d5.loss_dice: 0.7703  decode.d6.loss_cls: 0.0826  decode.d6.loss_mask: 0.8169  decode.d6.loss_dice: 0.7584  decode.d7.loss_cls: 0.0802  decode.d7.loss_mask: 0.8222  decode.d7.loss_dice: 0.7595  decode.d8.loss_cls: 0.0890  decode.d8.loss_mask: 0.8441  decode.d8.loss_dice: 0.7820
2024/04/12 19:52:03 - mmengine - INFO - per class results:
2024/04/12 19:52:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.48 | 98.43 | 98.21 | 98.21  |   97.99   | 98.43  |
| monolayer  | 86.41 | 92.75 | 92.71 | 92.71  |   92.67   | 92.75  |
|  bilayer   | 70.71 | 81.65 | 82.84 | 82.84  |   84.07   | 81.65  |
| multilayer | 87.94 | 92.83 | 93.58 | 93.58  |   94.34   | 92.83  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 19:52:03 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.5700  mIoU: 85.3900  mAcc: 91.4200  mDice: 91.8400  mFscore: 91.8400  mPrecision: 92.2700  mRecall: 91.4200  data_time: 0.0147  time: 0.2338
2024/04/12 19:53:59 - mmengine - INFO - Iter(train) [ 5600/20000]  base_lr: 9.4383e-05 lr: 9.4383e-06  eta: 4:40:08  time: 1.1623  data_time: 0.0124  memory: 7967  grad_norm: 235.4978  loss: 13.8220  decode.loss_cls: 0.0864  decode.loss_mask: 0.7073  decode.loss_dice: 0.5721  decode.d0.loss_cls: 0.1861  decode.d0.loss_mask: 0.7367  decode.d0.loss_dice: 0.6372  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.6955  decode.d1.loss_dice: 0.5921  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.7164  decode.d2.loss_dice: 0.6088  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.6920  decode.d3.loss_dice: 0.5888  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.7071  decode.d4.loss_dice: 0.5956  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.7033  decode.d5.loss_dice: 0.6071  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.6963  decode.d6.loss_dice: 0.6078  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.7085  decode.d7.loss_dice: 0.5856  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.7063  decode.d8.loss_dice: 0.5929
2024/04/12 19:55:55 - mmengine - INFO - Iter(train) [ 5700/20000]  base_lr: 9.4282e-05 lr: 9.4282e-06  eta: 4:38:10  time: 1.1660  data_time: 0.0115  memory: 7967  grad_norm: 296.8890  loss: 16.6387  decode.loss_cls: 0.0603  decode.loss_mask: 0.9176  decode.loss_dice: 0.6360  decode.d0.loss_cls: 0.3417  decode.d0.loss_mask: 0.9438  decode.d0.loss_dice: 0.6470  decode.d1.loss_cls: 0.1436  decode.d1.loss_mask: 0.9259  decode.d1.loss_dice: 0.6393  decode.d2.loss_cls: 0.1205  decode.d2.loss_mask: 0.8983  decode.d2.loss_dice: 0.6366  decode.d3.loss_cls: 0.0671  decode.d3.loss_mask: 0.9008  decode.d3.loss_dice: 0.6229  decode.d4.loss_cls: 0.0408  decode.d4.loss_mask: 0.9301  decode.d4.loss_dice: 0.6436  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.9258  decode.d5.loss_dice: 0.6406  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.9180  decode.d6.loss_dice: 0.6294  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.9383  decode.d7.loss_dice: 0.6410  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.9380  decode.d8.loss_dice: 0.6318
2024/04/12 19:57:51 - mmengine - INFO - Iter(train) [ 5800/20000]  base_lr: 9.4182e-05 lr: 9.4182e-06  eta: 4:36:12  time: 1.1617  data_time: 0.0126  memory: 7967  grad_norm: 227.4535  loss: 18.4470  decode.loss_cls: 0.1612  decode.loss_mask: 0.8496  decode.loss_dice: 0.7610  decode.d0.loss_cls: 0.3139  decode.d0.loss_mask: 0.9152  decode.d0.loss_dice: 0.8500  decode.d1.loss_cls: 0.2243  decode.d1.loss_mask: 0.8370  decode.d1.loss_dice: 0.7856  decode.d2.loss_cls: 0.2008  decode.d2.loss_mask: 0.8549  decode.d2.loss_dice: 0.7810  decode.d3.loss_cls: 0.1787  decode.d3.loss_mask: 0.8571  decode.d3.loss_dice: 0.7778  decode.d4.loss_cls: 0.2249  decode.d4.loss_mask: 0.8521  decode.d4.loss_dice: 0.7536  decode.d5.loss_cls: 0.2138  decode.d5.loss_mask: 0.8513  decode.d5.loss_dice: 0.7558  decode.d6.loss_cls: 0.1779  decode.d6.loss_mask: 0.8597  decode.d6.loss_dice: 0.7771  decode.d7.loss_cls: 0.1801  decode.d7.loss_mask: 0.8871  decode.d7.loss_dice: 0.7926  decode.d8.loss_cls: 0.1347  decode.d8.loss_mask: 0.8712  decode.d8.loss_dice: 0.7670
2024/04/12 19:59:47 - mmengine - INFO - Iter(train) [ 5900/20000]  base_lr: 9.4081e-05 lr: 9.4081e-06  eta: 4:34:14  time: 1.1575  data_time: 0.0114  memory: 7967  grad_norm: 202.8047  loss: 18.4588  decode.loss_cls: 0.1450  decode.loss_mask: 0.9435  decode.loss_dice: 0.7270  decode.d0.loss_cls: 0.2790  decode.d0.loss_mask: 0.9804  decode.d0.loss_dice: 0.7928  decode.d1.loss_cls: 0.1187  decode.d1.loss_mask: 0.9542  decode.d1.loss_dice: 0.7707  decode.d2.loss_cls: 0.1363  decode.d2.loss_mask: 0.9669  decode.d2.loss_dice: 0.7304  decode.d3.loss_cls: 0.1295  decode.d3.loss_mask: 0.9605  decode.d3.loss_dice: 0.7284  decode.d4.loss_cls: 0.1420  decode.d4.loss_mask: 0.9756  decode.d4.loss_dice: 0.7146  decode.d5.loss_cls: 0.1293  decode.d5.loss_mask: 0.9559  decode.d5.loss_dice: 0.7356  decode.d6.loss_cls: 0.1148  decode.d6.loss_mask: 0.9419  decode.d6.loss_dice: 0.7355  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.9653  decode.d7.loss_dice: 0.7637  decode.d8.loss_cls: 0.1397  decode.d8.loss_mask: 0.9427  decode.d8.loss_dice: 0.7170
2024/04/12 20:01:43 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 20:01:43 - mmengine - INFO - Iter(train) [ 6000/20000]  base_lr: 9.3980e-05 lr: 9.3980e-06  eta: 4:32:15  time: 1.1660  data_time: 0.0116  memory: 7963  grad_norm: 232.3481  loss: 16.1297  decode.loss_cls: 0.1735  decode.loss_mask: 0.7370  decode.loss_dice: 0.7131  decode.d0.loss_cls: 0.1858  decode.d0.loss_mask: 0.7577  decode.d0.loss_dice: 0.7806  decode.d1.loss_cls: 0.1200  decode.d1.loss_mask: 0.7348  decode.d1.loss_dice: 0.7563  decode.d2.loss_cls: 0.1326  decode.d2.loss_mask: 0.7356  decode.d2.loss_dice: 0.7396  decode.d3.loss_cls: 0.1496  decode.d3.loss_mask: 0.7200  decode.d3.loss_dice: 0.7154  decode.d4.loss_cls: 0.1159  decode.d4.loss_mask: 0.7372  decode.d4.loss_dice: 0.7213  decode.d5.loss_cls: 0.1418  decode.d5.loss_mask: 0.7307  decode.d5.loss_dice: 0.7322  decode.d6.loss_cls: 0.1474  decode.d6.loss_mask: 0.7330  decode.d6.loss_dice: 0.7030  decode.d7.loss_cls: 0.1542  decode.d7.loss_mask: 0.7330  decode.d7.loss_dice: 0.7214  decode.d8.loss_cls: 0.1772  decode.d8.loss_mask: 0.7207  decode.d8.loss_dice: 0.7089
2024/04/12 20:01:45 - mmengine - INFO - per class results:
2024/04/12 20:01:45 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.47 | 98.51 |  98.2 |  98.2  |    97.9   | 98.51  |
| monolayer  | 86.81 | 92.66 | 92.94 | 92.94  |   93.22   | 92.66  |
|  bilayer   | 72.35 | 85.83 | 83.95 | 83.95  |   82.16   | 85.83  |
| multilayer | 86.74 | 90.54 |  92.9 |  92.9  |   95.39   | 90.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 20:01:45 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.6100  mIoU: 85.5900  mAcc: 91.8800  mDice: 92.0000  mFscore: 92.0000  mPrecision: 92.1700  mRecall: 91.8800  data_time: 0.0155  time: 0.2349
2024/04/12 20:03:41 - mmengine - INFO - Iter(train) [ 6100/20000]  base_lr: 9.3880e-05 lr: 9.3880e-06  eta: 4:30:18  time: 1.1613  data_time: 0.0111  memory: 7963  grad_norm: 197.5401  loss: 14.3051  decode.loss_cls: 0.1334  decode.loss_mask: 0.5943  decode.loss_dice: 0.6555  decode.d0.loss_cls: 0.2510  decode.d0.loss_mask: 0.6328  decode.d0.loss_dice: 0.7185  decode.d1.loss_cls: 0.1642  decode.d1.loss_mask: 0.6016  decode.d1.loss_dice: 0.6707  decode.d2.loss_cls: 0.1556  decode.d2.loss_mask: 0.6110  decode.d2.loss_dice: 0.6868  decode.d3.loss_cls: 0.1476  decode.d3.loss_mask: 0.6004  decode.d3.loss_dice: 0.6646  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 0.6053  decode.d4.loss_dice: 0.6654  decode.d5.loss_cls: 0.1567  decode.d5.loss_mask: 0.6071  decode.d5.loss_dice: 0.6693  decode.d6.loss_cls: 0.1340  decode.d6.loss_mask: 0.6003  decode.d6.loss_dice: 0.6615  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 0.5978  decode.d7.loss_dice: 0.6692  decode.d8.loss_cls: 0.1291  decode.d8.loss_mask: 0.5927  decode.d8.loss_dice: 0.6620
2024/04/12 20:05:37 - mmengine - INFO - Iter(train) [ 6200/20000]  base_lr: 9.3779e-05 lr: 9.3779e-06  eta: 4:28:20  time: 1.1547  data_time: 0.0119  memory: 7965  grad_norm: 259.0994  loss: 16.7604  decode.loss_cls: 0.1138  decode.loss_mask: 0.8527  decode.loss_dice: 0.7043  decode.d0.loss_cls: 0.2621  decode.d0.loss_mask: 0.8788  decode.d0.loss_dice: 0.7359  decode.d1.loss_cls: 0.1361  decode.d1.loss_mask: 0.8605  decode.d1.loss_dice: 0.7126  decode.d2.loss_cls: 0.1307  decode.d2.loss_mask: 0.8526  decode.d2.loss_dice: 0.6929  decode.d3.loss_cls: 0.1325  decode.d3.loss_mask: 0.8327  decode.d3.loss_dice: 0.6967  decode.d4.loss_cls: 0.1269  decode.d4.loss_mask: 0.8231  decode.d4.loss_dice: 0.6689  decode.d5.loss_cls: 0.1162  decode.d5.loss_mask: 0.8405  decode.d5.loss_dice: 0.6905  decode.d6.loss_cls: 0.0963  decode.d6.loss_mask: 0.8347  decode.d6.loss_dice: 0.6848  decode.d7.loss_cls: 0.1215  decode.d7.loss_mask: 0.8419  decode.d7.loss_dice: 0.6730  decode.d8.loss_cls: 0.1087  decode.d8.loss_mask: 0.8592  decode.d8.loss_dice: 0.6792
2024/04/12 20:07:34 - mmengine - INFO - Iter(train) [ 6300/20000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 4:26:23  time: 1.1654  data_time: 0.0115  memory: 7968  grad_norm: 267.0100  loss: 18.0715  decode.loss_cls: 0.1912  decode.loss_mask: 0.8259  decode.loss_dice: 0.7512  decode.d0.loss_cls: 0.3259  decode.d0.loss_mask: 0.8350  decode.d0.loss_dice: 0.7779  decode.d1.loss_cls: 0.1603  decode.d1.loss_mask: 0.8621  decode.d1.loss_dice: 0.7396  decode.d2.loss_cls: 0.2302  decode.d2.loss_mask: 0.8505  decode.d2.loss_dice: 0.7699  decode.d3.loss_cls: 0.1544  decode.d3.loss_mask: 0.8813  decode.d3.loss_dice: 0.7621  decode.d4.loss_cls: 0.1796  decode.d4.loss_mask: 0.9011  decode.d4.loss_dice: 0.7675  decode.d5.loss_cls: 0.1475  decode.d5.loss_mask: 0.8696  decode.d5.loss_dice: 0.7405  decode.d6.loss_cls: 0.1526  decode.d6.loss_mask: 0.8461  decode.d6.loss_dice: 0.7607  decode.d7.loss_cls: 0.1986  decode.d7.loss_mask: 0.8496  decode.d7.loss_dice: 0.7585  decode.d8.loss_cls: 0.1983  decode.d8.loss_mask: 0.8272  decode.d8.loss_dice: 0.7567
2024/04/12 20:09:30 - mmengine - INFO - Iter(train) [ 6400/20000]  base_lr: 9.3578e-05 lr: 9.3578e-06  eta: 4:24:25  time: 1.1621  data_time: 0.0120  memory: 7963  grad_norm: 235.8178  loss: 13.9909  decode.loss_cls: 0.0208  decode.loss_mask: 0.7647  decode.loss_dice: 0.5900  decode.d0.loss_cls: 0.1133  decode.d0.loss_mask: 0.7867  decode.d0.loss_dice: 0.6144  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.7638  decode.d1.loss_dice: 0.5799  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.7722  decode.d2.loss_dice: 0.6045  decode.d3.loss_cls: 0.0209  decode.d3.loss_mask: 0.7593  decode.d3.loss_dice: 0.5940  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.7591  decode.d4.loss_dice: 0.5966  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.7628  decode.d5.loss_dice: 0.5908  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.7681  decode.d6.loss_dice: 0.5961  decode.d7.loss_cls: 0.0355  decode.d7.loss_mask: 0.7684  decode.d7.loss_dice: 0.5953  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.7623  decode.d8.loss_dice: 0.5956
2024/04/12 20:11:26 - mmengine - INFO - Iter(train) [ 6500/20000]  base_lr: 9.3477e-05 lr: 9.3477e-06  eta: 4:22:27  time: 1.1582  data_time: 0.0117  memory: 7967  grad_norm: 286.6892  loss: 11.7656  decode.loss_cls: 0.0460  decode.loss_mask: 0.5837  decode.loss_dice: 0.5144  decode.d0.loss_cls: 0.1223  decode.d0.loss_mask: 0.5966  decode.d0.loss_dice: 0.5336  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.6048  decode.d1.loss_dice: 0.5584  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.6161  decode.d2.loss_dice: 0.5536  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 0.6029  decode.d3.loss_dice: 0.5320  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.5995  decode.d4.loss_dice: 0.5395  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.5990  decode.d5.loss_dice: 0.5291  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.5996  decode.d6.loss_dice: 0.5314  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.5943  decode.d7.loss_dice: 0.5364  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.6067  decode.d8.loss_dice: 0.5453
2024/04/12 20:11:28 - mmengine - INFO - per class results:
2024/04/12 20:11:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.17 |  98.5 | 98.05 | 98.05  |    97.6   |  98.5  |
| monolayer  | 86.43 | 92.51 | 92.72 | 92.72  |   92.93   | 92.51  |
|  bilayer   |  73.9 | 85.11 | 84.99 | 84.99  |   84.87   | 85.11  |
| multilayer | 86.47 | 90.38 | 92.75 | 92.75  |   95.24   | 90.38  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 20:11:28 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.5100  mIoU: 85.7400  mAcc: 91.6300  mDice: 92.1300  mFscore: 92.1300  mPrecision: 92.6600  mRecall: 91.6300  data_time: 0.0138  time: 0.2328
2024/04/12 20:13:24 - mmengine - INFO - Iter(train) [ 6600/20000]  base_lr: 9.3376e-05 lr: 9.3376e-06  eta: 4:20:29  time: 1.1582  data_time: 0.0116  memory: 7968  grad_norm: 210.6025  loss: 14.5813  decode.loss_cls: 0.1004  decode.loss_mask: 0.7467  decode.loss_dice: 0.5793  decode.d0.loss_cls: 0.1444  decode.d0.loss_mask: 0.7890  decode.d0.loss_dice: 0.6435  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.7539  decode.d1.loss_dice: 0.6030  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 0.7624  decode.d2.loss_dice: 0.5716  decode.d3.loss_cls: 0.1292  decode.d3.loss_mask: 0.7365  decode.d3.loss_dice: 0.6208  decode.d4.loss_cls: 0.1196  decode.d4.loss_mask: 0.7311  decode.d4.loss_dice: 0.6221  decode.d5.loss_cls: 0.1134  decode.d5.loss_mask: 0.7287  decode.d5.loss_dice: 0.5925  decode.d6.loss_cls: 0.1052  decode.d6.loss_mask: 0.7267  decode.d6.loss_dice: 0.5809  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.7305  decode.d7.loss_dice: 0.6173  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.7321  decode.d8.loss_dice: 0.6153
2024/04/12 20:15:20 - mmengine - INFO - Iter(train) [ 6700/20000]  base_lr: 9.3275e-05 lr: 9.3275e-06  eta: 4:18:31  time: 1.1584  data_time: 0.0114  memory: 7971  grad_norm: 248.0191  loss: 16.1156  decode.loss_cls: 0.0903  decode.loss_mask: 0.8104  decode.loss_dice: 0.6754  decode.d0.loss_cls: 0.2103  decode.d0.loss_mask: 0.8237  decode.d0.loss_dice: 0.7166  decode.d1.loss_cls: 0.1231  decode.d1.loss_mask: 0.8184  decode.d1.loss_dice: 0.6763  decode.d2.loss_cls: 0.0951  decode.d2.loss_mask: 0.8294  decode.d2.loss_dice: 0.6972  decode.d3.loss_cls: 0.0969  decode.d3.loss_mask: 0.8124  decode.d3.loss_dice: 0.6880  decode.d4.loss_cls: 0.1112  decode.d4.loss_mask: 0.8093  decode.d4.loss_dice: 0.6609  decode.d5.loss_cls: 0.1051  decode.d5.loss_mask: 0.8159  decode.d5.loss_dice: 0.6710  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.8339  decode.d6.loss_dice: 0.6782  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.8219  decode.d7.loss_dice: 0.6920  decode.d8.loss_cls: 0.1180  decode.d8.loss_mask: 0.8174  decode.d8.loss_dice: 0.6734
2024/04/12 20:17:16 - mmengine - INFO - Iter(train) [ 6800/20000]  base_lr: 9.3175e-05 lr: 9.3175e-06  eta: 4:16:33  time: 1.1602  data_time: 0.0118  memory: 7967  grad_norm: 221.5034  loss: 15.6175  decode.loss_cls: 0.1434  decode.loss_mask: 0.7226  decode.loss_dice: 0.6765  decode.d0.loss_cls: 0.2045  decode.d0.loss_mask: 0.7574  decode.d0.loss_dice: 0.7393  decode.d1.loss_cls: 0.1356  decode.d1.loss_mask: 0.7528  decode.d1.loss_dice: 0.6849  decode.d2.loss_cls: 0.1480  decode.d2.loss_mask: 0.7320  decode.d2.loss_dice: 0.6707  decode.d3.loss_cls: 0.1655  decode.d3.loss_mask: 0.7218  decode.d3.loss_dice: 0.6675  decode.d4.loss_cls: 0.1530  decode.d4.loss_mask: 0.7271  decode.d4.loss_dice: 0.6587  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 0.7255  decode.d5.loss_dice: 0.6360  decode.d6.loss_cls: 0.1713  decode.d6.loss_mask: 0.7239  decode.d6.loss_dice: 0.6678  decode.d7.loss_cls: 0.1249  decode.d7.loss_mask: 0.7339  decode.d7.loss_dice: 0.6901  decode.d8.loss_cls: 0.1308  decode.d8.loss_mask: 0.7216  decode.d8.loss_dice: 0.6573
2024/04/12 20:19:12 - mmengine - INFO - Iter(train) [ 6900/20000]  base_lr: 9.3074e-05 lr: 9.3074e-06  eta: 4:14:35  time: 1.1561  data_time: 0.0113  memory: 7967  grad_norm: 218.6647  loss: 13.1417  decode.loss_cls: 0.0267  decode.loss_mask: 0.7308  decode.loss_dice: 0.5343  decode.d0.loss_cls: 0.1425  decode.d0.loss_mask: 0.7920  decode.d0.loss_dice: 0.6020  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.7229  decode.d1.loss_dice: 0.5179  decode.d2.loss_cls: 0.0349  decode.d2.loss_mask: 0.7217  decode.d2.loss_dice: 0.5097  decode.d3.loss_cls: 0.0272  decode.d3.loss_mask: 0.7488  decode.d3.loss_dice: 0.5364  decode.d4.loss_cls: 0.0398  decode.d4.loss_mask: 0.7330  decode.d4.loss_dice: 0.5272  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.7291  decode.d5.loss_dice: 0.5196  decode.d6.loss_cls: 0.0335  decode.d6.loss_mask: 0.7253  decode.d6.loss_dice: 0.5286  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.7243  decode.d7.loss_dice: 0.5256  decode.d8.loss_cls: 0.0274  decode.d8.loss_mask: 0.7283  decode.d8.loss_dice: 0.5272
2024/04/12 20:21:08 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 20:21:08 - mmengine - INFO - Iter(train) [ 7000/20000]  base_lr: 9.2973e-05 lr: 9.2973e-06  eta: 4:12:37  time: 1.1587  data_time: 0.0123  memory: 7967  grad_norm: 160.6300  loss: 13.1618  decode.loss_cls: 0.0328  decode.loss_mask: 0.6290  decode.loss_dice: 0.6096  decode.d0.loss_cls: 0.1549  decode.d0.loss_mask: 0.6735  decode.d0.loss_dice: 0.6322  decode.d1.loss_cls: 0.1014  decode.d1.loss_mask: 0.6443  decode.d1.loss_dice: 0.5982  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.6373  decode.d2.loss_dice: 0.5973  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.6417  decode.d3.loss_dice: 0.6359  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.6357  decode.d4.loss_dice: 0.5959  decode.d5.loss_cls: 0.0530  decode.d5.loss_mask: 0.6366  decode.d5.loss_dice: 0.6138  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.6364  decode.d6.loss_dice: 0.6183  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.6375  decode.d7.loss_dice: 0.6128  decode.d8.loss_cls: 0.0450  decode.d8.loss_mask: 0.6409  decode.d8.loss_dice: 0.6122
2024/04/12 20:21:10 - mmengine - INFO - per class results:
2024/04/12 20:21:10 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 95.97 | 98.42 | 97.94 | 97.94  |   97.47   | 98.42  |
| monolayer  | 80.36 | 91.57 | 89.11 | 89.11  |   86.78   | 91.57  |
|  bilayer   | 50.17 | 53.89 | 66.81 | 66.81  |    87.9   | 53.89  |
| multilayer | 86.88 |  92.6 | 92.98 | 92.98  |   93.36   |  92.6  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 20:21:10 - mmengine - INFO - Iter(val) [8/8]    aAcc: 93.8000  mIoU: 78.3500  mAcc: 84.1200  mDice: 86.7100  mFscore: 86.7100  mPrecision: 91.3800  mRecall: 84.1200  data_time: 0.0135  time: 0.2328
2024/04/12 20:23:06 - mmengine - INFO - Iter(train) [ 7100/20000]  base_lr: 9.2872e-05 lr: 9.2872e-06  eta: 4:10:40  time: 1.1569  data_time: 0.0122  memory: 7967  grad_norm: 267.4228  loss: 15.2065  decode.loss_cls: 0.1041  decode.loss_mask: 0.7465  decode.loss_dice: 0.6665  decode.d0.loss_cls: 0.2465  decode.d0.loss_mask: 0.7960  decode.d0.loss_dice: 0.6910  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.7443  decode.d1.loss_dice: 0.6330  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.7558  decode.d2.loss_dice: 0.6586  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.7469  decode.d3.loss_dice: 0.6697  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 0.7644  decode.d4.loss_dice: 0.6420  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 0.7500  decode.d5.loss_dice: 0.6637  decode.d6.loss_cls: 0.0905  decode.d6.loss_mask: 0.7557  decode.d6.loss_dice: 0.6347  decode.d7.loss_cls: 0.1343  decode.d7.loss_mask: 0.7512  decode.d7.loss_dice: 0.6338  decode.d8.loss_cls: 0.1064  decode.d8.loss_mask: 0.7448  decode.d8.loss_dice: 0.6344
2024/04/12 20:25:02 - mmengine - INFO - Iter(train) [ 7200/20000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 4:08:42  time: 1.1654  data_time: 0.0123  memory: 7968  grad_norm: 290.9027  loss: 16.6288  decode.loss_cls: 0.1372  decode.loss_mask: 0.8846  decode.loss_dice: 0.6364  decode.d0.loss_cls: 0.2439  decode.d0.loss_mask: 0.8865  decode.d0.loss_dice: 0.6450  decode.d1.loss_cls: 0.1331  decode.d1.loss_mask: 0.8533  decode.d1.loss_dice: 0.5946  decode.d2.loss_cls: 0.1479  decode.d2.loss_mask: 0.8654  decode.d2.loss_dice: 0.6134  decode.d3.loss_cls: 0.1452  decode.d3.loss_mask: 0.8818  decode.d3.loss_dice: 0.6243  decode.d4.loss_cls: 0.1450  decode.d4.loss_mask: 0.8750  decode.d4.loss_dice: 0.6121  decode.d5.loss_cls: 0.1884  decode.d5.loss_mask: 0.8634  decode.d5.loss_dice: 0.6040  decode.d6.loss_cls: 0.1673  decode.d6.loss_mask: 0.8850  decode.d6.loss_dice: 0.6120  decode.d7.loss_cls: 0.1466  decode.d7.loss_mask: 0.9210  decode.d7.loss_dice: 0.6195  decode.d8.loss_cls: 0.1506  decode.d8.loss_mask: 0.9278  decode.d8.loss_dice: 0.6182
2024/04/12 20:26:58 - mmengine - INFO - Iter(train) [ 7300/20000]  base_lr: 9.2670e-05 lr: 9.2670e-06  eta: 4:06:46  time: 1.1657  data_time: 0.0124  memory: 7971  grad_norm: 254.4038  loss: 17.4172  decode.loss_cls: 0.1127  decode.loss_mask: 0.9139  decode.loss_dice: 0.7002  decode.d0.loss_cls: 0.2219  decode.d0.loss_mask: 0.9397  decode.d0.loss_dice: 0.7423  decode.d1.loss_cls: 0.1559  decode.d1.loss_mask: 0.9005  decode.d1.loss_dice: 0.6776  decode.d2.loss_cls: 0.1435  decode.d2.loss_mask: 0.8875  decode.d2.loss_dice: 0.6883  decode.d3.loss_cls: 0.1209  decode.d3.loss_mask: 0.8959  decode.d3.loss_dice: 0.7199  decode.d4.loss_cls: 0.1407  decode.d4.loss_mask: 0.8956  decode.d4.loss_dice: 0.7291  decode.d5.loss_cls: 0.1232  decode.d5.loss_mask: 0.8798  decode.d5.loss_dice: 0.7225  decode.d6.loss_cls: 0.1257  decode.d6.loss_mask: 0.9160  decode.d6.loss_dice: 0.7004  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 0.8864  decode.d7.loss_dice: 0.6642  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 0.8958  decode.d8.loss_dice: 0.6787
2024/04/12 20:28:55 - mmengine - INFO - Iter(train) [ 7400/20000]  base_lr: 9.2570e-05 lr: 9.2570e-06  eta: 4:04:49  time: 1.1591  data_time: 0.0124  memory: 7963  grad_norm: 253.5834  loss: 12.5663  decode.loss_cls: 0.0603  decode.loss_mask: 0.6319  decode.loss_dice: 0.5353  decode.d0.loss_cls: 0.1618  decode.d0.loss_mask: 0.6920  decode.d0.loss_dice: 0.5650  decode.d1.loss_cls: 0.0869  decode.d1.loss_mask: 0.6419  decode.d1.loss_dice: 0.5393  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.6363  decode.d2.loss_dice: 0.5245  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.6364  decode.d3.loss_dice: 0.5164  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 0.6358  decode.d4.loss_dice: 0.5369  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.6308  decode.d5.loss_dice: 0.5376  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.6412  decode.d6.loss_dice: 0.5427  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.6269  decode.d7.loss_dice: 0.5148  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.6317  decode.d8.loss_dice: 0.5169
2024/04/12 20:30:51 - mmengine - INFO - Iter(train) [ 7500/20000]  base_lr: 9.2469e-05 lr: 9.2469e-06  eta: 4:02:52  time: 1.1636  data_time: 0.0109  memory: 7967  grad_norm: 269.9355  loss: 15.9149  decode.loss_cls: 0.1477  decode.loss_mask: 0.6782  decode.loss_dice: 0.7323  decode.d0.loss_cls: 0.1984  decode.d0.loss_mask: 0.7470  decode.d0.loss_dice: 0.7689  decode.d1.loss_cls: 0.1716  decode.d1.loss_mask: 0.7208  decode.d1.loss_dice: 0.6958  decode.d2.loss_cls: 0.1438  decode.d2.loss_mask: 0.7315  decode.d2.loss_dice: 0.7490  decode.d3.loss_cls: 0.1652  decode.d3.loss_mask: 0.6885  decode.d3.loss_dice: 0.7389  decode.d4.loss_cls: 0.1006  decode.d4.loss_mask: 0.6799  decode.d4.loss_dice: 0.7453  decode.d5.loss_cls: 0.1415  decode.d5.loss_mask: 0.6867  decode.d5.loss_dice: 0.7136  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 0.7181  decode.d6.loss_dice: 0.7406  decode.d7.loss_cls: 0.1701  decode.d7.loss_mask: 0.7376  decode.d7.loss_dice: 0.7485  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 0.6819  decode.d8.loss_dice: 0.6886
2024/04/12 20:30:51 - mmengine - INFO - Saving checkpoint at 7500 iterations
2024/04/12 20:30:55 - mmengine - INFO - per class results:
2024/04/12 20:30:55 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.18 | 98.19 | 98.05 | 98.05  |   97.91   | 98.19  |
| monolayer  | 86.09 | 91.37 | 92.52 | 92.52  |   93.71   | 91.37  |
|  bilayer   | 76.26 | 88.59 | 86.53 | 86.53  |   84.57   | 88.59  |
| multilayer | 85.68 | 93.63 | 92.29 | 92.29  |   90.97   | 93.63  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 20:30:55 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.4800  mIoU: 86.0500  mAcc: 92.9500  mDice: 92.3500  mFscore: 92.3500  mPrecision: 91.7900  mRecall: 92.9500  data_time: 0.0092  time: 0.2298
2024/04/12 20:32:51 - mmengine - INFO - Iter(train) [ 7600/20000]  base_lr: 9.2368e-05 lr: 9.2368e-06  eta: 4:00:55  time: 1.1577  data_time: 0.0113  memory: 7967  grad_norm: 326.3742  loss: 20.7359  decode.loss_cls: 0.2547  decode.loss_mask: 0.9989  decode.loss_dice: 0.7534  decode.d0.loss_cls: 0.4630  decode.d0.loss_mask: 1.0059  decode.d0.loss_dice: 0.7478  decode.d1.loss_cls: 0.3309  decode.d1.loss_mask: 1.0338  decode.d1.loss_dice: 0.7690  decode.d2.loss_cls: 0.3038  decode.d2.loss_mask: 1.0055  decode.d2.loss_dice: 0.7712  decode.d3.loss_cls: 0.3294  decode.d3.loss_mask: 0.9944  decode.d3.loss_dice: 0.7585  decode.d4.loss_cls: 0.3117  decode.d4.loss_mask: 1.0068  decode.d4.loss_dice: 0.7490  decode.d5.loss_cls: 0.2641  decode.d5.loss_mask: 1.0353  decode.d5.loss_dice: 0.7659  decode.d6.loss_cls: 0.2525  decode.d6.loss_mask: 1.0207  decode.d6.loss_dice: 0.7441  decode.d7.loss_cls: 0.2393  decode.d7.loss_mask: 1.0066  decode.d7.loss_dice: 0.7727  decode.d8.loss_cls: 0.2457  decode.d8.loss_mask: 1.0372  decode.d8.loss_dice: 0.7638
2024/04/12 20:34:47 - mmengine - INFO - Iter(train) [ 7700/20000]  base_lr: 9.2267e-05 lr: 9.2267e-06  eta: 3:58:58  time: 1.1627  data_time: 0.0108  memory: 7967  grad_norm: 300.5315  loss: 16.3636  decode.loss_cls: 0.0793  decode.loss_mask: 0.7648  decode.loss_dice: 0.7250  decode.d0.loss_cls: 0.2541  decode.d0.loss_mask: 0.7896  decode.d0.loss_dice: 0.7845  decode.d1.loss_cls: 0.1136  decode.d1.loss_mask: 0.7847  decode.d1.loss_dice: 0.7823  decode.d2.loss_cls: 0.1310  decode.d2.loss_mask: 0.7477  decode.d2.loss_dice: 0.7297  decode.d3.loss_cls: 0.1080  decode.d3.loss_mask: 0.7755  decode.d3.loss_dice: 0.7469  decode.d4.loss_cls: 0.1147  decode.d4.loss_mask: 0.7722  decode.d4.loss_dice: 0.7248  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.7848  decode.d5.loss_dice: 0.7663  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.7710  decode.d6.loss_dice: 0.7354  decode.d7.loss_cls: 0.0883  decode.d7.loss_mask: 0.7732  decode.d7.loss_dice: 0.7428  decode.d8.loss_cls: 0.1120  decode.d8.loss_mask: 0.7675  decode.d8.loss_dice: 0.7140
2024/04/12 20:36:44 - mmengine - INFO - Iter(train) [ 7800/20000]  base_lr: 9.2166e-05 lr: 9.2166e-06  eta: 3:57:01  time: 1.1529  data_time: 0.0113  memory: 7963  grad_norm: 199.6597  loss: 16.2371  decode.loss_cls: 0.1351  decode.loss_mask: 0.8295  decode.loss_dice: 0.6434  decode.d0.loss_cls: 0.2795  decode.d0.loss_mask: 0.8582  decode.d0.loss_dice: 0.6920  decode.d1.loss_cls: 0.1442  decode.d1.loss_mask: 0.8251  decode.d1.loss_dice: 0.6474  decode.d2.loss_cls: 0.1175  decode.d2.loss_mask: 0.8059  decode.d2.loss_dice: 0.6233  decode.d3.loss_cls: 0.1412  decode.d3.loss_mask: 0.8195  decode.d3.loss_dice: 0.6315  decode.d4.loss_cls: 0.1256  decode.d4.loss_mask: 0.8224  decode.d4.loss_dice: 0.6288  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 0.8156  decode.d5.loss_dice: 0.6648  decode.d6.loss_cls: 0.1139  decode.d6.loss_mask: 0.8335  decode.d6.loss_dice: 0.6727  decode.d7.loss_cls: 0.1299  decode.d7.loss_mask: 0.8213  decode.d7.loss_dice: 0.6688  decode.d8.loss_cls: 0.1290  decode.d8.loss_mask: 0.8378  decode.d8.loss_dice: 0.6589
2024/04/12 20:38:40 - mmengine - INFO - Iter(train) [ 7900/20000]  base_lr: 9.2065e-05 lr: 9.2065e-06  eta: 3:55:04  time: 1.1605  data_time: 0.0120  memory: 7967  grad_norm: 228.5114  loss: 13.8626  decode.loss_cls: 0.1228  decode.loss_mask: 0.6633  decode.loss_dice: 0.6166  decode.d0.loss_cls: 0.2080  decode.d0.loss_mask: 0.6614  decode.d0.loss_dice: 0.6496  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 0.6535  decode.d1.loss_dice: 0.6281  decode.d2.loss_cls: 0.1148  decode.d2.loss_mask: 0.6863  decode.d2.loss_dice: 0.6033  decode.d3.loss_cls: 0.1033  decode.d3.loss_mask: 0.6420  decode.d3.loss_dice: 0.5854  decode.d4.loss_cls: 0.0993  decode.d4.loss_mask: 0.6562  decode.d4.loss_dice: 0.5992  decode.d5.loss_cls: 0.1060  decode.d5.loss_mask: 0.6467  decode.d5.loss_dice: 0.5994  decode.d6.loss_cls: 0.1280  decode.d6.loss_mask: 0.6155  decode.d6.loss_dice: 0.6003  decode.d7.loss_cls: 0.1202  decode.d7.loss_mask: 0.6461  decode.d7.loss_dice: 0.5975  decode.d8.loss_cls: 0.1090  decode.d8.loss_mask: 0.6879  decode.d8.loss_dice: 0.6104
2024/04/12 20:40:36 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 20:40:36 - mmengine - INFO - Iter(train) [ 8000/20000]  base_lr: 9.1964e-05 lr: 9.1964e-06  eta: 3:53:07  time: 1.1637  data_time: 0.0116  memory: 7963  grad_norm: 274.1649  loss: 12.5580  decode.loss_cls: 0.0562  decode.loss_mask: 0.6488  decode.loss_dice: 0.5110  decode.d0.loss_cls: 0.1559  decode.d0.loss_mask: 0.6864  decode.d0.loss_dice: 0.5730  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.6504  decode.d1.loss_dice: 0.5224  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.6534  decode.d2.loss_dice: 0.5146  decode.d3.loss_cls: 0.0750  decode.d3.loss_mask: 0.6703  decode.d3.loss_dice: 0.5179  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.6608  decode.d4.loss_dice: 0.5039  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.6663  decode.d5.loss_dice: 0.5237  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.6555  decode.d6.loss_dice: 0.5048  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.6566  decode.d7.loss_dice: 0.4985  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.6554  decode.d8.loss_dice: 0.5226
2024/04/12 20:40:38 - mmengine - INFO - per class results:
2024/04/12 20:40:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 95.56 | 97.02 | 97.73 | 97.73  |   98.45   | 97.02  |
| monolayer  | 81.29 | 93.47 | 89.68 | 89.68  |   86.19   | 93.47  |
|  bilayer   |  51.6 | 60.14 | 68.07 | 68.07  |   78.43   | 60.14  |
| multilayer | 86.66 | 91.76 | 92.85 | 92.85  |   93.97   | 91.76  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 20:40:38 - mmengine - INFO - Iter(val) [8/8]    aAcc: 93.7300  mIoU: 78.7800  mAcc: 85.6000  mDice: 87.0800  mFscore: 87.0800  mPrecision: 89.2600  mRecall: 85.6000  data_time: 0.0137  time: 0.2332
2024/04/12 20:42:34 - mmengine - INFO - Iter(train) [ 8100/20000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 3:51:10  time: 1.1667  data_time: 0.0114  memory: 7967  grad_norm: 211.1149  loss: 12.6477  decode.loss_cls: 0.1200  decode.loss_mask: 0.5472  decode.loss_dice: 0.5577  decode.d0.loss_cls: 0.3230  decode.d0.loss_mask: 0.5994  decode.d0.loss_dice: 0.6028  decode.d1.loss_cls: 0.1487  decode.d1.loss_mask: 0.5640  decode.d1.loss_dice: 0.5534  decode.d2.loss_cls: 0.1323  decode.d2.loss_mask: 0.5427  decode.d2.loss_dice: 0.5622  decode.d3.loss_cls: 0.1165  decode.d3.loss_mask: 0.5441  decode.d3.loss_dice: 0.5606  decode.d4.loss_cls: 0.1320  decode.d4.loss_mask: 0.5448  decode.d4.loss_dice: 0.5537  decode.d5.loss_cls: 0.1014  decode.d5.loss_mask: 0.5685  decode.d5.loss_dice: 0.5690  decode.d6.loss_cls: 0.1031  decode.d6.loss_mask: 0.5611  decode.d6.loss_dice: 0.5618  decode.d7.loss_cls: 0.1032  decode.d7.loss_mask: 0.5460  decode.d7.loss_dice: 0.5806  decode.d8.loss_cls: 0.1033  decode.d8.loss_mask: 0.5644  decode.d8.loss_dice: 0.5804
2024/04/12 20:44:31 - mmengine - INFO - Iter(train) [ 8200/20000]  base_lr: 9.1762e-05 lr: 9.1762e-06  eta: 3:49:13  time: 1.1603  data_time: 0.0110  memory: 7967  grad_norm: 185.5637  loss: 11.6115  decode.loss_cls: 0.0713  decode.loss_mask: 0.5906  decode.loss_dice: 0.4726  decode.d0.loss_cls: 0.2092  decode.d0.loss_mask: 0.5860  decode.d0.loss_dice: 0.5077  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 0.5796  decode.d1.loss_dice: 0.5108  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.5797  decode.d2.loss_dice: 0.4939  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.5866  decode.d3.loss_dice: 0.4807  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.5855  decode.d4.loss_dice: 0.4579  decode.d5.loss_cls: 0.0929  decode.d5.loss_mask: 0.5968  decode.d5.loss_dice: 0.4802  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.5991  decode.d6.loss_dice: 0.4727  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.5922  decode.d7.loss_dice: 0.4530  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.5848  decode.d8.loss_dice: 0.4668
2024/04/12 20:46:27 - mmengine - INFO - Iter(train) [ 8300/20000]  base_lr: 9.1661e-05 lr: 9.1661e-06  eta: 3:47:16  time: 1.1681  data_time: 0.0131  memory: 7964  grad_norm: 216.2827  loss: 12.3825  decode.loss_cls: 0.0932  decode.loss_mask: 0.6166  decode.loss_dice: 0.5129  decode.d0.loss_cls: 0.1534  decode.d0.loss_mask: 0.6657  decode.d0.loss_dice: 0.5202  decode.d1.loss_cls: 0.0605  decode.d1.loss_mask: 0.6275  decode.d1.loss_dice: 0.5385  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 0.6195  decode.d2.loss_dice: 0.5339  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 0.6187  decode.d3.loss_dice: 0.4968  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.6210  decode.d4.loss_dice: 0.5185  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.6382  decode.d5.loss_dice: 0.5193  decode.d6.loss_cls: 0.0794  decode.d6.loss_mask: 0.6431  decode.d6.loss_dice: 0.5097  decode.d7.loss_cls: 0.0959  decode.d7.loss_mask: 0.6238  decode.d7.loss_dice: 0.5186  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.6136  decode.d8.loss_dice: 0.5135
2024/04/12 20:48:23 - mmengine - INFO - Iter(train) [ 8400/20000]  base_lr: 9.1560e-05 lr: 9.1560e-06  eta: 3:45:19  time: 1.1638  data_time: 0.0111  memory: 7967  grad_norm: 271.3329  loss: 12.5376  decode.loss_cls: 0.1087  decode.loss_mask: 0.6194  decode.loss_dice: 0.5366  decode.d0.loss_cls: 0.1990  decode.d0.loss_mask: 0.6073  decode.d0.loss_dice: 0.5638  decode.d1.loss_cls: 0.1388  decode.d1.loss_mask: 0.5943  decode.d1.loss_dice: 0.5161  decode.d2.loss_cls: 0.1077  decode.d2.loss_mask: 0.6106  decode.d2.loss_dice: 0.5028  decode.d3.loss_cls: 0.1464  decode.d3.loss_mask: 0.5968  decode.d3.loss_dice: 0.4912  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.6083  decode.d4.loss_dice: 0.5183  decode.d5.loss_cls: 0.1135  decode.d5.loss_mask: 0.6104  decode.d5.loss_dice: 0.4995  decode.d6.loss_cls: 0.1000  decode.d6.loss_mask: 0.6242  decode.d6.loss_dice: 0.5313  decode.d7.loss_cls: 0.1003  decode.d7.loss_mask: 0.6257  decode.d7.loss_dice: 0.5054  decode.d8.loss_cls: 0.1015  decode.d8.loss_mask: 0.6292  decode.d8.loss_dice: 0.5192
2024/04/12 20:50:20 - mmengine - INFO - Iter(train) [ 8500/20000]  base_lr: 9.1459e-05 lr: 9.1459e-06  eta: 3:43:22  time: 1.1633  data_time: 0.0114  memory: 7967  grad_norm: 201.3657  loss: 14.8924  decode.loss_cls: 0.1184  decode.loss_mask: 0.7002  decode.loss_dice: 0.6083  decode.d0.loss_cls: 0.3030  decode.d0.loss_mask: 0.7293  decode.d0.loss_dice: 0.6613  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.7172  decode.d1.loss_dice: 0.6303  decode.d2.loss_cls: 0.1187  decode.d2.loss_mask: 0.7230  decode.d2.loss_dice: 0.6391  decode.d3.loss_cls: 0.1340  decode.d3.loss_mask: 0.7116  decode.d3.loss_dice: 0.6326  decode.d4.loss_cls: 0.1813  decode.d4.loss_mask: 0.7280  decode.d4.loss_dice: 0.6374  decode.d5.loss_cls: 0.0863  decode.d5.loss_mask: 0.7344  decode.d5.loss_dice: 0.6274  decode.d6.loss_cls: 0.1010  decode.d6.loss_mask: 0.6998  decode.d6.loss_dice: 0.6050  decode.d7.loss_cls: 0.1608  decode.d7.loss_mask: 0.7142  decode.d7.loss_dice: 0.6170  decode.d8.loss_cls: 0.1211  decode.d8.loss_mask: 0.7154  decode.d8.loss_dice: 0.6277
2024/04/12 20:50:22 - mmengine - INFO - per class results:
2024/04/12 20:50:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 95.35 | 98.76 | 97.62 | 97.62  |   96.51   | 98.76  |
| monolayer  | 80.29 | 88.91 | 89.07 | 89.07  |   89.22   | 88.91  |
|  bilayer   | 54.18 | 62.44 | 70.28 | 70.28  |   80.37   | 62.44  |
| multilayer | 86.09 | 91.73 | 92.53 | 92.53  |   93.34   | 91.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 20:50:22 - mmengine - INFO - Iter(val) [8/8]    aAcc: 93.6500  mIoU: 78.9800  mAcc: 85.4600  mDice: 87.3700  mFscore: 87.3700  mPrecision: 89.8600  mRecall: 85.4600  data_time: 0.0133  time: 0.2335
2024/04/12 20:52:18 - mmengine - INFO - Iter(train) [ 8600/20000]  base_lr: 9.1358e-05 lr: 9.1358e-06  eta: 3:41:25  time: 1.1589  data_time: 0.0117  memory: 7967  grad_norm: 194.5676  loss: 11.7195  decode.loss_cls: 0.0811  decode.loss_mask: 0.5947  decode.loss_dice: 0.4922  decode.d0.loss_cls: 0.1352  decode.d0.loss_mask: 0.6387  decode.d0.loss_dice: 0.5229  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 0.6144  decode.d1.loss_dice: 0.5068  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.5979  decode.d2.loss_dice: 0.4988  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.6030  decode.d3.loss_dice: 0.4831  decode.d4.loss_cls: 0.0514  decode.d4.loss_mask: 0.6110  decode.d4.loss_dice: 0.4911  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.6111  decode.d5.loss_dice: 0.4812  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.6115  decode.d6.loss_dice: 0.5060  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.5950  decode.d7.loss_dice: 0.5039  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.5889  decode.d8.loss_dice: 0.4840
2024/04/12 20:54:14 - mmengine - INFO - Iter(train) [ 8700/20000]  base_lr: 9.1257e-05 lr: 9.1257e-06  eta: 3:39:28  time: 1.1559  data_time: 0.0122  memory: 7967  grad_norm: 218.9530  loss: 13.7618  decode.loss_cls: 0.0747  decode.loss_mask: 0.7586  decode.loss_dice: 0.5599  decode.d0.loss_cls: 0.1059  decode.d0.loss_mask: 0.7668  decode.d0.loss_dice: 0.5800  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.7626  decode.d1.loss_dice: 0.5681  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.7642  decode.d2.loss_dice: 0.5515  decode.d3.loss_cls: 0.0301  decode.d3.loss_mask: 0.7567  decode.d3.loss_dice: 0.5685  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.7619  decode.d4.loss_dice: 0.5596  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.7593  decode.d5.loss_dice: 0.5537  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.7630  decode.d6.loss_dice: 0.5668  decode.d7.loss_cls: 0.0236  decode.d7.loss_mask: 0.7785  decode.d7.loss_dice: 0.5781  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.7595  decode.d8.loss_dice: 0.5709
2024/04/12 20:56:10 - mmengine - INFO - Iter(train) [ 8800/20000]  base_lr: 9.1156e-05 lr: 9.1156e-06  eta: 3:37:31  time: 1.1585  data_time: 0.0121  memory: 7967  grad_norm: 219.6176  loss: 17.0213  decode.loss_cls: 0.1624  decode.loss_mask: 0.7400  decode.loss_dice: 0.7686  decode.d0.loss_cls: 0.2783  decode.d0.loss_mask: 0.7202  decode.d0.loss_dice: 0.8169  decode.d1.loss_cls: 0.2056  decode.d1.loss_mask: 0.7155  decode.d1.loss_dice: 0.7909  decode.d2.loss_cls: 0.1737  decode.d2.loss_mask: 0.7420  decode.d2.loss_dice: 0.7592  decode.d3.loss_cls: 0.1457  decode.d3.loss_mask: 0.7402  decode.d3.loss_dice: 0.7786  decode.d4.loss_cls: 0.1295  decode.d4.loss_mask: 0.7555  decode.d4.loss_dice: 0.8077  decode.d5.loss_cls: 0.1418  decode.d5.loss_mask: 0.7553  decode.d5.loss_dice: 0.7932  decode.d6.loss_cls: 0.1851  decode.d6.loss_mask: 0.7602  decode.d6.loss_dice: 0.7738  decode.d7.loss_cls: 0.1633  decode.d7.loss_mask: 0.7521  decode.d7.loss_dice: 0.7650  decode.d8.loss_cls: 0.1692  decode.d8.loss_mask: 0.7476  decode.d8.loss_dice: 0.7840
2024/04/12 20:58:07 - mmengine - INFO - Iter(train) [ 8900/20000]  base_lr: 9.1055e-05 lr: 9.1055e-06  eta: 3:35:35  time: 1.1664  data_time: 0.0117  memory: 7967  grad_norm: 219.0952  loss: 11.5805  decode.loss_cls: 0.0584  decode.loss_mask: 0.6064  decode.loss_dice: 0.5034  decode.d0.loss_cls: 0.2018  decode.d0.loss_mask: 0.5986  decode.d0.loss_dice: 0.5225  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.5998  decode.d1.loss_dice: 0.5031  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 0.5762  decode.d2.loss_dice: 0.4997  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.5789  decode.d3.loss_dice: 0.4790  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.5875  decode.d4.loss_dice: 0.4894  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.5716  decode.d5.loss_dice: 0.4771  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.5674  decode.d6.loss_dice: 0.5029  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.5802  decode.d7.loss_dice: 0.4907  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.5879  decode.d8.loss_dice: 0.4961
2024/04/12 21:00:03 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 21:00:03 - mmengine - INFO - Iter(train) [ 9000/20000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 3:33:38  time: 1.1657  data_time: 0.0114  memory: 7967  grad_norm: 254.4764  loss: 12.3877  decode.loss_cls: 0.0354  decode.loss_mask: 0.6228  decode.loss_dice: 0.5823  decode.d0.loss_cls: 0.1266  decode.d0.loss_mask: 0.6418  decode.d0.loss_dice: 0.5633  decode.d1.loss_cls: 0.0331  decode.d1.loss_mask: 0.6151  decode.d1.loss_dice: 0.5738  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 0.6171  decode.d2.loss_dice: 0.5713  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.6021  decode.d3.loss_dice: 0.5495  decode.d4.loss_cls: 0.0278  decode.d4.loss_mask: 0.6253  decode.d4.loss_dice: 0.5747  decode.d5.loss_cls: 0.0584  decode.d5.loss_mask: 0.6160  decode.d5.loss_dice: 0.5724  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.6067  decode.d6.loss_dice: 0.5811  decode.d7.loss_cls: 0.0383  decode.d7.loss_mask: 0.6109  decode.d7.loss_dice: 0.5691  decode.d8.loss_cls: 0.0273  decode.d8.loss_mask: 0.6166  decode.d8.loss_dice: 0.5768
2024/04/12 21:00:05 - mmengine - INFO - per class results:
2024/04/12 21:00:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background |  95.6 | 98.51 | 97.75 | 97.75  |   97.01   | 98.51  |
| monolayer  | 81.13 | 89.91 | 89.58 | 89.58  |   89.25   | 89.91  |
|  bilayer   | 54.42 | 61.77 | 70.48 | 70.48  |   82.06   | 61.77  |
| multilayer |  85.4 | 92.94 | 92.13 | 92.13  |   91.33   | 92.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 21:00:05 - mmengine - INFO - Iter(val) [8/8]    aAcc: 93.8400  mIoU: 79.1400  mAcc: 85.7800  mDice: 87.4900  mFscore: 87.4900  mPrecision: 89.9100  mRecall: 85.7800  data_time: 0.0156  time: 0.2355
2024/04/12 21:02:02 - mmengine - INFO - Iter(train) [ 9100/20000]  base_lr: 9.0853e-05 lr: 9.0853e-06  eta: 3:31:42  time: 1.1652  data_time: 0.0136  memory: 7968  grad_norm: 147.6292  loss: 11.1551  decode.loss_cls: 0.0741  decode.loss_mask: 0.5461  decode.loss_dice: 0.4528  decode.d0.loss_cls: 0.1660  decode.d0.loss_mask: 0.5780  decode.d0.loss_dice: 0.5349  decode.d1.loss_cls: 0.0647  decode.d1.loss_mask: 0.5441  decode.d1.loss_dice: 0.4807  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.5469  decode.d2.loss_dice: 0.4776  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.5433  decode.d3.loss_dice: 0.4823  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 0.5393  decode.d4.loss_dice: 0.4867  decode.d5.loss_cls: 0.0872  decode.d5.loss_mask: 0.5484  decode.d5.loss_dice: 0.4881  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.5399  decode.d6.loss_dice: 0.4761  decode.d7.loss_cls: 0.0826  decode.d7.loss_mask: 0.5385  decode.d7.loss_dice: 0.4581  decode.d8.loss_cls: 0.0849  decode.d8.loss_mask: 0.5407  decode.d8.loss_dice: 0.4525
2024/04/12 21:03:58 - mmengine - INFO - Iter(train) [ 9200/20000]  base_lr: 9.0752e-05 lr: 9.0752e-06  eta: 3:29:45  time: 1.1652  data_time: 0.0117  memory: 7968  grad_norm: 329.2744  loss: 11.8370  decode.loss_cls: 0.0374  decode.loss_mask: 0.5814  decode.loss_dice: 0.5559  decode.d0.loss_cls: 0.1465  decode.d0.loss_mask: 0.6291  decode.d0.loss_dice: 0.5868  decode.d1.loss_cls: 0.0394  decode.d1.loss_mask: 0.5851  decode.d1.loss_dice: 0.5677  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.5829  decode.d2.loss_dice: 0.5424  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.5819  decode.d3.loss_dice: 0.5547  decode.d4.loss_cls: 0.0355  decode.d4.loss_mask: 0.5768  decode.d4.loss_dice: 0.5433  decode.d5.loss_cls: 0.0346  decode.d5.loss_mask: 0.5789  decode.d5.loss_dice: 0.5409  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.5673  decode.d6.loss_dice: 0.5453  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 0.5739  decode.d7.loss_dice: 0.5268  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.5760  decode.d8.loss_dice: 0.5431
2024/04/12 21:05:55 - mmengine - INFO - Iter(train) [ 9300/20000]  base_lr: 9.0651e-05 lr: 9.0651e-06  eta: 3:27:49  time: 1.1628  data_time: 0.0115  memory: 7968  grad_norm: 205.2196  loss: 12.6108  decode.loss_cls: 0.0773  decode.loss_mask: 0.6612  decode.loss_dice: 0.5445  decode.d0.loss_cls: 0.2704  decode.d0.loss_mask: 0.6432  decode.d0.loss_dice: 0.5197  decode.d1.loss_cls: 0.1049  decode.d1.loss_mask: 0.6076  decode.d1.loss_dice: 0.4881  decode.d2.loss_cls: 0.1055  decode.d2.loss_mask: 0.6268  decode.d2.loss_dice: 0.4895  decode.d3.loss_cls: 0.0902  decode.d3.loss_mask: 0.6230  decode.d3.loss_dice: 0.5045  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.6148  decode.d4.loss_dice: 0.5134  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.6475  decode.d5.loss_dice: 0.5503  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.6458  decode.d6.loss_dice: 0.5032  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.6450  decode.d7.loss_dice: 0.5492  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.6734  decode.d8.loss_dice: 0.5474
2024/04/12 21:07:51 - mmengine - INFO - Iter(train) [ 9400/20000]  base_lr: 9.0550e-05 lr: 9.0550e-06  eta: 3:25:52  time: 1.1668  data_time: 0.0113  memory: 7967  grad_norm: 181.2758  loss: 11.9654  decode.loss_cls: 0.0745  decode.loss_mask: 0.5601  decode.loss_dice: 0.5383  decode.d0.loss_cls: 0.1904  decode.d0.loss_mask: 0.5923  decode.d0.loss_dice: 0.5736  decode.d1.loss_cls: 0.0788  decode.d1.loss_mask: 0.5626  decode.d1.loss_dice: 0.5553  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.5613  decode.d2.loss_dice: 0.5371  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.5631  decode.d3.loss_dice: 0.5304  decode.d4.loss_cls: 0.0925  decode.d4.loss_mask: 0.5542  decode.d4.loss_dice: 0.5438  decode.d5.loss_cls: 0.0974  decode.d5.loss_mask: 0.5720  decode.d5.loss_dice: 0.5552  decode.d6.loss_cls: 0.0697  decode.d6.loss_mask: 0.5597  decode.d6.loss_dice: 0.5434  decode.d7.loss_cls: 0.0653  decode.d7.loss_mask: 0.5629  decode.d7.loss_dice: 0.5365  decode.d8.loss_cls: 0.0724  decode.d8.loss_mask: 0.5521  decode.d8.loss_dice: 0.5418
2024/04/12 21:09:48 - mmengine - INFO - Iter(train) [ 9500/20000]  base_lr: 9.0449e-05 lr: 9.0449e-06  eta: 3:23:56  time: 1.1775  data_time: 0.0115  memory: 7967  grad_norm: 181.0161  loss: 12.4501  decode.loss_cls: 0.0447  decode.loss_mask: 0.6444  decode.loss_dice: 0.5424  decode.d0.loss_cls: 0.1876  decode.d0.loss_mask: 0.6554  decode.d0.loss_dice: 0.5409  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.6488  decode.d1.loss_dice: 0.4968  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.6374  decode.d2.loss_dice: 0.4934  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.6495  decode.d3.loss_dice: 0.5029  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.6490  decode.d4.loss_dice: 0.5098  decode.d5.loss_cls: 0.0670  decode.d5.loss_mask: 0.6495  decode.d5.loss_dice: 0.5171  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.6539  decode.d6.loss_dice: 0.5390  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.6638  decode.d7.loss_dice: 0.5285  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.6540  decode.d8.loss_dice: 0.5553
2024/04/12 21:09:50 - mmengine - INFO - per class results:
2024/04/12 21:09:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.44 | 98.86 | 98.19 | 98.19  |   97.53   | 98.86  |
| monolayer  | 86.53 | 91.07 | 92.78 | 92.78  |   94.56   | 91.07  |
|  bilayer   | 74.11 | 85.82 | 85.13 | 85.13  |   84.45   | 85.82  |
| multilayer | 86.33 | 93.19 | 92.67 | 92.67  |   92.14   | 93.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 21:09:50 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.6100  mIoU: 85.8500  mAcc: 92.2300  mDice: 92.1900  mFscore: 92.1900  mPrecision: 92.1700  mRecall: 92.2300  data_time: 0.0105  time: 0.2296
2024/04/12 21:11:46 - mmengine - INFO - Iter(train) [ 9600/20000]  base_lr: 9.0348e-05 lr: 9.0348e-06  eta: 3:21:59  time: 1.1661  data_time: 0.0115  memory: 7967  grad_norm: 287.1115  loss: 11.1322  decode.loss_cls: 0.0657  decode.loss_mask: 0.4739  decode.loss_dice: 0.5403  decode.d0.loss_cls: 0.1735  decode.d0.loss_mask: 0.4892  decode.d0.loss_dice: 0.5952  decode.d1.loss_cls: 0.1146  decode.d1.loss_mask: 0.4837  decode.d1.loss_dice: 0.5336  decode.d2.loss_cls: 0.1080  decode.d2.loss_mask: 0.4854  decode.d2.loss_dice: 0.5346  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.4790  decode.d3.loss_dice: 0.5306  decode.d4.loss_cls: 0.1253  decode.d4.loss_mask: 0.4762  decode.d4.loss_dice: 0.5180  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.4797  decode.d5.loss_dice: 0.5630  decode.d6.loss_cls: 0.0598  decode.d6.loss_mask: 0.4765  decode.d6.loss_dice: 0.5253  decode.d7.loss_cls: 0.0758  decode.d7.loss_mask: 0.4743  decode.d7.loss_dice: 0.5143  decode.d8.loss_cls: 0.0524  decode.d8.loss_mask: 0.4775  decode.d8.loss_dice: 0.5407
2024/04/12 21:13:42 - mmengine - INFO - Iter(train) [ 9700/20000]  base_lr: 9.0246e-05 lr: 9.0246e-06  eta: 3:20:02  time: 1.1663  data_time: 0.0118  memory: 7967  grad_norm: 227.6155  loss: 14.0958  decode.loss_cls: 0.0990  decode.loss_mask: 0.7154  decode.loss_dice: 0.5489  decode.d0.loss_cls: 0.2360  decode.d0.loss_mask: 0.7694  decode.d0.loss_dice: 0.6129  decode.d1.loss_cls: 0.1072  decode.d1.loss_mask: 0.7194  decode.d1.loss_dice: 0.5961  decode.d2.loss_cls: 0.0917  decode.d2.loss_mask: 0.7234  decode.d2.loss_dice: 0.6049  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.6997  decode.d3.loss_dice: 0.5617  decode.d4.loss_cls: 0.1017  decode.d4.loss_mask: 0.7157  decode.d4.loss_dice: 0.5628  decode.d5.loss_cls: 0.1029  decode.d5.loss_mask: 0.7213  decode.d5.loss_dice: 0.5636  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.7776  decode.d6.loss_dice: 0.5448  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.7093  decode.d7.loss_dice: 0.5412  decode.d8.loss_cls: 0.1157  decode.d8.loss_mask: 0.7138  decode.d8.loss_dice: 0.5501
2024/04/12 21:15:39 - mmengine - INFO - Iter(train) [ 9800/20000]  base_lr: 9.0145e-05 lr: 9.0145e-06  eta: 3:18:05  time: 1.1603  data_time: 0.0123  memory: 7963  grad_norm: 252.5961  loss: 14.5025  decode.loss_cls: 0.1166  decode.loss_mask: 0.7634  decode.loss_dice: 0.5432  decode.d0.loss_cls: 0.2445  decode.d0.loss_mask: 0.8236  decode.d0.loss_dice: 0.5593  decode.d1.loss_cls: 0.1238  decode.d1.loss_mask: 0.7984  decode.d1.loss_dice: 0.5499  decode.d2.loss_cls: 0.0990  decode.d2.loss_mask: 0.7722  decode.d2.loss_dice: 0.5464  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.7822  decode.d3.loss_dice: 0.5338  decode.d4.loss_cls: 0.0936  decode.d4.loss_mask: 0.7814  decode.d4.loss_dice: 0.5585  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.7973  decode.d5.loss_dice: 0.5850  decode.d6.loss_cls: 0.1064  decode.d6.loss_mask: 0.7818  decode.d6.loss_dice: 0.5539  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.8266  decode.d7.loss_dice: 0.5423  decode.d8.loss_cls: 0.0985  decode.d8.loss_mask: 0.7592  decode.d8.loss_dice: 0.5523
2024/04/12 21:17:35 - mmengine - INFO - Iter(train) [ 9900/20000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 3:16:09  time: 1.1659  data_time: 0.0117  memory: 7967  grad_norm: 326.4164  loss: 14.0883  decode.loss_cls: 0.0306  decode.loss_mask: 0.7664  decode.loss_dice: 0.6017  decode.d0.loss_cls: 0.1099  decode.d0.loss_mask: 0.8328  decode.d0.loss_dice: 0.6388  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.7547  decode.d1.loss_dice: 0.5986  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.7733  decode.d2.loss_dice: 0.6012  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.7625  decode.d3.loss_dice: 0.5756  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.7814  decode.d4.loss_dice: 0.5941  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.7715  decode.d5.loss_dice: 0.5969  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.7657  decode.d6.loss_dice: 0.5926  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.7463  decode.d7.loss_dice: 0.5833  decode.d8.loss_cls: 0.0648  decode.d8.loss_mask: 0.7323  decode.d8.loss_dice: 0.5874
2024/04/12 21:19:32 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 21:19:32 - mmengine - INFO - Iter(train) [10000/20000]  base_lr: 8.9943e-05 lr: 8.9943e-06  eta: 3:14:12  time: 1.1867  data_time: 0.0136  memory: 7965  grad_norm: 190.6713  loss: 10.6367  decode.loss_cls: 0.1744  decode.loss_mask: 0.4926  decode.loss_dice: 0.4001  decode.d0.loss_cls: 0.1795  decode.d0.loss_mask: 0.5305  decode.d0.loss_dice: 0.4730  decode.d1.loss_cls: 0.1114  decode.d1.loss_mask: 0.5001  decode.d1.loss_dice: 0.4093  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.5255  decode.d2.loss_dice: 0.4100  decode.d3.loss_cls: 0.1287  decode.d3.loss_mask: 0.5128  decode.d3.loss_dice: 0.4121  decode.d4.loss_cls: 0.1112  decode.d4.loss_mask: 0.5276  decode.d4.loss_dice: 0.4203  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 0.5166  decode.d5.loss_dice: 0.4193  decode.d6.loss_cls: 0.1519  decode.d6.loss_mask: 0.5248  decode.d6.loss_dice: 0.4119  decode.d7.loss_cls: 0.1477  decode.d7.loss_mask: 0.4987  decode.d7.loss_dice: 0.4220  decode.d8.loss_cls: 0.1493  decode.d8.loss_mask: 0.4878  decode.d8.loss_dice: 0.4085
2024/04/12 21:19:32 - mmengine - INFO - Saving checkpoint at 10000 iterations
2024/04/12 21:19:35 - mmengine - INFO - per class results:
2024/04/12 21:19:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.63 | 98.77 | 98.29 | 98.29  |   97.81   | 98.77  |
| monolayer  | 87.37 | 91.98 | 93.26 | 93.26  |   94.58   | 91.98  |
|  bilayer   | 75.73 |  86.8 | 86.19 | 86.19  |   85.59   |  86.8  |
| multilayer | 86.66 | 93.29 | 92.85 | 92.85  |   92.42   | 93.29  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 21:19:35 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8600  mIoU: 86.6000  mAcc: 92.7100  mDice: 92.6500  mFscore: 92.6500  mPrecision: 92.6000  mRecall: 92.7100  data_time: 0.0115  time: 0.2310
2024/04/12 21:19:35 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful/best_mIoU_iter_4500.pth is removed
2024/04/12 21:19:36 - mmengine - INFO - The best checkpoint with 86.6000 mIoU at 10000 iter is saved to best_mIoU_iter_10000.pth.
2024/04/12 21:21:34 - mmengine - INFO - Iter(train) [10100/20000]  base_lr: 8.9842e-05 lr: 8.9842e-06  eta: 3:12:18  time: 1.1659  data_time: 0.0125  memory: 7967  grad_norm: 275.0546  loss: 10.0805  decode.loss_cls: 0.0476  decode.loss_mask: 0.4713  decode.loss_dice: 0.4783  decode.d0.loss_cls: 0.0937  decode.d0.loss_mask: 0.4863  decode.d0.loss_dice: 0.4936  decode.d1.loss_cls: 0.0624  decode.d1.loss_mask: 0.4639  decode.d1.loss_dice: 0.4792  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.4649  decode.d2.loss_dice: 0.4822  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.4670  decode.d3.loss_dice: 0.4805  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.4635  decode.d4.loss_dice: 0.4881  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.4652  decode.d5.loss_dice: 0.4932  decode.d6.loss_cls: 0.0437  decode.d6.loss_mask: 0.4708  decode.d6.loss_dice: 0.4939  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.4661  decode.d7.loss_dice: 0.4792  decode.d8.loss_cls: 0.0371  decode.d8.loss_mask: 0.4669  decode.d8.loss_dice: 0.4776
2024/04/12 21:23:30 - mmengine - INFO - Iter(train) [10200/20000]  base_lr: 8.9741e-05 lr: 8.9741e-06  eta: 3:10:21  time: 1.1647  data_time: 0.0111  memory: 7967  grad_norm: 174.2107  loss: 10.4817  decode.loss_cls: 0.0269  decode.loss_mask: 0.5414  decode.loss_dice: 0.4432  decode.d0.loss_cls: 0.1225  decode.d0.loss_mask: 0.5716  decode.d0.loss_dice: 0.4617  decode.d1.loss_cls: 0.0488  decode.d1.loss_mask: 0.5456  decode.d1.loss_dice: 0.4597  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.5382  decode.d2.loss_dice: 0.4501  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.5420  decode.d3.loss_dice: 0.4701  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.5522  decode.d4.loss_dice: 0.4568  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 0.4528  decode.d6.loss_cls: 0.0302  decode.d6.loss_mask: 0.5551  decode.d6.loss_dice: 0.4514  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.5498  decode.d7.loss_dice: 0.4463  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.5497  decode.d8.loss_dice: 0.4517
2024/04/12 21:25:27 - mmengine - INFO - Iter(train) [10300/20000]  base_lr: 8.9639e-05 lr: 8.9639e-06  eta: 3:08:24  time: 1.1666  data_time: 0.0112  memory: 7963  grad_norm: 240.1615  loss: 12.9306  decode.loss_cls: 0.0734  decode.loss_mask: 0.6496  decode.loss_dice: 0.5012  decode.d0.loss_cls: 0.2829  decode.d0.loss_mask: 0.6641  decode.d0.loss_dice: 0.5505  decode.d1.loss_cls: 0.1427  decode.d1.loss_mask: 0.6530  decode.d1.loss_dice: 0.5395  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.6501  decode.d2.loss_dice: 0.4997  decode.d3.loss_cls: 0.0984  decode.d3.loss_mask: 0.6616  decode.d3.loss_dice: 0.5332  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.6558  decode.d4.loss_dice: 0.5299  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 0.6714  decode.d5.loss_dice: 0.5229  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.6621  decode.d6.loss_dice: 0.5437  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.6584  decode.d7.loss_dice: 0.5308  decode.d8.loss_cls: 0.0411  decode.d8.loss_mask: 0.6637  decode.d8.loss_dice: 0.5582
2024/04/12 21:27:23 - mmengine - INFO - Iter(train) [10400/20000]  base_lr: 8.9538e-05 lr: 8.9538e-06  eta: 3:06:28  time: 1.1650  data_time: 0.0121  memory: 7967  grad_norm: 176.9179  loss: 11.4551  decode.loss_cls: 0.0688  decode.loss_mask: 0.5440  decode.loss_dice: 0.5095  decode.d0.loss_cls: 0.2302  decode.d0.loss_mask: 0.5338  decode.d0.loss_dice: 0.5271  decode.d1.loss_cls: 0.0896  decode.d1.loss_mask: 0.5559  decode.d1.loss_dice: 0.5097  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.5498  decode.d2.loss_dice: 0.5263  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.5469  decode.d3.loss_dice: 0.5279  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.5582  decode.d4.loss_dice: 0.5178  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.5500  decode.d5.loss_dice: 0.4721  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.5566  decode.d6.loss_dice: 0.4914  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.5530  decode.d7.loss_dice: 0.4832  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.5967  decode.d8.loss_dice: 0.5082
2024/04/12 21:29:20 - mmengine - INFO - Iter(train) [10500/20000]  base_lr: 8.9437e-05 lr: 8.9437e-06  eta: 3:04:31  time: 1.1655  data_time: 0.0109  memory: 7967  grad_norm: 215.3765  loss: 11.4164  decode.loss_cls: 0.0674  decode.loss_mask: 0.5484  decode.loss_dice: 0.4930  decode.d0.loss_cls: 0.1869  decode.d0.loss_mask: 0.5937  decode.d0.loss_dice: 0.5255  decode.d1.loss_cls: 0.1143  decode.d1.loss_mask: 0.5889  decode.d1.loss_dice: 0.5217  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.5569  decode.d2.loss_dice: 0.5100  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.5516  decode.d3.loss_dice: 0.5134  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 0.5425  decode.d4.loss_dice: 0.4992  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.5430  decode.d5.loss_dice: 0.4995  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.5570  decode.d6.loss_dice: 0.4908  decode.d7.loss_cls: 0.0539  decode.d7.loss_mask: 0.5541  decode.d7.loss_dice: 0.5139  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.5450  decode.d8.loss_dice: 0.4899
2024/04/12 21:29:22 - mmengine - INFO - per class results:
2024/04/12 21:29:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.75 | 98.57 | 98.35 | 98.35  |   98.12   | 98.57  |
| monolayer  | 87.24 | 92.82 | 93.19 | 93.19  |   93.55   | 92.82  |
|  bilayer   | 74.48 | 85.93 | 85.37 | 85.37  |   84.82   | 85.93  |
| multilayer | 86.48 | 92.05 | 92.75 | 92.75  |   93.46   | 92.05  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 21:29:22 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8200  mIoU: 86.2400  mAcc: 92.3400  mDice: 92.4100  mFscore: 92.4100  mPrecision: 92.4900  mRecall: 92.3400  data_time: 0.0150  time: 0.2340
2024/04/12 21:31:18 - mmengine - INFO - Iter(train) [10600/20000]  base_lr: 8.9336e-05 lr: 8.9336e-06  eta: 3:02:35  time: 1.1610  data_time: 0.0114  memory: 7971  grad_norm: 290.2522  loss: 15.6420  decode.loss_cls: 0.1711  decode.loss_mask: 0.7470  decode.loss_dice: 0.6458  decode.d0.loss_cls: 0.3523  decode.d0.loss_mask: 0.7702  decode.d0.loss_dice: 0.6680  decode.d1.loss_cls: 0.2278  decode.d1.loss_mask: 0.7186  decode.d1.loss_dice: 0.5925  decode.d2.loss_cls: 0.1920  decode.d2.loss_mask: 0.7421  decode.d2.loss_dice: 0.6302  decode.d3.loss_cls: 0.1727  decode.d3.loss_mask: 0.7426  decode.d3.loss_dice: 0.6476  decode.d4.loss_cls: 0.1274  decode.d4.loss_mask: 0.7270  decode.d4.loss_dice: 0.6284  decode.d5.loss_cls: 0.1549  decode.d5.loss_mask: 0.7419  decode.d5.loss_dice: 0.6188  decode.d6.loss_cls: 0.1901  decode.d6.loss_mask: 0.7355  decode.d6.loss_dice: 0.6279  decode.d7.loss_cls: 0.1618  decode.d7.loss_mask: 0.7343  decode.d7.loss_dice: 0.6150  decode.d8.loss_cls: 0.1424  decode.d8.loss_mask: 0.7477  decode.d8.loss_dice: 0.6684
2024/04/12 21:33:15 - mmengine - INFO - Iter(train) [10700/20000]  base_lr: 8.9234e-05 lr: 8.9234e-06  eta: 3:00:38  time: 1.1712  data_time: 0.0127  memory: 7963  grad_norm: 239.7694  loss: 8.6783  decode.loss_cls: 0.0201  decode.loss_mask: 0.4624  decode.loss_dice: 0.3395  decode.d0.loss_cls: 0.1276  decode.d0.loss_mask: 0.4882  decode.d0.loss_dice: 0.3780  decode.d1.loss_cls: 0.0375  decode.d1.loss_mask: 0.4661  decode.d1.loss_dice: 0.3633  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.4661  decode.d2.loss_dice: 0.3488  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.4641  decode.d3.loss_dice: 0.3685  decode.d4.loss_cls: 0.0231  decode.d4.loss_mask: 0.4686  decode.d4.loss_dice: 0.3500  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.4751  decode.d5.loss_dice: 0.3470  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.4793  decode.d6.loss_dice: 0.3455  decode.d7.loss_cls: 0.0262  decode.d7.loss_mask: 0.4689  decode.d7.loss_dice: 0.3576  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.4672  decode.d8.loss_dice: 0.3563
2024/04/12 21:35:11 - mmengine - INFO - Iter(train) [10800/20000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 2:58:41  time: 1.1603  data_time: 0.0113  memory: 7963  grad_norm: 166.2453  loss: 9.0950  decode.loss_cls: 0.0130  decode.loss_mask: 0.4599  decode.loss_dice: 0.4112  decode.d0.loss_cls: 0.0999  decode.d0.loss_mask: 0.4848  decode.d0.loss_dice: 0.4225  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.4722  decode.d1.loss_dice: 0.4147  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.4600  decode.d2.loss_dice: 0.4159  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.4603  decode.d3.loss_dice: 0.4068  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.4585  decode.d4.loss_dice: 0.4276  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 0.4556  decode.d5.loss_dice: 0.4089  decode.d6.loss_cls: 0.0494  decode.d6.loss_mask: 0.4596  decode.d6.loss_dice: 0.4194  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.4603  decode.d7.loss_dice: 0.4123  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.4580  decode.d8.loss_dice: 0.4194
2024/04/12 21:37:07 - mmengine - INFO - Iter(train) [10900/20000]  base_lr: 8.9032e-05 lr: 8.9032e-06  eta: 2:56:45  time: 1.1608  data_time: 0.0115  memory: 7971  grad_norm: 230.7601  loss: 12.3216  decode.loss_cls: 0.1083  decode.loss_mask: 0.5378  decode.loss_dice: 0.5771  decode.d0.loss_cls: 0.2440  decode.d0.loss_mask: 0.5554  decode.d0.loss_dice: 0.5868  decode.d1.loss_cls: 0.1258  decode.d1.loss_mask: 0.5353  decode.d1.loss_dice: 0.5700  decode.d2.loss_cls: 0.1225  decode.d2.loss_mask: 0.5371  decode.d2.loss_dice: 0.5361  decode.d3.loss_cls: 0.1464  decode.d3.loss_mask: 0.5368  decode.d3.loss_dice: 0.5612  decode.d4.loss_cls: 0.1421  decode.d4.loss_mask: 0.5342  decode.d4.loss_dice: 0.5506  decode.d5.loss_cls: 0.1429  decode.d5.loss_mask: 0.5390  decode.d5.loss_dice: 0.5398  decode.d6.loss_cls: 0.1394  decode.d6.loss_mask: 0.5357  decode.d6.loss_dice: 0.5664  decode.d7.loss_cls: 0.1023  decode.d7.loss_mask: 0.5364  decode.d7.loss_dice: 0.5441  decode.d8.loss_cls: 0.1090  decode.d8.loss_mask: 0.5334  decode.d8.loss_dice: 0.5258
2024/04/12 21:39:04 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 21:39:04 - mmengine - INFO - Iter(train) [11000/20000]  base_lr: 8.8930e-05 lr: 8.8930e-06  eta: 2:54:48  time: 1.1661  data_time: 0.0112  memory: 7968  grad_norm: 266.7779  loss: 16.1307  decode.loss_cls: 0.1871  decode.loss_mask: 0.7613  decode.loss_dice: 0.6988  decode.d0.loss_cls: 0.3042  decode.d0.loss_mask: 0.7620  decode.d0.loss_dice: 0.7148  decode.d1.loss_cls: 0.2008  decode.d1.loss_mask: 0.7453  decode.d1.loss_dice: 0.6318  decode.d2.loss_cls: 0.1644  decode.d2.loss_mask: 0.7455  decode.d2.loss_dice: 0.6661  decode.d3.loss_cls: 0.2020  decode.d3.loss_mask: 0.7299  decode.d3.loss_dice: 0.6436  decode.d4.loss_cls: 0.2063  decode.d4.loss_mask: 0.7417  decode.d4.loss_dice: 0.6372  decode.d5.loss_cls: 0.2002  decode.d5.loss_mask: 0.7436  decode.d5.loss_dice: 0.6396  decode.d6.loss_cls: 0.2207  decode.d6.loss_mask: 0.7452  decode.d6.loss_dice: 0.6397  decode.d7.loss_cls: 0.2085  decode.d7.loss_mask: 0.7409  decode.d7.loss_dice: 0.6349  decode.d8.loss_cls: 0.1742  decode.d8.loss_mask: 0.7677  decode.d8.loss_dice: 0.6728
2024/04/12 21:39:06 - mmengine - INFO - per class results:
2024/04/12 21:39:06 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.56 | 98.66 | 98.25 | 98.25  |   97.84   | 98.66  |
| monolayer  | 86.36 | 92.47 | 92.68 | 92.68  |    92.9   | 92.47  |
|  bilayer   | 73.67 | 84.98 | 84.84 | 84.84  |    84.7   | 84.98  |
| multilayer | 85.26 | 89.94 | 92.04 | 92.04  |   94.24   | 89.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 21:39:06 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.5500  mIoU: 85.4600  mAcc: 91.5100  mDice: 91.9500  mFscore: 91.9500  mPrecision: 92.4200  mRecall: 91.5100  data_time: 0.0162  time: 0.2351
2024/04/12 21:41:02 - mmengine - INFO - Iter(train) [11100/20000]  base_lr: 8.8829e-05 lr: 8.8829e-06  eta: 2:52:51  time: 1.1618  data_time: 0.0119  memory: 7963  grad_norm: 228.6930  loss: 9.8231  decode.loss_cls: 0.0114  decode.loss_mask: 0.5254  decode.loss_dice: 0.4099  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.5645  decode.d0.loss_dice: 0.4675  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.5285  decode.d1.loss_dice: 0.4120  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.5240  decode.d2.loss_dice: 0.4194  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.5204  decode.d3.loss_dice: 0.4058  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.5164  decode.d4.loss_dice: 0.3997  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.5298  decode.d5.loss_dice: 0.4298  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.5223  decode.d6.loss_dice: 0.4199  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.5250  decode.d7.loss_dice: 0.4110  decode.d8.loss_cls: 0.0360  decode.d8.loss_mask: 0.5259  decode.d8.loss_dice: 0.4059
2024/04/12 21:42:58 - mmengine - INFO - Iter(train) [11200/20000]  base_lr: 8.8728e-05 lr: 8.8728e-06  eta: 2:50:55  time: 1.1653  data_time: 0.0111  memory: 7967  grad_norm: 203.1490  loss: 10.3573  decode.loss_cls: 0.0257  decode.loss_mask: 0.5056  decode.loss_dice: 0.4856  decode.d0.loss_cls: 0.1270  decode.d0.loss_mask: 0.5333  decode.d0.loss_dice: 0.4876  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.5069  decode.d1.loss_dice: 0.4643  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.5175  decode.d2.loss_dice: 0.4781  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.5258  decode.d3.loss_dice: 0.4826  decode.d4.loss_cls: 0.0490  decode.d4.loss_mask: 0.4763  decode.d4.loss_dice: 0.4939  decode.d5.loss_cls: 0.0304  decode.d5.loss_mask: 0.5186  decode.d5.loss_dice: 0.4852  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 0.5104  decode.d6.loss_dice: 0.4868  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.5074  decode.d7.loss_dice: 0.4732  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.5123  decode.d8.loss_dice: 0.4785
2024/04/12 21:44:54 - mmengine - INFO - Iter(train) [11300/20000]  base_lr: 8.8626e-05 lr: 8.8626e-06  eta: 2:48:58  time: 1.1726  data_time: 0.0134  memory: 7968  grad_norm: 246.2059  loss: 10.7695  decode.loss_cls: 0.0435  decode.loss_mask: 0.5387  decode.loss_dice: 0.4598  decode.d0.loss_cls: 0.1877  decode.d0.loss_mask: 0.5788  decode.d0.loss_dice: 0.5061  decode.d1.loss_cls: 0.0588  decode.d1.loss_mask: 0.5426  decode.d1.loss_dice: 0.4535  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.5408  decode.d2.loss_dice: 0.4691  decode.d3.loss_cls: 0.0613  decode.d3.loss_mask: 0.5436  decode.d3.loss_dice: 0.4629  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 0.5426  decode.d4.loss_dice: 0.4814  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.5414  decode.d5.loss_dice: 0.4612  decode.d6.loss_cls: 0.0416  decode.d6.loss_mask: 0.5428  decode.d6.loss_dice: 0.4639  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.5424  decode.d7.loss_dice: 0.4834  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.5413  decode.d8.loss_dice: 0.4528
2024/04/12 21:46:51 - mmengine - INFO - Iter(train) [11400/20000]  base_lr: 8.8525e-05 lr: 8.8525e-06  eta: 2:47:01  time: 1.1650  data_time: 0.0127  memory: 7967  grad_norm: 216.7840  loss: 10.2417  decode.loss_cls: 0.0117  decode.loss_mask: 0.5607  decode.loss_dice: 0.4166  decode.d0.loss_cls: 0.1351  decode.d0.loss_mask: 0.6108  decode.d0.loss_dice: 0.4724  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.5684  decode.d1.loss_dice: 0.4345  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.5552  decode.d2.loss_dice: 0.4405  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.5537  decode.d3.loss_dice: 0.4383  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.5596  decode.d4.loss_dice: 0.4381  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.5580  decode.d5.loss_dice: 0.4289  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.5577  decode.d6.loss_dice: 0.4281  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.5540  decode.d7.loss_dice: 0.4224  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.5582  decode.d8.loss_dice: 0.4195
2024/04/12 21:48:47 - mmengine - INFO - Iter(train) [11500/20000]  base_lr: 8.8424e-05 lr: 8.8424e-06  eta: 2:45:04  time: 1.1719  data_time: 0.0113  memory: 7965  grad_norm: 198.8527  loss: 10.7597  decode.loss_cls: 0.1058  decode.loss_mask: 0.4589  decode.loss_dice: 0.4648  decode.d0.loss_cls: 0.2082  decode.d0.loss_mask: 0.4827  decode.d0.loss_dice: 0.4757  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 0.4696  decode.d1.loss_dice: 0.4701  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.4671  decode.d2.loss_dice: 0.4890  decode.d3.loss_cls: 0.1806  decode.d3.loss_mask: 0.4607  decode.d3.loss_dice: 0.4667  decode.d4.loss_cls: 0.1497  decode.d4.loss_mask: 0.4715  decode.d4.loss_dice: 0.4731  decode.d5.loss_cls: 0.1489  decode.d5.loss_mask: 0.4699  decode.d5.loss_dice: 0.4768  decode.d6.loss_cls: 0.0926  decode.d6.loss_mask: 0.4668  decode.d6.loss_dice: 0.4959  decode.d7.loss_cls: 0.1024  decode.d7.loss_mask: 0.4666  decode.d7.loss_dice: 0.4805  decode.d8.loss_cls: 0.1130  decode.d8.loss_mask: 0.4645  decode.d8.loss_dice: 0.4585
2024/04/12 21:48:49 - mmengine - INFO - per class results:
2024/04/12 21:48:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.91 | 98.59 | 98.43 | 98.43  |   98.27   | 98.59  |
| monolayer  | 88.03 | 93.16 | 93.64 | 93.64  |   94.12   | 93.16  |
|  bilayer   | 75.32 | 86.11 | 85.92 | 85.92  |   85.73   | 86.11  |
| multilayer | 86.74 | 93.19 |  92.9 |  92.9  |   92.61   | 93.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 21:48:49 - mmengine - INFO - Iter(val) [8/8]    aAcc: 96.0300  mIoU: 86.7500  mAcc: 92.7600  mDice: 92.7200  mFscore: 92.7200  mPrecision: 92.6800  mRecall: 92.7600  data_time: 0.0145  time: 0.2337
2024/04/12 21:48:49 - mmengine - INFO - The previous best checkpoint /home/zhouruiliang/code/mmsegmentation-main/work_head_dirs/mask2former-ful/best_mIoU_iter_10000.pth is removed
2024/04/12 21:48:50 - mmengine - INFO - The best checkpoint with 86.7500 mIoU at 11500 iter is saved to best_mIoU_iter_11500.pth.
2024/04/12 21:50:48 - mmengine - INFO - Iter(train) [11600/20000]  base_lr: 8.8322e-05 lr: 8.8322e-06  eta: 2:43:10  time: 1.1675  data_time: 0.0138  memory: 7965  grad_norm: 186.9746  loss: 10.0505  decode.loss_cls: 0.0240  decode.loss_mask: 0.4632  decode.loss_dice: 0.4968  decode.d0.loss_cls: 0.1099  decode.d0.loss_mask: 0.4803  decode.d0.loss_dice: 0.5130  decode.d1.loss_cls: 0.0198  decode.d1.loss_mask: 0.4643  decode.d1.loss_dice: 0.5060  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.4629  decode.d2.loss_dice: 0.4990  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.4654  decode.d3.loss_dice: 0.5067  decode.d4.loss_cls: 0.0292  decode.d4.loss_mask: 0.4672  decode.d4.loss_dice: 0.5016  decode.d5.loss_cls: 0.0269  decode.d5.loss_mask: 0.4757  decode.d5.loss_dice: 0.4944  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.4744  decode.d6.loss_dice: 0.4924  decode.d7.loss_cls: 0.0232  decode.d7.loss_mask: 0.4710  decode.d7.loss_dice: 0.5060  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.4802  decode.d8.loss_dice: 0.4991
2024/04/12 21:52:45 - mmengine - INFO - Iter(train) [11700/20000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 2:41:13  time: 1.1611  data_time: 0.0118  memory: 7967  grad_norm: 176.4318  loss: 8.8250  decode.loss_cls: 0.0257  decode.loss_mask: 0.4653  decode.loss_dice: 0.3680  decode.d0.loss_cls: 0.1277  decode.d0.loss_mask: 0.4754  decode.d0.loss_dice: 0.3822  decode.d1.loss_cls: 0.0665  decode.d1.loss_mask: 0.4642  decode.d1.loss_dice: 0.3643  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.4576  decode.d2.loss_dice: 0.3677  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.4553  decode.d3.loss_dice: 0.3653  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.4634  decode.d4.loss_dice: 0.3575  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.4660  decode.d5.loss_dice: 0.3573  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.4672  decode.d6.loss_dice: 0.3575  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.4611  decode.d7.loss_dice: 0.3669  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.4591  decode.d8.loss_dice: 0.3596
2024/04/12 21:54:41 - mmengine - INFO - Iter(train) [11800/20000]  base_lr: 8.8120e-05 lr: 8.8120e-06  eta: 2:39:17  time: 1.1641  data_time: 0.0109  memory: 7967  grad_norm: 292.2044  loss: 15.7081  decode.loss_cls: 0.0833  decode.loss_mask: 0.7710  decode.loss_dice: 0.6862  decode.d0.loss_cls: 0.2842  decode.d0.loss_mask: 0.7731  decode.d0.loss_dice: 0.7155  decode.d1.loss_cls: 0.2188  decode.d1.loss_mask: 0.7542  decode.d1.loss_dice: 0.6371  decode.d2.loss_cls: 0.2146  decode.d2.loss_mask: 0.7451  decode.d2.loss_dice: 0.6473  decode.d3.loss_cls: 0.1866  decode.d3.loss_mask: 0.7467  decode.d3.loss_dice: 0.6548  decode.d4.loss_cls: 0.1738  decode.d4.loss_mask: 0.7234  decode.d4.loss_dice: 0.6422  decode.d5.loss_cls: 0.1767  decode.d5.loss_mask: 0.7247  decode.d5.loss_dice: 0.6372  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.7241  decode.d6.loss_dice: 0.6348  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.7316  decode.d7.loss_dice: 0.6596  decode.d8.loss_cls: 0.0890  decode.d8.loss_mask: 0.7443  decode.d8.loss_dice: 0.6688
2024/04/12 21:56:37 - mmengine - INFO - Iter(train) [11900/20000]  base_lr: 8.8018e-05 lr: 8.8018e-06  eta: 2:37:20  time: 1.1615  data_time: 0.0110  memory: 7967  grad_norm: 499.4836  loss: 15.9816  decode.loss_cls: 0.1374  decode.loss_mask: 0.7374  decode.loss_dice: 0.6899  decode.d0.loss_cls: 0.3237  decode.d0.loss_mask: 0.7511  decode.d0.loss_dice: 0.7220  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 0.7343  decode.d1.loss_dice: 0.6803  decode.d2.loss_cls: 0.1458  decode.d2.loss_mask: 0.7601  decode.d2.loss_dice: 0.7056  decode.d3.loss_cls: 0.1363  decode.d3.loss_mask: 0.7455  decode.d3.loss_dice: 0.6894  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 0.7302  decode.d4.loss_dice: 0.7041  decode.d5.loss_cls: 0.1251  decode.d5.loss_mask: 0.7285  decode.d5.loss_dice: 0.6969  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.7399  decode.d6.loss_dice: 0.6889  decode.d7.loss_cls: 0.1724  decode.d7.loss_mask: 0.7417  decode.d7.loss_dice: 0.6823  decode.d8.loss_cls: 0.1533  decode.d8.loss_mask: 0.7345  decode.d8.loss_dice: 0.6723
2024/04/12 21:58:34 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 21:58:34 - mmengine - INFO - Iter(train) [12000/20000]  base_lr: 8.7917e-05 lr: 8.7917e-06  eta: 2:35:23  time: 1.1739  data_time: 0.0118  memory: 7963  grad_norm: 303.5083  loss: 10.4563  decode.loss_cls: 0.0378  decode.loss_mask: 0.5744  decode.loss_dice: 0.4126  decode.d0.loss_cls: 0.1570  decode.d0.loss_mask: 0.5908  decode.d0.loss_dice: 0.4281  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.5630  decode.d1.loss_dice: 0.4142  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.5760  decode.d2.loss_dice: 0.4209  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.5741  decode.d3.loss_dice: 0.4236  decode.d4.loss_cls: 0.0428  decode.d4.loss_mask: 0.5718  decode.d4.loss_dice: 0.4147  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.5796  decode.d5.loss_dice: 0.4194  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.5770  decode.d6.loss_dice: 0.4132  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.5670  decode.d7.loss_dice: 0.4122  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.5822  decode.d8.loss_dice: 0.4137
2024/04/12 21:58:36 - mmengine - INFO - per class results:
2024/04/12 21:58:36 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.78 | 98.69 | 98.36 | 98.36  |   98.03   | 98.69  |
| monolayer  | 87.04 | 92.04 | 93.07 | 93.07  |   94.13   | 92.04  |
|  bilayer   | 74.54 | 84.95 | 85.41 | 85.41  |   85.87   | 84.95  |
| multilayer | 84.81 | 93.09 | 91.78 | 91.78  |   90.51   | 93.09  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 21:58:36 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.7300  mIoU: 85.7900  mAcc: 92.2000  mDice: 92.1600  mFscore: 92.1600  mPrecision: 92.1400  mRecall: 92.2000  data_time: 0.0118  time: 0.2319
2024/04/12 22:00:32 - mmengine - INFO - Iter(train) [12100/20000]  base_lr: 8.7815e-05 lr: 8.7815e-06  eta: 2:33:27  time: 1.1625  data_time: 0.0119  memory: 7967  grad_norm: 199.0036  loss: 11.6869  decode.loss_cls: 0.1079  decode.loss_mask: 0.5132  decode.loss_dice: 0.5054  decode.d0.loss_cls: 0.2154  decode.d0.loss_mask: 0.5184  decode.d0.loss_dice: 0.5791  decode.d1.loss_cls: 0.1371  decode.d1.loss_mask: 0.5197  decode.d1.loss_dice: 0.5093  decode.d2.loss_cls: 0.1164  decode.d2.loss_mask: 0.5150  decode.d2.loss_dice: 0.5130  decode.d3.loss_cls: 0.1437  decode.d3.loss_mask: 0.5130  decode.d3.loss_dice: 0.5071  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.5192  decode.d4.loss_dice: 0.5303  decode.d5.loss_cls: 0.1156  decode.d5.loss_mask: 0.5131  decode.d5.loss_dice: 0.5117  decode.d6.loss_cls: 0.1061  decode.d6.loss_mask: 0.5127  decode.d6.loss_dice: 0.5198  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.5146  decode.d7.loss_dice: 0.5250  decode.d8.loss_cls: 0.1469  decode.d8.loss_mask: 0.4936  decode.d8.loss_dice: 0.5089
2024/04/12 22:02:28 - mmengine - INFO - Iter(train) [12200/20000]  base_lr: 8.7714e-05 lr: 8.7714e-06  eta: 2:31:30  time: 1.1606  data_time: 0.0114  memory: 7963  grad_norm: 186.4881  loss: 10.4284  decode.loss_cls: 0.0543  decode.loss_mask: 0.5229  decode.loss_dice: 0.4372  decode.d0.loss_cls: 0.2409  decode.d0.loss_mask: 0.5573  decode.d0.loss_dice: 0.4390  decode.d1.loss_cls: 0.0605  decode.d1.loss_mask: 0.5346  decode.d1.loss_dice: 0.4557  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.5516  decode.d2.loss_dice: 0.4235  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.5457  decode.d3.loss_dice: 0.4189  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.5194  decode.d4.loss_dice: 0.4094  decode.d5.loss_cls: 0.0680  decode.d5.loss_mask: 0.5185  decode.d5.loss_dice: 0.4075  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.5358  decode.d6.loss_dice: 0.4233  decode.d7.loss_cls: 0.0537  decode.d7.loss_mask: 0.5306  decode.d7.loss_dice: 0.4310  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.5382  decode.d8.loss_dice: 0.4303
2024/04/12 22:04:25 - mmengine - INFO - Iter(train) [12300/20000]  base_lr: 8.7612e-05 lr: 8.7612e-06  eta: 2:29:33  time: 1.1667  data_time: 0.0132  memory: 7967  grad_norm: 200.8423  loss: 9.6332  decode.loss_cls: 0.0963  decode.loss_mask: 0.4393  decode.loss_dice: 0.4015  decode.d0.loss_cls: 0.2016  decode.d0.loss_mask: 0.4704  decode.d0.loss_dice: 0.4441  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 0.4511  decode.d1.loss_dice: 0.3944  decode.d2.loss_cls: 0.0769  decode.d2.loss_mask: 0.4473  decode.d2.loss_dice: 0.4041  decode.d3.loss_cls: 0.0811  decode.d3.loss_mask: 0.4379  decode.d3.loss_dice: 0.3984  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.4553  decode.d4.loss_dice: 0.4146  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.4659  decode.d5.loss_dice: 0.4183  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 0.4631  decode.d6.loss_dice: 0.3977  decode.d7.loss_cls: 0.0943  decode.d7.loss_mask: 0.4414  decode.d7.loss_dice: 0.3868  decode.d8.loss_cls: 0.0998  decode.d8.loss_mask: 0.4562  decode.d8.loss_dice: 0.4063
2024/04/12 22:06:21 - mmengine - INFO - Iter(train) [12400/20000]  base_lr: 8.7511e-05 lr: 8.7511e-06  eta: 2:27:37  time: 1.1688  data_time: 0.0120  memory: 7967  grad_norm: 188.0919  loss: 9.6862  decode.loss_cls: 0.0731  decode.loss_mask: 0.4478  decode.loss_dice: 0.4455  decode.d0.loss_cls: 0.1279  decode.d0.loss_mask: 0.4552  decode.d0.loss_dice: 0.4956  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.4424  decode.d1.loss_dice: 0.4703  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.4489  decode.d2.loss_dice: 0.4467  decode.d3.loss_cls: 0.0537  decode.d3.loss_mask: 0.4411  decode.d3.loss_dice: 0.4457  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.4456  decode.d4.loss_dice: 0.4630  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 0.4468  decode.d5.loss_dice: 0.4327  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.4455  decode.d6.loss_dice: 0.4327  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 0.4421  decode.d7.loss_dice: 0.4437  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.4370  decode.d8.loss_dice: 0.4383
2024/04/12 22:08:18 - mmengine - INFO - Iter(train) [12500/20000]  base_lr: 8.7409e-05 lr: 8.7409e-06  eta: 2:25:40  time: 1.1712  data_time: 0.0132  memory: 7967  grad_norm: 175.1021  loss: 9.7890  decode.loss_cls: 0.0785  decode.loss_mask: 0.4676  decode.loss_dice: 0.4200  decode.d0.loss_cls: 0.1293  decode.d0.loss_mask: 0.4822  decode.d0.loss_dice: 0.4474  decode.d1.loss_cls: 0.0860  decode.d1.loss_mask: 0.4831  decode.d1.loss_dice: 0.4336  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.4785  decode.d2.loss_dice: 0.4301  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.4703  decode.d3.loss_dice: 0.4113  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.4733  decode.d4.loss_dice: 0.4227  decode.d5.loss_cls: 0.0822  decode.d5.loss_mask: 0.4730  decode.d5.loss_dice: 0.4302  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 0.4736  decode.d6.loss_dice: 0.4282  decode.d7.loss_cls: 0.0783  decode.d7.loss_mask: 0.4729  decode.d7.loss_dice: 0.4169  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.4714  decode.d8.loss_dice: 0.4111
2024/04/12 22:08:18 - mmengine - INFO - Saving checkpoint at 12500 iterations
2024/04/12 22:08:21 - mmengine - INFO - per class results:
2024/04/12 22:08:21 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.71 | 98.79 | 98.33 | 98.33  |   97.87   | 98.79  |
| monolayer  | 87.34 | 92.04 | 93.24 | 93.24  |   94.48   | 92.04  |
|  bilayer   | 74.81 | 86.43 | 85.59 | 85.59  |   84.76   | 86.43  |
| multilayer | 86.45 | 92.87 | 92.73 | 92.73  |   92.59   | 92.87  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 22:08:21 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8400  mIoU: 86.3300  mAcc: 92.5300  mDice: 92.4700  mFscore: 92.4700  mPrecision: 92.4200  mRecall: 92.5300  data_time: 0.0112  time: 0.2314
2024/04/12 22:10:18 - mmengine - INFO - Iter(train) [12600/20000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 2:23:43  time: 1.1601  data_time: 0.0113  memory: 7963  grad_norm: 187.4490  loss: 10.4318  decode.loss_cls: 0.0766  decode.loss_mask: 0.4444  decode.loss_dice: 0.4887  decode.d0.loss_cls: 0.1126  decode.d0.loss_mask: 0.4888  decode.d0.loss_dice: 0.5831  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.4358  decode.d1.loss_dice: 0.4859  decode.d2.loss_cls: 0.1110  decode.d2.loss_mask: 0.4381  decode.d2.loss_dice: 0.4892  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.4414  decode.d3.loss_dice: 0.5285  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 0.4436  decode.d4.loss_dice: 0.4819  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.4453  decode.d5.loss_dice: 0.5080  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.4543  decode.d6.loss_dice: 0.4996  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.4494  decode.d7.loss_dice: 0.4683  decode.d8.loss_cls: 0.1004  decode.d8.loss_mask: 0.4403  decode.d8.loss_dice: 0.4749
2024/04/12 22:12:14 - mmengine - INFO - Iter(train) [12700/20000]  base_lr: 8.7206e-05 lr: 8.7206e-06  eta: 2:21:47  time: 1.1629  data_time: 0.0120  memory: 7968  grad_norm: 298.4026  loss: 10.7168  decode.loss_cls: 0.1369  decode.loss_mask: 0.4873  decode.loss_dice: 0.4615  decode.d0.loss_cls: 0.3181  decode.d0.loss_mask: 0.4653  decode.d0.loss_dice: 0.4343  decode.d1.loss_cls: 0.1413  decode.d1.loss_mask: 0.4960  decode.d1.loss_dice: 0.4525  decode.d2.loss_cls: 0.1411  decode.d2.loss_mask: 0.4719  decode.d2.loss_dice: 0.4417  decode.d3.loss_cls: 0.1159  decode.d3.loss_mask: 0.4690  decode.d3.loss_dice: 0.4285  decode.d4.loss_cls: 0.1443  decode.d4.loss_mask: 0.4532  decode.d4.loss_dice: 0.4234  decode.d5.loss_cls: 0.1040  decode.d5.loss_mask: 0.4908  decode.d5.loss_dice: 0.4418  decode.d6.loss_cls: 0.0986  decode.d6.loss_mask: 0.4779  decode.d6.loss_dice: 0.4580  decode.d7.loss_cls: 0.1120  decode.d7.loss_mask: 0.4796  decode.d7.loss_dice: 0.4684  decode.d8.loss_cls: 0.1203  decode.d8.loss_mask: 0.5063  decode.d8.loss_dice: 0.4767
2024/04/12 22:14:11 - mmengine - INFO - Iter(train) [12800/20000]  base_lr: 8.7105e-05 lr: 8.7105e-06  eta: 2:19:50  time: 1.1623  data_time: 0.0115  memory: 7963  grad_norm: 161.6173  loss: 9.9870  decode.loss_cls: 0.0238  decode.loss_mask: 0.5590  decode.loss_dice: 0.4041  decode.d0.loss_cls: 0.1679  decode.d0.loss_mask: 0.5771  decode.d0.loss_dice: 0.4296  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 0.4105  decode.d2.loss_cls: 0.0333  decode.d2.loss_mask: 0.5456  decode.d2.loss_dice: 0.4039  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 0.5451  decode.d3.loss_dice: 0.3907  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.5352  decode.d4.loss_dice: 0.3887  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.5478  decode.d5.loss_dice: 0.3907  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.5504  decode.d6.loss_dice: 0.3913  decode.d7.loss_cls: 0.0340  decode.d7.loss_mask: 0.5571  decode.d7.loss_dice: 0.4031  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.5627  decode.d8.loss_dice: 0.4081
2024/04/12 22:16:07 - mmengine - INFO - Iter(train) [12900/20000]  base_lr: 8.7003e-05 lr: 8.7003e-06  eta: 2:17:53  time: 1.1739  data_time: 0.0117  memory: 7967  grad_norm: 228.9199  loss: 13.0845  decode.loss_cls: 0.1245  decode.loss_mask: 0.5858  decode.loss_dice: 0.6055  decode.d0.loss_cls: 0.2273  decode.d0.loss_mask: 0.6009  decode.d0.loss_dice: 0.6109  decode.d1.loss_cls: 0.2136  decode.d1.loss_mask: 0.5820  decode.d1.loss_dice: 0.5812  decode.d2.loss_cls: 0.1550  decode.d2.loss_mask: 0.5707  decode.d2.loss_dice: 0.5882  decode.d3.loss_cls: 0.1282  decode.d3.loss_mask: 0.5619  decode.d3.loss_dice: 0.6067  decode.d4.loss_cls: 0.1178  decode.d4.loss_mask: 0.5765  decode.d4.loss_dice: 0.5752  decode.d5.loss_cls: 0.1360  decode.d5.loss_mask: 0.5714  decode.d5.loss_dice: 0.5753  decode.d6.loss_cls: 0.0992  decode.d6.loss_mask: 0.5688  decode.d6.loss_dice: 0.6073  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 0.5561  decode.d7.loss_dice: 0.5938  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.5720  decode.d8.loss_dice: 0.5694
2024/04/12 22:18:03 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 22:18:03 - mmengine - INFO - Iter(train) [13000/20000]  base_lr: 8.6902e-05 lr: 8.6902e-06  eta: 2:15:57  time: 1.1605  data_time: 0.0113  memory: 7967  grad_norm: 233.2106  loss: 10.2585  decode.loss_cls: 0.0347  decode.loss_mask: 0.5385  decode.loss_dice: 0.4276  decode.d0.loss_cls: 0.1208  decode.d0.loss_mask: 0.5611  decode.d0.loss_dice: 0.4581  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.5468  decode.d1.loss_dice: 0.4455  decode.d2.loss_cls: 0.0318  decode.d2.loss_mask: 0.5370  decode.d2.loss_dice: 0.4373  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.5463  decode.d3.loss_dice: 0.4485  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.5419  decode.d4.loss_dice: 0.4279  decode.d5.loss_cls: 0.0307  decode.d5.loss_mask: 0.5413  decode.d5.loss_dice: 0.4404  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.5416  decode.d6.loss_dice: 0.4469  decode.d7.loss_cls: 0.0409  decode.d7.loss_mask: 0.5467  decode.d7.loss_dice: 0.4377  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.5459  decode.d8.loss_dice: 0.4392
2024/04/12 22:18:05 - mmengine - INFO - per class results:
2024/04/12 22:18:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.73 |  98.6 | 98.34 | 98.34  |   98.08   |  98.6  |
| monolayer  |  87.0 | 92.54 | 93.05 | 93.05  |   93.56   | 92.54  |
|  bilayer   | 73.53 | 84.68 | 84.75 | 84.75  |   84.81   | 84.68  |
| multilayer | 86.25 | 92.54 | 92.62 | 92.62  |   92.69   | 92.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 22:18:05 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.7400  mIoU: 85.8800  mAcc: 92.0900  mDice: 92.1900  mFscore: 92.1900  mPrecision: 92.2900  mRecall: 92.0900  data_time: 0.0120  time: 0.2313
2024/04/12 22:20:02 - mmengine - INFO - Iter(train) [13100/20000]  base_lr: 8.6800e-05 lr: 8.6800e-06  eta: 2:14:00  time: 1.1664  data_time: 0.0123  memory: 7971  grad_norm: 326.5679  loss: 10.3035  decode.loss_cls: 0.0937  decode.loss_mask: 0.4346  decode.loss_dice: 0.5054  decode.d0.loss_cls: 0.1376  decode.d0.loss_mask: 0.4275  decode.d0.loss_dice: 0.5262  decode.d1.loss_cls: 0.0920  decode.d1.loss_mask: 0.4453  decode.d1.loss_dice: 0.5072  decode.d2.loss_cls: 0.1521  decode.d2.loss_mask: 0.4338  decode.d2.loss_dice: 0.4569  decode.d3.loss_cls: 0.1015  decode.d3.loss_mask: 0.4230  decode.d3.loss_dice: 0.4723  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 0.4257  decode.d4.loss_dice: 0.4906  decode.d5.loss_cls: 0.1187  decode.d5.loss_mask: 0.4237  decode.d5.loss_dice: 0.4629  decode.d6.loss_cls: 0.1374  decode.d6.loss_mask: 0.4223  decode.d6.loss_dice: 0.4428  decode.d7.loss_cls: 0.1317  decode.d7.loss_mask: 0.4253  decode.d7.loss_dice: 0.4662  decode.d8.loss_cls: 0.1361  decode.d8.loss_mask: 0.4250  decode.d8.loss_dice: 0.4912
2024/04/12 22:21:58 - mmengine - INFO - Iter(train) [13200/20000]  base_lr: 8.6698e-05 lr: 8.6698e-06  eta: 2:12:04  time: 1.1628  data_time: 0.0113  memory: 7964  grad_norm: 201.2902  loss: 11.2144  decode.loss_cls: 0.1302  decode.loss_mask: 0.5443  decode.loss_dice: 0.4276  decode.d0.loss_cls: 0.2187  decode.d0.loss_mask: 0.5531  decode.d0.loss_dice: 0.4161  decode.d1.loss_cls: 0.1203  decode.d1.loss_mask: 0.5788  decode.d1.loss_dice: 0.4148  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 0.5541  decode.d2.loss_dice: 0.4136  decode.d3.loss_cls: 0.1235  decode.d3.loss_mask: 0.5676  decode.d3.loss_dice: 0.4402  decode.d4.loss_cls: 0.1224  decode.d4.loss_mask: 0.5867  decode.d4.loss_dice: 0.4368  decode.d5.loss_cls: 0.1192  decode.d5.loss_mask: 0.5439  decode.d5.loss_dice: 0.4219  decode.d6.loss_cls: 0.1239  decode.d6.loss_mask: 0.5473  decode.d6.loss_dice: 0.4433  decode.d7.loss_cls: 0.1348  decode.d7.loss_mask: 0.5388  decode.d7.loss_dice: 0.4210  decode.d8.loss_cls: 0.1043  decode.d8.loss_mask: 0.5844  decode.d8.loss_dice: 0.4434
2024/04/12 22:23:54 - mmengine - INFO - Iter(train) [13300/20000]  base_lr: 8.6597e-05 lr: 8.6597e-06  eta: 2:10:07  time: 1.1585  data_time: 0.0114  memory: 7967  grad_norm: 211.5228  loss: 14.8202  decode.loss_cls: 0.1924  decode.loss_mask: 0.6723  decode.loss_dice: 0.6415  decode.d0.loss_cls: 0.3783  decode.d0.loss_mask: 0.6949  decode.d0.loss_dice: 0.6528  decode.d1.loss_cls: 0.1860  decode.d1.loss_mask: 0.6799  decode.d1.loss_dice: 0.5896  decode.d2.loss_cls: 0.1597  decode.d2.loss_mask: 0.6833  decode.d2.loss_dice: 0.6141  decode.d3.loss_cls: 0.1838  decode.d3.loss_mask: 0.6823  decode.d3.loss_dice: 0.5645  decode.d4.loss_cls: 0.1868  decode.d4.loss_mask: 0.6628  decode.d4.loss_dice: 0.6123  decode.d5.loss_cls: 0.1557  decode.d5.loss_mask: 0.6889  decode.d5.loss_dice: 0.6351  decode.d6.loss_cls: 0.1328  decode.d6.loss_mask: 0.6731  decode.d6.loss_dice: 0.6108  decode.d7.loss_cls: 0.1503  decode.d7.loss_mask: 0.6787  decode.d7.loss_dice: 0.6007  decode.d8.loss_cls: 0.1531  decode.d8.loss_mask: 0.6643  decode.d8.loss_dice: 0.6392
2024/04/12 22:25:51 - mmengine - INFO - Iter(train) [13400/20000]  base_lr: 8.6495e-05 lr: 8.6495e-06  eta: 2:08:10  time: 1.1624  data_time: 0.0110  memory: 7963  grad_norm: 245.2111  loss: 10.5547  decode.loss_cls: 0.0405  decode.loss_mask: 0.5338  decode.loss_dice: 0.4646  decode.d0.loss_cls: 0.1394  decode.d0.loss_mask: 0.5477  decode.d0.loss_dice: 0.4681  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.5371  decode.d1.loss_dice: 0.4537  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.5404  decode.d2.loss_dice: 0.4656  decode.d3.loss_cls: 0.0286  decode.d3.loss_mask: 0.5346  decode.d3.loss_dice: 0.4592  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.5373  decode.d4.loss_dice: 0.4744  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 0.5335  decode.d5.loss_dice: 0.4726  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.5486  decode.d6.loss_dice: 0.4753  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.5506  decode.d7.loss_dice: 0.4687  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.5352  decode.d8.loss_dice: 0.4698
2024/04/12 22:27:48 - mmengine - INFO - Iter(train) [13500/20000]  base_lr: 8.6394e-05 lr: 8.6394e-06  eta: 2:06:14  time: 1.1745  data_time: 0.0132  memory: 7963  grad_norm: 176.6096  loss: 8.9681  decode.loss_cls: 0.0280  decode.loss_mask: 0.4795  decode.loss_dice: 0.3785  decode.d0.loss_cls: 0.1295  decode.d0.loss_mask: 0.5079  decode.d0.loss_dice: 0.3763  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.4850  decode.d1.loss_dice: 0.3638  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 0.4899  decode.d2.loss_dice: 0.3734  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.4774  decode.d3.loss_dice: 0.3686  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.4800  decode.d4.loss_dice: 0.3708  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.4888  decode.d5.loss_dice: 0.3737  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.4738  decode.d6.loss_dice: 0.3754  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.4777  decode.d7.loss_dice: 0.3651  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.4828  decode.d8.loss_dice: 0.3708
2024/04/12 22:27:49 - mmengine - INFO - per class results:
2024/04/12 22:27:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.81 |  98.5 | 98.38 | 98.38  |   98.26   |  98.5  |
| monolayer  | 86.58 | 93.14 | 92.81 | 92.81  |   92.48   | 93.14  |
|  bilayer   | 69.24 | 81.03 | 81.82 | 81.82  |   82.63   | 81.03  |
| multilayer | 86.07 | 91.22 | 92.52 | 92.52  |   93.85   | 91.22  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 22:27:49 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.5400  mIoU: 84.6700  mAcc: 90.9700  mDice: 91.3800  mFscore: 91.3800  mPrecision: 91.8000  mRecall: 90.9700  data_time: 0.0105  time: 0.2300
2024/04/12 22:29:46 - mmengine - INFO - Iter(train) [13600/20000]  base_lr: 8.6292e-05 lr: 8.6292e-06  eta: 2:04:17  time: 1.1622  data_time: 0.0111  memory: 7971  grad_norm: 226.9499  loss: 10.0375  decode.loss_cls: 0.1095  decode.loss_mask: 0.4230  decode.loss_dice: 0.4349  decode.d0.loss_cls: 0.3038  decode.d0.loss_mask: 0.4301  decode.d0.loss_dice: 0.4704  decode.d1.loss_cls: 0.1367  decode.d1.loss_mask: 0.4400  decode.d1.loss_dice: 0.4403  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.4357  decode.d2.loss_dice: 0.4393  decode.d3.loss_cls: 0.1318  decode.d3.loss_mask: 0.4412  decode.d3.loss_dice: 0.4213  decode.d4.loss_cls: 0.1321  decode.d4.loss_mask: 0.4203  decode.d4.loss_dice: 0.4206  decode.d5.loss_cls: 0.1226  decode.d5.loss_mask: 0.4202  decode.d5.loss_dice: 0.4453  decode.d6.loss_cls: 0.1221  decode.d6.loss_mask: 0.4175  decode.d6.loss_dice: 0.4303  decode.d7.loss_cls: 0.1382  decode.d7.loss_mask: 0.4138  decode.d7.loss_dice: 0.4463  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.4101  decode.d8.loss_dice: 0.4428
2024/04/12 22:31:42 - mmengine - INFO - Iter(train) [13700/20000]  base_lr: 8.6190e-05 lr: 8.6190e-06  eta: 2:02:21  time: 1.1656  data_time: 0.0112  memory: 7971  grad_norm: 212.9821  loss: 10.5217  decode.loss_cls: 0.0435  decode.loss_mask: 0.5106  decode.loss_dice: 0.4876  decode.d0.loss_cls: 0.1322  decode.d0.loss_mask: 0.5002  decode.d0.loss_dice: 0.4708  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.4898  decode.d1.loss_dice: 0.4978  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.4991  decode.d2.loss_dice: 0.4953  decode.d3.loss_cls: 0.0549  decode.d3.loss_mask: 0.5004  decode.d3.loss_dice: 0.4893  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.5062  decode.d4.loss_dice: 0.4826  decode.d5.loss_cls: 0.0537  decode.d5.loss_mask: 0.5046  decode.d5.loss_dice: 0.4996  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.5091  decode.d6.loss_dice: 0.4895  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.5041  decode.d7.loss_dice: 0.4783  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.4969  decode.d8.loss_dice: 0.4742
2024/04/12 22:33:39 - mmengine - INFO - Iter(train) [13800/20000]  base_lr: 8.6089e-05 lr: 8.6089e-06  eta: 2:00:24  time: 1.1642  data_time: 0.0130  memory: 7963  grad_norm: 206.9082  loss: 9.2235  decode.loss_cls: 0.0121  decode.loss_mask: 0.4640  decode.loss_dice: 0.4135  decode.d0.loss_cls: 0.1621  decode.d0.loss_mask: 0.4700  decode.d0.loss_dice: 0.4496  decode.d1.loss_cls: 0.0514  decode.d1.loss_mask: 0.4668  decode.d1.loss_dice: 0.4314  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.4731  decode.d2.loss_dice: 0.4204  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.4668  decode.d3.loss_dice: 0.4282  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.4638  decode.d4.loss_dice: 0.4175  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.4662  decode.d5.loss_dice: 0.4070  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.4697  decode.d6.loss_dice: 0.4240  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.4704  decode.d7.loss_dice: 0.4272  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.4656  decode.d8.loss_dice: 0.4087
2024/04/12 22:35:36 - mmengine - INFO - Iter(train) [13900/20000]  base_lr: 8.5987e-05 lr: 8.5987e-06  eta: 1:58:28  time: 1.1651  data_time: 0.0113  memory: 7963  grad_norm: 188.8182  loss: 10.1451  decode.loss_cls: 0.1093  decode.loss_mask: 0.5051  decode.loss_dice: 0.3966  decode.d0.loss_cls: 0.1729  decode.d0.loss_mask: 0.5280  decode.d0.loss_dice: 0.4429  decode.d1.loss_cls: 0.1053  decode.d1.loss_mask: 0.5025  decode.d1.loss_dice: 0.4205  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.4979  decode.d2.loss_dice: 0.3775  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.5049  decode.d3.loss_dice: 0.3869  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.5106  decode.d4.loss_dice: 0.4198  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.5125  decode.d5.loss_dice: 0.3864  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.5251  decode.d6.loss_dice: 0.4220  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.5295  decode.d7.loss_dice: 0.4264  decode.d8.loss_cls: 0.1006  decode.d8.loss_mask: 0.5074  decode.d8.loss_dice: 0.4003
2024/04/12 22:37:32 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 22:37:32 - mmengine - INFO - Iter(train) [14000/20000]  base_lr: 8.5885e-05 lr: 8.5885e-06  eta: 1:56:32  time: 1.1760  data_time: 0.0132  memory: 7968  grad_norm: 163.0792  loss: 10.2777  decode.loss_cls: 0.0834  decode.loss_mask: 0.4787  decode.loss_dice: 0.4388  decode.d0.loss_cls: 0.2205  decode.d0.loss_mask: 0.5095  decode.d0.loss_dice: 0.4747  decode.d1.loss_cls: 0.1151  decode.d1.loss_mask: 0.4929  decode.d1.loss_dice: 0.4442  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.4872  decode.d2.loss_dice: 0.4452  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.4886  decode.d3.loss_dice: 0.4482  decode.d4.loss_cls: 0.0992  decode.d4.loss_mask: 0.4905  decode.d4.loss_dice: 0.4444  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.4906  decode.d5.loss_dice: 0.4376  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.4939  decode.d6.loss_dice: 0.4433  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.4921  decode.d7.loss_dice: 0.4528  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.4886  decode.d8.loss_dice: 0.4497
2024/04/12 22:37:34 - mmengine - INFO - per class results:
2024/04/12 22:37:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.87 | 98.66 | 98.41 | 98.41  |   98.16   | 98.66  |
| monolayer  |  87.4 | 92.71 | 93.28 | 93.28  |   93.85   | 92.71  |
|  bilayer   | 75.84 | 87.16 | 86.26 | 86.26  |   85.37   | 87.16  |
| multilayer | 85.53 | 91.74 |  92.2 |  92.2  |   92.67   | 91.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 22:37:34 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8800  mIoU: 86.4100  mAcc: 92.5700  mDice: 92.5400  mFscore: 92.5400  mPrecision: 92.5100  mRecall: 92.5700  data_time: 0.0144  time: 0.2339
2024/04/12 22:39:31 - mmengine - INFO - Iter(train) [14100/20000]  base_lr: 8.5783e-05 lr: 8.5783e-06  eta: 1:54:35  time: 1.1602  data_time: 0.0134  memory: 7964  grad_norm: 224.8026  loss: 12.4765  decode.loss_cls: 0.1473  decode.loss_mask: 0.4744  decode.loss_dice: 0.5425  decode.d0.loss_cls: 0.2227  decode.d0.loss_mask: 0.5494  decode.d0.loss_dice: 0.6357  decode.d1.loss_cls: 0.1744  decode.d1.loss_mask: 0.4601  decode.d1.loss_dice: 0.5529  decode.d2.loss_cls: 0.1711  decode.d2.loss_mask: 0.4875  decode.d2.loss_dice: 0.5691  decode.d3.loss_cls: 0.1903  decode.d3.loss_mask: 0.4922  decode.d3.loss_dice: 0.5817  decode.d4.loss_cls: 0.2078  decode.d4.loss_mask: 0.4937  decode.d4.loss_dice: 0.5230  decode.d5.loss_cls: 0.1463  decode.d5.loss_mask: 0.4852  decode.d5.loss_dice: 0.5977  decode.d6.loss_cls: 0.1851  decode.d6.loss_mask: 0.4839  decode.d6.loss_dice: 0.5769  decode.d7.loss_cls: 0.1681  decode.d7.loss_mask: 0.4938  decode.d7.loss_dice: 0.6003  decode.d8.loss_cls: 0.2121  decode.d8.loss_mask: 0.4869  decode.d8.loss_dice: 0.5646
2024/04/12 22:41:27 - mmengine - INFO - Iter(train) [14200/20000]  base_lr: 8.5682e-05 lr: 8.5682e-06  eta: 1:52:38  time: 1.1647  data_time: 0.0114  memory: 7968  grad_norm: 146.8218  loss: 10.3399  decode.loss_cls: 0.0457  decode.loss_mask: 0.4728  decode.loss_dice: 0.4754  decode.d0.loss_cls: 0.1686  decode.d0.loss_mask: 0.5360  decode.d0.loss_dice: 0.5506  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.4684  decode.d1.loss_dice: 0.4405  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.4658  decode.d2.loss_dice: 0.4728  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.4708  decode.d3.loss_dice: 0.4998  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.4679  decode.d4.loss_dice: 0.4962  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.4686  decode.d5.loss_dice: 0.4836  decode.d6.loss_cls: 0.0796  decode.d6.loss_mask: 0.4718  decode.d6.loss_dice: 0.4737  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.4708  decode.d7.loss_dice: 0.4525  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.4754  decode.d8.loss_dice: 0.4695
2024/04/12 22:43:23 - mmengine - INFO - Iter(train) [14300/20000]  base_lr: 8.5580e-05 lr: 8.5580e-06  eta: 1:50:42  time: 1.1679  data_time: 0.0127  memory: 7967  grad_norm: 172.8074  loss: 9.8283  decode.loss_cls: 0.0326  decode.loss_mask: 0.5025  decode.loss_dice: 0.4093  decode.d0.loss_cls: 0.1764  decode.d0.loss_mask: 0.5239  decode.d0.loss_dice: 0.4228  decode.d1.loss_cls: 0.0499  decode.d1.loss_mask: 0.5005  decode.d1.loss_dice: 0.4129  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.4908  decode.d2.loss_dice: 0.4208  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.4954  decode.d3.loss_dice: 0.4158  decode.d4.loss_cls: 0.0483  decode.d4.loss_mask: 0.5046  decode.d4.loss_dice: 0.4238  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.5182  decode.d5.loss_dice: 0.4457  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.5397  decode.d6.loss_dice: 0.4266  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.4957  decode.d7.loss_dice: 0.4132  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.4914  decode.d8.loss_dice: 0.4245
2024/04/12 22:45:20 - mmengine - INFO - Iter(train) [14400/20000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 1:48:45  time: 1.1739  data_time: 0.0138  memory: 7967  grad_norm: 165.7702  loss: 12.0166  decode.loss_cls: 0.0741  decode.loss_mask: 0.5688  decode.loss_dice: 0.5244  decode.d0.loss_cls: 0.2071  decode.d0.loss_mask: 0.5900  decode.d0.loss_dice: 0.5348  decode.d1.loss_cls: 0.1082  decode.d1.loss_mask: 0.5757  decode.d1.loss_dice: 0.5096  decode.d2.loss_cls: 0.1099  decode.d2.loss_mask: 0.5713  decode.d2.loss_dice: 0.5028  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.5902  decode.d3.loss_dice: 0.5295  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.5612  decode.d4.loss_dice: 0.5153  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.5781  decode.d5.loss_dice: 0.5207  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.6355  decode.d6.loss_dice: 0.5423  decode.d7.loss_cls: 0.0484  decode.d7.loss_mask: 0.6315  decode.d7.loss_dice: 0.5213  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.5821  decode.d8.loss_dice: 0.5282
2024/04/12 22:47:17 - mmengine - INFO - Iter(train) [14500/20000]  base_lr: 8.5376e-05 lr: 8.5376e-06  eta: 1:46:49  time: 1.1699  data_time: 0.0119  memory: 7967  grad_norm: 146.7684  loss: 10.3494  decode.loss_cls: 0.0747  decode.loss_mask: 0.4874  decode.loss_dice: 0.4378  decode.d0.loss_cls: 0.2056  decode.d0.loss_mask: 0.5152  decode.d0.loss_dice: 0.4611  decode.d1.loss_cls: 0.0831  decode.d1.loss_mask: 0.4862  decode.d1.loss_dice: 0.4272  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.4952  decode.d2.loss_dice: 0.4440  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.4763  decode.d3.loss_dice: 0.4394  decode.d4.loss_cls: 0.0758  decode.d4.loss_mask: 0.4902  decode.d4.loss_dice: 0.4376  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.5046  decode.d5.loss_dice: 0.4587  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.5239  decode.d6.loss_dice: 0.4573  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.4979  decode.d7.loss_dice: 0.4559  decode.d8.loss_cls: 0.0749  decode.d8.loss_mask: 0.4974  decode.d8.loss_dice: 0.4467
2024/04/12 22:47:19 - mmengine - INFO - per class results:
2024/04/12 22:47:19 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 95.61 | 98.56 | 97.76 | 97.76  |   96.97   | 98.56  |
| monolayer  | 83.89 | 90.14 | 91.24 | 91.24  |   92.37   | 90.14  |
|  bilayer   | 70.01 | 79.91 | 82.36 | 82.36  |   84.97   | 79.91  |
| multilayer | 86.49 | 92.62 | 92.76 | 92.76  |    92.9   | 92.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 22:47:19 - mmengine - INFO - Iter(val) [8/8]    aAcc: 94.8400  mIoU: 84.0000  mAcc: 90.3100  mDice: 91.0300  mFscore: 91.0300  mPrecision: 91.8000  mRecall: 90.3100  data_time: 0.0126  time: 0.2322
2024/04/12 22:49:15 - mmengine - INFO - Iter(train) [14600/20000]  base_lr: 8.5275e-05 lr: 8.5275e-06  eta: 1:44:52  time: 1.1725  data_time: 0.0115  memory: 7968  grad_norm: 165.2645  loss: 9.6393  decode.loss_cls: 0.0188  decode.loss_mask: 0.5086  decode.loss_dice: 0.4106  decode.d0.loss_cls: 0.1106  decode.d0.loss_mask: 0.5209  decode.d0.loss_dice: 0.4155  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.5135  decode.d1.loss_dice: 0.4065  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.5010  decode.d2.loss_dice: 0.4071  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.5065  decode.d3.loss_dice: 0.3971  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.5118  decode.d4.loss_dice: 0.3888  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.5150  decode.d5.loss_dice: 0.4120  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.5096  decode.d6.loss_dice: 0.3932  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 0.5152  decode.d7.loss_dice: 0.3879  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.5127  decode.d8.loss_dice: 0.3960
2024/04/12 22:51:12 - mmengine - INFO - Iter(train) [14700/20000]  base_lr: 8.5173e-05 lr: 8.5173e-06  eta: 1:42:56  time: 1.1685  data_time: 0.0124  memory: 7964  grad_norm: 173.6149  loss: 9.5806  decode.loss_cls: 0.0491  decode.loss_mask: 0.4373  decode.loss_dice: 0.4613  decode.d0.loss_cls: 0.1704  decode.d0.loss_mask: 0.4631  decode.d0.loss_dice: 0.4502  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.4425  decode.d1.loss_dice: 0.4256  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 0.4404  decode.d2.loss_dice: 0.4205  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.4420  decode.d3.loss_dice: 0.4135  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.4321  decode.d4.loss_dice: 0.4547  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.4490  decode.d5.loss_dice: 0.4305  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.4642  decode.d6.loss_dice: 0.4376  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.4607  decode.d7.loss_dice: 0.4427  decode.d8.loss_cls: 0.0717  decode.d8.loss_mask: 0.4441  decode.d8.loss_dice: 0.4283
2024/04/12 22:53:08 - mmengine - INFO - Iter(train) [14800/20000]  base_lr: 8.5071e-05 lr: 8.5071e-06  eta: 1:40:59  time: 1.1596  data_time: 0.0119  memory: 7963  grad_norm: 239.2339  loss: 9.4993  decode.loss_cls: 0.0610  decode.loss_mask: 0.4117  decode.loss_dice: 0.4418  decode.d0.loss_cls: 0.2022  decode.d0.loss_mask: 0.4281  decode.d0.loss_dice: 0.4517  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.4456  decode.d1.loss_dice: 0.4761  decode.d2.loss_cls: 0.0840  decode.d2.loss_mask: 0.4228  decode.d2.loss_dice: 0.4423  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.4298  decode.d3.loss_dice: 0.4623  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.4131  decode.d4.loss_dice: 0.4578  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.4138  decode.d5.loss_dice: 0.4525  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.4187  decode.d6.loss_dice: 0.4514  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.4264  decode.d7.loss_dice: 0.4614  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 0.4113  decode.d8.loss_dice: 0.4457
2024/04/12 22:55:04 - mmengine - INFO - Iter(train) [14900/20000]  base_lr: 8.4969e-05 lr: 8.4969e-06  eta: 1:39:02  time: 1.1610  data_time: 0.0114  memory: 7968  grad_norm: 185.4801  loss: 6.7542  decode.loss_cls: 0.0121  decode.loss_mask: 0.3459  decode.loss_dice: 0.2983  decode.d0.loss_cls: 0.1380  decode.d0.loss_mask: 0.3582  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.3520  decode.d1.loss_dice: 0.2945  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.3513  decode.d2.loss_dice: 0.3005  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.3449  decode.d3.loss_dice: 0.2963  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.3506  decode.d4.loss_dice: 0.2735  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.3482  decode.d5.loss_dice: 0.2781  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.3441  decode.d6.loss_dice: 0.2897  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.3452  decode.d7.loss_dice: 0.2843  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.3482  decode.d8.loss_dice: 0.2848
2024/04/12 22:57:00 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 22:57:00 - mmengine - INFO - Iter(train) [15000/20000]  base_lr: 8.4867e-05 lr: 8.4867e-06  eta: 1:37:06  time: 1.1581  data_time: 0.0116  memory: 7965  grad_norm: 203.4096  loss: 11.2342  decode.loss_cls: 0.0693  decode.loss_mask: 0.5853  decode.loss_dice: 0.4739  decode.d0.loss_cls: 0.1138  decode.d0.loss_mask: 0.5941  decode.d0.loss_dice: 0.4938  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.5888  decode.d1.loss_dice: 0.4894  decode.d2.loss_cls: 0.0623  decode.d2.loss_mask: 0.5797  decode.d2.loss_dice: 0.4727  decode.d3.loss_cls: 0.0392  decode.d3.loss_mask: 0.5604  decode.d3.loss_dice: 0.4718  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 0.5599  decode.d4.loss_dice: 0.4443  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.5779  decode.d5.loss_dice: 0.4779  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.5688  decode.d6.loss_dice: 0.4772  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.5765  decode.d7.loss_dice: 0.4755  decode.d8.loss_cls: 0.0691  decode.d8.loss_mask: 0.5915  decode.d8.loss_dice: 0.4929
2024/04/12 22:57:00 - mmengine - INFO - Saving checkpoint at 15000 iterations
2024/04/12 22:57:04 - mmengine - INFO - per class results:
2024/04/12 22:57:04 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.82 | 98.58 | 98.38 | 98.38  |   98.19   | 98.58  |
| monolayer  | 87.54 | 93.07 | 93.36 | 93.36  |   93.64   | 93.07  |
|  bilayer   | 74.87 | 85.03 | 85.63 | 85.63  |   86.24   | 85.03  |
| multilayer | 86.06 | 92.51 | 92.51 | 92.51  |   92.51   | 92.51  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 22:57:04 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8900  mIoU: 86.3200  mAcc: 92.3000  mDice: 92.4700  mFscore: 92.4700  mPrecision: 92.6400  mRecall: 92.3000  data_time: 0.0113  time: 0.2305
2024/04/12 22:59:01 - mmengine - INFO - Iter(train) [15100/20000]  base_lr: 8.4766e-05 lr: 8.4766e-06  eta: 1:35:09  time: 1.1631  data_time: 0.0119  memory: 7967  grad_norm: 382.3526  loss: 12.3457  decode.loss_cls: 0.1515  decode.loss_mask: 0.5730  decode.loss_dice: 0.4973  decode.d0.loss_cls: 0.2979  decode.d0.loss_mask: 0.5739  decode.d0.loss_dice: 0.5111  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 0.5786  decode.d1.loss_dice: 0.4779  decode.d2.loss_cls: 0.1497  decode.d2.loss_mask: 0.5645  decode.d2.loss_dice: 0.4601  decode.d3.loss_cls: 0.1611  decode.d3.loss_mask: 0.5591  decode.d3.loss_dice: 0.5007  decode.d4.loss_cls: 0.1424  decode.d4.loss_mask: 0.5661  decode.d4.loss_dice: 0.4746  decode.d5.loss_cls: 0.1554  decode.d5.loss_mask: 0.5794  decode.d5.loss_dice: 0.5070  decode.d6.loss_cls: 0.1556  decode.d6.loss_mask: 0.5675  decode.d6.loss_dice: 0.4747  decode.d7.loss_cls: 0.1717  decode.d7.loss_mask: 0.5857  decode.d7.loss_dice: 0.5123  decode.d8.loss_cls: 0.1803  decode.d8.loss_mask: 0.5615  decode.d8.loss_dice: 0.4956
2024/04/12 23:00:57 - mmengine - INFO - Iter(train) [15200/20000]  base_lr: 8.4664e-05 lr: 8.4664e-06  eta: 1:33:13  time: 1.1693  data_time: 0.0128  memory: 7968  grad_norm: 167.0042  loss: 9.9342  decode.loss_cls: 0.1015  decode.loss_mask: 0.4562  decode.loss_dice: 0.4267  decode.d0.loss_cls: 0.1964  decode.d0.loss_mask: 0.4612  decode.d0.loss_dice: 0.4279  decode.d1.loss_cls: 0.1445  decode.d1.loss_mask: 0.4716  decode.d1.loss_dice: 0.4219  decode.d2.loss_cls: 0.1453  decode.d2.loss_mask: 0.4493  decode.d2.loss_dice: 0.4407  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.4453  decode.d3.loss_dice: 0.4140  decode.d4.loss_cls: 0.0983  decode.d4.loss_mask: 0.4407  decode.d4.loss_dice: 0.4266  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.4445  decode.d5.loss_dice: 0.4087  decode.d6.loss_cls: 0.1340  decode.d6.loss_mask: 0.4379  decode.d6.loss_dice: 0.4123  decode.d7.loss_cls: 0.0950  decode.d7.loss_mask: 0.4565  decode.d7.loss_dice: 0.4107  decode.d8.loss_cls: 0.0784  decode.d8.loss_mask: 0.4586  decode.d8.loss_dice: 0.4298
2024/04/12 23:02:53 - mmengine - INFO - Iter(train) [15300/20000]  base_lr: 8.4562e-05 lr: 8.4562e-06  eta: 1:31:16  time: 1.1650  data_time: 0.0111  memory: 7963  grad_norm: 183.4891  loss: 6.6049  decode.loss_cls: 0.0087  decode.loss_mask: 0.3293  decode.loss_dice: 0.2965  decode.d0.loss_cls: 0.0984  decode.d0.loss_mask: 0.3456  decode.d0.loss_dice: 0.3219  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.3279  decode.d1.loss_dice: 0.3139  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.3333  decode.d2.loss_dice: 0.3037  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.3290  decode.d3.loss_dice: 0.3086  decode.d4.loss_cls: 0.0316  decode.d4.loss_mask: 0.3289  decode.d4.loss_dice: 0.3015  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.3325  decode.d5.loss_dice: 0.3102  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.3093  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.3330  decode.d7.loss_dice: 0.3056  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.3295  decode.d8.loss_dice: 0.3021
2024/04/12 23:04:50 - mmengine - INFO - Iter(train) [15400/20000]  base_lr: 8.4460e-05 lr: 8.4460e-06  eta: 1:29:20  time: 1.1718  data_time: 0.0134  memory: 7963  grad_norm: 228.6449  loss: 15.9288  decode.loss_cls: 0.2363  decode.loss_mask: 0.7023  decode.loss_dice: 0.6058  decode.d0.loss_cls: 0.4123  decode.d0.loss_mask: 0.6652  decode.d0.loss_dice: 0.6581  decode.d1.loss_cls: 0.2670  decode.d1.loss_mask: 0.6543  decode.d1.loss_dice: 0.6300  decode.d2.loss_cls: 0.2269  decode.d2.loss_mask: 0.7036  decode.d2.loss_dice: 0.6411  decode.d3.loss_cls: 0.2445  decode.d3.loss_mask: 0.6826  decode.d3.loss_dice: 0.6395  decode.d4.loss_cls: 0.2559  decode.d4.loss_mask: 0.6833  decode.d4.loss_dice: 0.6364  decode.d5.loss_cls: 0.2654  decode.d5.loss_mask: 0.7093  decode.d5.loss_dice: 0.6583  decode.d6.loss_cls: 0.2467  decode.d6.loss_mask: 0.6905  decode.d6.loss_dice: 0.6233  decode.d7.loss_cls: 0.2404  decode.d7.loss_mask: 0.7106  decode.d7.loss_dice: 0.6301  decode.d8.loss_cls: 0.2370  decode.d8.loss_mask: 0.7383  decode.d8.loss_dice: 0.6336
2024/04/12 23:06:46 - mmengine - INFO - Iter(train) [15500/20000]  base_lr: 8.4358e-05 lr: 8.4358e-06  eta: 1:27:23  time: 1.1653  data_time: 0.0115  memory: 7967  grad_norm: 169.5035  loss: 10.6095  decode.loss_cls: 0.0480  decode.loss_mask: 0.5603  decode.loss_dice: 0.4555  decode.d0.loss_cls: 0.1272  decode.d0.loss_mask: 0.5712  decode.d0.loss_dice: 0.4522  decode.d1.loss_cls: 0.0548  decode.d1.loss_mask: 0.5543  decode.d1.loss_dice: 0.4238  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.5606  decode.d2.loss_dice: 0.4744  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.5547  decode.d3.loss_dice: 0.4401  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.5532  decode.d4.loss_dice: 0.4289  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.5404  decode.d5.loss_dice: 0.4299  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.5605  decode.d6.loss_dice: 0.4450  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.5614  decode.d7.loss_dice: 0.4527  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.5971  decode.d8.loss_dice: 0.4351
2024/04/12 23:06:48 - mmengine - INFO - per class results:
2024/04/12 23:06:48 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.97 | 98.58 | 98.46 | 98.46  |   98.35   | 98.58  |
| monolayer  | 87.83 | 93.31 | 93.52 | 93.52  |   93.73   | 93.31  |
|  bilayer   | 75.64 | 85.89 | 86.13 | 86.13  |   86.37   | 85.89  |
| multilayer | 85.56 | 92.26 | 92.22 | 92.22  |   92.18   | 92.26  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 23:06:48 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.9700  mIoU: 86.5000  mAcc: 92.5100  mDice: 92.5800  mFscore: 92.5800  mPrecision: 92.6600  mRecall: 92.5100  data_time: 0.0114  time: 0.2311
2024/04/12 23:08:45 - mmengine - INFO - Iter(train) [15600/20000]  base_lr: 8.4256e-05 lr: 8.4256e-06  eta: 1:25:26  time: 1.1612  data_time: 0.0121  memory: 7967  grad_norm: 282.4217  loss: 9.9924  decode.loss_cls: 0.0645  decode.loss_mask: 0.4854  decode.loss_dice: 0.4353  decode.d0.loss_cls: 0.1857  decode.d0.loss_mask: 0.5049  decode.d0.loss_dice: 0.4370  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 0.4913  decode.d1.loss_dice: 0.4368  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.4917  decode.d2.loss_dice: 0.4356  decode.d3.loss_cls: 0.0912  decode.d3.loss_mask: 0.4779  decode.d3.loss_dice: 0.3855  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.4782  decode.d4.loss_dice: 0.4264  decode.d5.loss_cls: 0.1104  decode.d5.loss_mask: 0.4928  decode.d5.loss_dice: 0.4243  decode.d6.loss_cls: 0.0900  decode.d6.loss_mask: 0.4886  decode.d6.loss_dice: 0.3912  decode.d7.loss_cls: 0.0861  decode.d7.loss_mask: 0.4898  decode.d7.loss_dice: 0.4172  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.4820  decode.d8.loss_dice: 0.3749
2024/04/12 23:10:41 - mmengine - INFO - Iter(train) [15700/20000]  base_lr: 8.4154e-05 lr: 8.4154e-06  eta: 1:23:30  time: 1.1603  data_time: 0.0126  memory: 7968  grad_norm: 191.1999  loss: 8.6472  decode.loss_cls: 0.0221  decode.loss_mask: 0.4209  decode.loss_dice: 0.3920  decode.d0.loss_cls: 0.1147  decode.d0.loss_mask: 0.4272  decode.d0.loss_dice: 0.4179  decode.d1.loss_cls: 0.0553  decode.d1.loss_mask: 0.4166  decode.d1.loss_dice: 0.3814  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.4218  decode.d2.loss_dice: 0.3982  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.4271  decode.d3.loss_dice: 0.3997  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.4255  decode.d4.loss_dice: 0.4096  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.4218  decode.d5.loss_dice: 0.3953  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.4201  decode.d6.loss_dice: 0.3950  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.4199  decode.d7.loss_dice: 0.3928  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.4193  decode.d8.loss_dice: 0.3925
2024/04/12 23:12:38 - mmengine - INFO - Iter(train) [15800/20000]  base_lr: 8.4052e-05 lr: 8.4052e-06  eta: 1:21:33  time: 1.1598  data_time: 0.0120  memory: 7967  grad_norm: 181.6052  loss: 8.7448  decode.loss_cls: 0.0048  decode.loss_mask: 0.4488  decode.loss_dice: 0.4055  decode.d0.loss_cls: 0.1296  decode.d0.loss_mask: 0.4594  decode.d0.loss_dice: 0.3842  decode.d1.loss_cls: 0.0516  decode.d1.loss_mask: 0.4496  decode.d1.loss_dice: 0.3889  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.4475  decode.d2.loss_dice: 0.4163  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.4546  decode.d3.loss_dice: 0.4112  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.4453  decode.d4.loss_dice: 0.3828  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.4436  decode.d5.loss_dice: 0.3908  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.4534  decode.d6.loss_dice: 0.4074  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.4575  decode.d7.loss_dice: 0.4049  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.4448  decode.d8.loss_dice: 0.4101
2024/04/12 23:14:34 - mmengine - INFO - Iter(train) [15900/20000]  base_lr: 8.3950e-05 lr: 8.3950e-06  eta: 1:19:37  time: 1.1575  data_time: 0.0117  memory: 7967  grad_norm: 158.3809  loss: 10.8183  decode.loss_cls: 0.0756  decode.loss_mask: 0.5136  decode.loss_dice: 0.4805  decode.d0.loss_cls: 0.2525  decode.d0.loss_mask: 0.5231  decode.d0.loss_dice: 0.4972  decode.d1.loss_cls: 0.1254  decode.d1.loss_mask: 0.4984  decode.d1.loss_dice: 0.4524  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.4958  decode.d2.loss_dice: 0.4686  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.5051  decode.d3.loss_dice: 0.4662  decode.d4.loss_cls: 0.0854  decode.d4.loss_mask: 0.5082  decode.d4.loss_dice: 0.4839  decode.d5.loss_cls: 0.1037  decode.d5.loss_mask: 0.5029  decode.d5.loss_dice: 0.4554  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.5053  decode.d6.loss_dice: 0.4675  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.5030  decode.d7.loss_dice: 0.4774  decode.d8.loss_cls: 0.0868  decode.d8.loss_mask: 0.4981  decode.d8.loss_dice: 0.4706
2024/04/12 23:16:30 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 23:16:30 - mmengine - INFO - Iter(train) [16000/20000]  base_lr: 8.3848e-05 lr: 8.3848e-06  eta: 1:17:40  time: 1.1617  data_time: 0.0116  memory: 7968  grad_norm: 124.0682  loss: 7.7006  decode.loss_cls: 0.0120  decode.loss_mask: 0.3896  decode.loss_dice: 0.3567  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.3944  decode.d0.loss_dice: 0.3527  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.3913  decode.d1.loss_dice: 0.3516  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.3917  decode.d2.loss_dice: 0.3460  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.3870  decode.d3.loss_dice: 0.3312  decode.d4.loss_cls: 0.0311  decode.d4.loss_mask: 0.3842  decode.d4.loss_dice: 0.3468  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.3889  decode.d5.loss_dice: 0.3475  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.3897  decode.d6.loss_dice: 0.3436  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.3908  decode.d7.loss_dice: 0.3543  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.3856  decode.d8.loss_dice: 0.3446
2024/04/12 23:16:32 - mmengine - INFO - per class results:
2024/04/12 23:16:32 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.76 |  98.6 | 98.35 | 98.35  |   98.11   |  98.6  |
| monolayer  | 87.71 | 92.96 | 93.45 | 93.45  |   93.96   | 92.96  |
|  bilayer   | 75.77 | 86.23 | 86.22 | 86.22  |   86.21   | 86.23  |
| multilayer | 86.62 | 92.76 | 92.83 | 92.83  |    92.9   | 92.76  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 23:16:32 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.9500  mIoU: 86.7100  mAcc: 92.6400  mDice: 92.7100  mFscore: 92.7100  mPrecision: 92.7900  mRecall: 92.6400  data_time: 0.0116  time: 0.2317
2024/04/12 23:18:29 - mmengine - INFO - Iter(train) [16100/20000]  base_lr: 8.3746e-05 lr: 8.3746e-06  eta: 1:15:44  time: 1.1711  data_time: 0.0138  memory: 7964  grad_norm: 197.2720  loss: 12.9511  decode.loss_cls: 0.1285  decode.loss_mask: 0.5975  decode.loss_dice: 0.5139  decode.d0.loss_cls: 0.4344  decode.d0.loss_mask: 0.5990  decode.d0.loss_dice: 0.4899  decode.d1.loss_cls: 0.1715  decode.d1.loss_mask: 0.5981  decode.d1.loss_dice: 0.5104  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 0.6180  decode.d2.loss_dice: 0.4849  decode.d3.loss_cls: 0.1631  decode.d3.loss_mask: 0.6081  decode.d3.loss_dice: 0.5023  decode.d4.loss_cls: 0.1516  decode.d4.loss_mask: 0.5958  decode.d4.loss_dice: 0.4957  decode.d5.loss_cls: 0.1500  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 0.5203  decode.d6.loss_cls: 0.1564  decode.d6.loss_mask: 0.6051  decode.d6.loss_dice: 0.5308  decode.d7.loss_cls: 0.1310  decode.d7.loss_mask: 0.6117  decode.d7.loss_dice: 0.5503  decode.d8.loss_cls: 0.1459  decode.d8.loss_mask: 0.6081  decode.d8.loss_dice: 0.5365
2024/04/12 23:20:26 - mmengine - INFO - Iter(train) [16200/20000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 1:13:47  time: 1.1664  data_time: 0.0115  memory: 7971  grad_norm: 186.2760  loss: 10.5073  decode.loss_cls: 0.0907  decode.loss_mask: 0.4809  decode.loss_dice: 0.4436  decode.d0.loss_cls: 0.2130  decode.d0.loss_mask: 0.5015  decode.d0.loss_dice: 0.4614  decode.d1.loss_cls: 0.1689  decode.d1.loss_mask: 0.4884  decode.d1.loss_dice: 0.4492  decode.d2.loss_cls: 0.1009  decode.d2.loss_mask: 0.4837  decode.d2.loss_dice: 0.4448  decode.d3.loss_cls: 0.1309  decode.d3.loss_mask: 0.4897  decode.d3.loss_dice: 0.4825  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.4726  decode.d4.loss_dice: 0.4389  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.4639  decode.d5.loss_dice: 0.4349  decode.d6.loss_cls: 0.1171  decode.d6.loss_mask: 0.4666  decode.d6.loss_dice: 0.4538  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 0.4666  decode.d7.loss_dice: 0.4461  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.4767  decode.d8.loss_dice: 0.4564
2024/04/12 23:22:22 - mmengine - INFO - Iter(train) [16300/20000]  base_lr: 8.3542e-05 lr: 8.3542e-06  eta: 1:11:51  time: 1.1688  data_time: 0.0107  memory: 7967  grad_norm: 176.2302  loss: 10.1598  decode.loss_cls: 0.0519  decode.loss_mask: 0.4868  decode.loss_dice: 0.4405  decode.d0.loss_cls: 0.1234  decode.d0.loss_mask: 0.5116  decode.d0.loss_dice: 0.4752  decode.d1.loss_cls: 0.0907  decode.d1.loss_mask: 0.4879  decode.d1.loss_dice: 0.4488  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 0.4906  decode.d2.loss_dice: 0.4258  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.4945  decode.d3.loss_dice: 0.4298  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.5047  decode.d4.loss_dice: 0.4451  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.4981  decode.d5.loss_dice: 0.4645  decode.d6.loss_cls: 0.0697  decode.d6.loss_mask: 0.4949  decode.d6.loss_dice: 0.4429  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.4903  decode.d7.loss_dice: 0.4223  decode.d8.loss_cls: 0.0672  decode.d8.loss_mask: 0.4901  decode.d8.loss_dice: 0.4422
2024/04/12 23:24:18 - mmengine - INFO - Iter(train) [16400/20000]  base_lr: 8.3440e-05 lr: 8.3440e-06  eta: 1:09:54  time: 1.1678  data_time: 0.0115  memory: 7967  grad_norm: 176.8996  loss: 6.3444  decode.loss_cls: 0.0230  decode.loss_mask: 0.3460  decode.loss_dice: 0.2411  decode.d0.loss_cls: 0.1039  decode.d0.loss_mask: 0.3503  decode.d0.loss_dice: 0.2614  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.3496  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 0.3521  decode.d2.loss_dice: 0.2509  decode.d3.loss_cls: 0.0353  decode.d3.loss_mask: 0.3531  decode.d3.loss_dice: 0.2524  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.3508  decode.d4.loss_dice: 0.2433  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.3485  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.3490  decode.d6.loss_dice: 0.2486  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.3482  decode.d7.loss_dice: 0.2610  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.3462  decode.d8.loss_dice: 0.2456
2024/04/12 23:26:15 - mmengine - INFO - Iter(train) [16500/20000]  base_lr: 8.3338e-05 lr: 8.3338e-06  eta: 1:07:58  time: 1.1617  data_time: 0.0116  memory: 7964  grad_norm: 157.1692  loss: 7.6912  decode.loss_cls: 0.0232  decode.loss_mask: 0.4073  decode.loss_dice: 0.3452  decode.d0.loss_cls: 0.1281  decode.d0.loss_mask: 0.3976  decode.d0.loss_dice: 0.3518  decode.d1.loss_cls: 0.0352  decode.d1.loss_mask: 0.3865  decode.d1.loss_dice: 0.3298  decode.d2.loss_cls: 0.0232  decode.d2.loss_mask: 0.3891  decode.d2.loss_dice: 0.3304  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.4050  decode.d3.loss_dice: 0.3426  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.3989  decode.d4.loss_dice: 0.3345  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.3896  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.3827  decode.d6.loss_dice: 0.3352  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.3945  decode.d7.loss_dice: 0.3475  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.4000  decode.d8.loss_dice: 0.3437
2024/04/12 23:26:17 - mmengine - INFO - per class results:
2024/04/12 23:26:17 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 95.53 | 98.76 | 97.71 | 97.71  |   96.68   | 98.76  |
| monolayer  | 83.57 | 89.32 | 91.05 | 91.05  |   92.85   | 89.32  |
|  bilayer   | 70.75 | 80.56 | 82.87 | 82.87  |   85.32   | 80.56  |
| multilayer | 86.26 | 92.75 | 92.62 | 92.62  |    92.5   | 92.75  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 23:26:17 - mmengine - INFO - Iter(val) [8/8]    aAcc: 94.7800  mIoU: 84.0300  mAcc: 90.3500  mDice: 91.0600  mFscore: 91.0600  mPrecision: 91.8400  mRecall: 90.3500  data_time: 0.0142  time: 0.2337
2024/04/12 23:28:13 - mmengine - INFO - Iter(train) [16600/20000]  base_lr: 8.3236e-05 lr: 8.3236e-06  eta: 1:06:01  time: 1.1610  data_time: 0.0129  memory: 7971  grad_norm: 151.4503  loss: 8.0572  decode.loss_cls: 0.0525  decode.loss_mask: 0.4182  decode.loss_dice: 0.3266  decode.d0.loss_cls: 0.1682  decode.d0.loss_mask: 0.4258  decode.d0.loss_dice: 0.3535  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.4270  decode.d1.loss_dice: 0.3211  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.4162  decode.d2.loss_dice: 0.3225  decode.d3.loss_cls: 0.0515  decode.d3.loss_mask: 0.4091  decode.d3.loss_dice: 0.3294  decode.d4.loss_cls: 0.0480  decode.d4.loss_mask: 0.4067  decode.d4.loss_dice: 0.3261  decode.d5.loss_cls: 0.0553  decode.d5.loss_mask: 0.4128  decode.d5.loss_dice: 0.3262  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.4083  decode.d6.loss_dice: 0.3221  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.4119  decode.d7.loss_dice: 0.3154  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.4108  decode.d8.loss_dice: 0.3134
2024/04/12 23:30:10 - mmengine - INFO - Iter(train) [16700/20000]  base_lr: 8.3134e-05 lr: 8.3134e-06  eta: 1:04:05  time: 1.1706  data_time: 0.0122  memory: 7967  grad_norm: 237.3821  loss: 8.4146  decode.loss_cls: 0.0410  decode.loss_mask: 0.4295  decode.loss_dice: 0.3575  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 0.4640  decode.d0.loss_dice: 0.3865  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.4374  decode.d1.loss_dice: 0.3657  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.4323  decode.d2.loss_dice: 0.3654  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.4289  decode.d3.loss_dice: 0.3560  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.4281  decode.d4.loss_dice: 0.3445  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.4288  decode.d5.loss_dice: 0.3591  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.4311  decode.d6.loss_dice: 0.3560  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.4308  decode.d7.loss_dice: 0.3591  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.4288  decode.d8.loss_dice: 0.3435
2024/04/12 23:32:07 - mmengine - INFO - Iter(train) [16800/20000]  base_lr: 8.3032e-05 lr: 8.3032e-06  eta: 1:02:08  time: 1.1686  data_time: 0.0122  memory: 7967  grad_norm: 155.6353  loss: 11.1203  decode.loss_cls: 0.1077  decode.loss_mask: 0.4794  decode.loss_dice: 0.5354  decode.d0.loss_cls: 0.1890  decode.d0.loss_mask: 0.4660  decode.d0.loss_dice: 0.5562  decode.d1.loss_cls: 0.1525  decode.d1.loss_mask: 0.4509  decode.d1.loss_dice: 0.5035  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.4741  decode.d2.loss_dice: 0.5413  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 0.4819  decode.d3.loss_dice: 0.5300  decode.d4.loss_cls: 0.0868  decode.d4.loss_mask: 0.4745  decode.d4.loss_dice: 0.5112  decode.d5.loss_cls: 0.0994  decode.d5.loss_mask: 0.4542  decode.d5.loss_dice: 0.5395  decode.d6.loss_cls: 0.1237  decode.d6.loss_mask: 0.4594  decode.d6.loss_dice: 0.5611  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 0.4565  decode.d7.loss_dice: 0.5046  decode.d8.loss_cls: 0.1204  decode.d8.loss_mask: 0.4550  decode.d8.loss_dice: 0.5118
2024/04/12 23:34:03 - mmengine - INFO - Iter(train) [16900/20000]  base_lr: 8.2930e-05 lr: 8.2930e-06  eta: 1:00:12  time: 1.1612  data_time: 0.0115  memory: 7967  grad_norm: 176.8552  loss: 11.8488  decode.loss_cls: 0.1136  decode.loss_mask: 0.5919  decode.loss_dice: 0.4702  decode.d0.loss_cls: 0.2187  decode.d0.loss_mask: 0.6071  decode.d0.loss_dice: 0.4812  decode.d1.loss_cls: 0.0954  decode.d1.loss_mask: 0.5936  decode.d1.loss_dice: 0.4759  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.6306  decode.d2.loss_dice: 0.4856  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.6303  decode.d3.loss_dice: 0.4946  decode.d4.loss_cls: 0.1044  decode.d4.loss_mask: 0.5788  decode.d4.loss_dice: 0.4720  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 0.5908  decode.d5.loss_dice: 0.4748  decode.d6.loss_cls: 0.1268  decode.d6.loss_mask: 0.5891  decode.d6.loss_dice: 0.4580  decode.d7.loss_cls: 0.1215  decode.d7.loss_mask: 0.5925  decode.d7.loss_dice: 0.4642  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.5796  decode.d8.loss_dice: 0.4579
2024/04/12 23:35:59 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 23:35:59 - mmengine - INFO - Iter(train) [17000/20000]  base_lr: 8.2828e-05 lr: 8.2828e-06  eta: 0:58:15  time: 1.1672  data_time: 0.0129  memory: 7967  grad_norm: 159.8886  loss: 7.1930  decode.loss_cls: 0.0286  decode.loss_mask: 0.3392  decode.loss_dice: 0.3666  decode.d0.loss_cls: 0.1202  decode.d0.loss_mask: 0.3467  decode.d0.loss_dice: 0.3510  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 0.3389  decode.d1.loss_dice: 0.3693  decode.d2.loss_cls: 0.0338  decode.d2.loss_mask: 0.3383  decode.d2.loss_dice: 0.3412  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.3330  decode.d3.loss_dice: 0.3350  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 0.3319  decode.d4.loss_dice: 0.3309  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.3342  decode.d5.loss_dice: 0.3581  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.3356  decode.d6.loss_dice: 0.3468  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.3357  decode.d7.loss_dice: 0.3514  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.3358  decode.d8.loss_dice: 0.3467
2024/04/12 23:36:01 - mmengine - INFO - per class results:
2024/04/12 23:36:01 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.76 | 98.61 | 98.35 | 98.35  |    98.1   | 98.61  |
| monolayer  | 87.41 | 92.25 | 93.28 | 93.28  |   94.34   | 92.25  |
|  bilayer   | 74.65 | 89.12 | 85.48 | 85.48  |   82.13   | 89.12  |
| multilayer | 86.22 |  91.8 |  92.6 |  92.6  |   93.41   |  91.8  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 23:36:01 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8300  mIoU: 86.2600  mAcc: 92.9400  mDice: 92.4300  mFscore: 92.4300  mPrecision: 92.0000  mRecall: 92.9400  data_time: 0.0087  time: 0.2284
2024/04/12 23:37:58 - mmengine - INFO - Iter(train) [17100/20000]  base_lr: 8.2726e-05 lr: 8.2726e-06  eta: 0:56:19  time: 1.1645  data_time: 0.0122  memory: 7963  grad_norm: 186.7258  loss: 8.2059  decode.loss_cls: 0.0426  decode.loss_mask: 0.4068  decode.loss_dice: 0.3532  decode.d0.loss_cls: 0.1719  decode.d0.loss_mask: 0.4137  decode.d0.loss_dice: 0.3649  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 0.4021  decode.d1.loss_dice: 0.3591  decode.d2.loss_cls: 0.0311  decode.d2.loss_mask: 0.4045  decode.d2.loss_dice: 0.3576  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.4027  decode.d3.loss_dice: 0.3546  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.4160  decode.d4.loss_dice: 0.3643  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 0.4126  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 0.0507  decode.d6.loss_mask: 0.4045  decode.d6.loss_dice: 0.3419  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.4058  decode.d7.loss_dice: 0.3550  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.4089  decode.d8.loss_dice: 0.3515
2024/04/12 23:39:54 - mmengine - INFO - Iter(train) [17200/20000]  base_lr: 8.2624e-05 lr: 8.2624e-06  eta: 0:54:22  time: 1.1657  data_time: 0.0121  memory: 7967  grad_norm: 217.5016  loss: 7.2178  decode.loss_cls: 0.0104  decode.loss_mask: 0.3905  decode.loss_dice: 0.2991  decode.d0.loss_cls: 0.1498  decode.d0.loss_mask: 0.3994  decode.d0.loss_dice: 0.3100  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.3896  decode.d1.loss_dice: 0.3072  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.3898  decode.d2.loss_dice: 0.3040  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.3939  decode.d3.loss_dice: 0.3068  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.3862  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.3881  decode.d5.loss_dice: 0.2997  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.3904  decode.d6.loss_dice: 0.3031  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.3895  decode.d7.loss_dice: 0.3041  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.3919  decode.d8.loss_dice: 0.3041
2024/04/12 23:41:51 - mmengine - INFO - Iter(train) [17300/20000]  base_lr: 8.2521e-05 lr: 8.2521e-06  eta: 0:52:26  time: 1.1688  data_time: 0.0136  memory: 7967  grad_norm: 119.2000  loss: 5.9585  decode.loss_cls: 0.0073  decode.loss_mask: 0.3110  decode.loss_dice: 0.2636  decode.d0.loss_cls: 0.1169  decode.d0.loss_mask: 0.3225  decode.d0.loss_dice: 0.2721  decode.d1.loss_cls: 0.0144  decode.d1.loss_mask: 0.3130  decode.d1.loss_dice: 0.2566  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.3128  decode.d2.loss_dice: 0.2547  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.3106  decode.d3.loss_dice: 0.2735  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.3159  decode.d4.loss_dice: 0.2646  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.3131  decode.d5.loss_dice: 0.2630  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.3112  decode.d6.loss_dice: 0.2602  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.3118  decode.d7.loss_dice: 0.2680  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.3116  decode.d8.loss_dice: 0.2666
2024/04/12 23:43:48 - mmengine - INFO - Iter(train) [17400/20000]  base_lr: 8.2419e-05 lr: 8.2419e-06  eta: 0:50:29  time: 1.1833  data_time: 0.0129  memory: 7963  grad_norm: 249.0661  loss: 8.4326  decode.loss_cls: 0.0470  decode.loss_mask: 0.3835  decode.loss_dice: 0.4117  decode.d0.loss_cls: 0.1335  decode.d0.loss_mask: 0.3984  decode.d0.loss_dice: 0.3928  decode.d1.loss_cls: 0.0515  decode.d1.loss_mask: 0.3877  decode.d1.loss_dice: 0.3847  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.3808  decode.d2.loss_dice: 0.3949  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.3775  decode.d3.loss_dice: 0.3824  decode.d4.loss_cls: 0.0662  decode.d4.loss_mask: 0.3783  decode.d4.loss_dice: 0.3944  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.3753  decode.d5.loss_dice: 0.3880  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.3796  decode.d6.loss_dice: 0.3817  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.3843  decode.d7.loss_dice: 0.3971  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.3830  decode.d8.loss_dice: 0.4034
2024/04/12 23:45:46 - mmengine - INFO - Iter(train) [17500/20000]  base_lr: 8.2317e-05 lr: 8.2317e-06  eta: 0:48:33  time: 1.1743  data_time: 0.0125  memory: 7968  grad_norm: 154.6133  loss: 8.7317  decode.loss_cls: 0.0647  decode.loss_mask: 0.3884  decode.loss_dice: 0.4263  decode.d0.loss_cls: 0.0968  decode.d0.loss_mask: 0.3887  decode.d0.loss_dice: 0.4484  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.3800  decode.d1.loss_dice: 0.4241  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.3881  decode.d2.loss_dice: 0.4539  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.3904  decode.d3.loss_dice: 0.4335  decode.d4.loss_cls: 0.0259  decode.d4.loss_mask: 0.3886  decode.d4.loss_dice: 0.4381  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.3941  decode.d5.loss_dice: 0.4320  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.3847  decode.d6.loss_dice: 0.4216  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.3806  decode.d7.loss_dice: 0.4184  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.3972  decode.d8.loss_dice: 0.4343
2024/04/12 23:45:46 - mmengine - INFO - Saving checkpoint at 17500 iterations
2024/04/12 23:45:50 - mmengine - INFO - per class results:
2024/04/12 23:45:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.85 | 98.61 |  98.4 |  98.4  |   98.18   | 98.61  |
| monolayer  | 86.13 | 93.27 | 92.55 | 92.55  |   91.84   | 93.27  |
|  bilayer   |  69.2 | 79.23 |  81.8 |  81.8  |   84.54   | 79.23  |
| multilayer | 85.51 | 90.29 | 92.19 | 92.19  |   94.18   | 90.29  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 23:45:50 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.4700  mIoU: 84.4200  mAcc: 90.3500  mDice: 91.2300  mFscore: 91.2300  mPrecision: 92.1800  mRecall: 90.3500  data_time: 0.0112  time: 0.2304
2024/04/12 23:47:47 - mmengine - INFO - Iter(train) [17600/20000]  base_lr: 8.2215e-05 lr: 8.2215e-06  eta: 0:46:36  time: 1.1816  data_time: 0.0136  memory: 7967  grad_norm: 188.3376  loss: 7.2037  decode.loss_cls: 0.0339  decode.loss_mask: 0.3418  decode.loss_dice: 0.3291  decode.d0.loss_cls: 0.1270  decode.d0.loss_mask: 0.3553  decode.d0.loss_dice: 0.3467  decode.d1.loss_cls: 0.0455  decode.d1.loss_mask: 0.3554  decode.d1.loss_dice: 0.3198  decode.d2.loss_cls: 0.0275  decode.d2.loss_mask: 0.3438  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.0376  decode.d3.loss_mask: 0.3460  decode.d3.loss_dice: 0.3276  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.3446  decode.d4.loss_dice: 0.3165  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.3422  decode.d5.loss_dice: 0.3304  decode.d6.loss_cls: 0.0380  decode.d6.loss_mask: 0.3468  decode.d6.loss_dice: 0.3274  decode.d7.loss_cls: 0.0340  decode.d7.loss_mask: 0.3506  decode.d7.loss_dice: 0.3179  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.3438  decode.d8.loss_dice: 0.3270
2024/04/12 23:49:45 - mmengine - INFO - Iter(train) [17700/20000]  base_lr: 8.2113e-05 lr: 8.2113e-06  eta: 0:44:40  time: 1.1819  data_time: 0.0137  memory: 7967  grad_norm: 160.7130  loss: 7.8711  decode.loss_cls: 0.0107  decode.loss_mask: 0.4441  decode.loss_dice: 0.3078  decode.d0.loss_cls: 0.1382  decode.d0.loss_mask: 0.4784  decode.d0.loss_dice: 0.3123  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.4454  decode.d1.loss_dice: 0.3281  decode.d2.loss_cls: 0.0142  decode.d2.loss_mask: 0.4409  decode.d2.loss_dice: 0.3160  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.4337  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.4356  decode.d4.loss_dice: 0.3148  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.4369  decode.d5.loss_dice: 0.3134  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.4423  decode.d6.loss_dice: 0.3218  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.4504  decode.d7.loss_dice: 0.3123  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.4527  decode.d8.loss_dice: 0.3171
2024/04/12 23:51:42 - mmengine - INFO - Iter(train) [17800/20000]  base_lr: 8.2011e-05 lr: 8.2011e-06  eta: 0:42:44  time: 1.1763  data_time: 0.0126  memory: 7963  grad_norm: 137.8430  loss: 6.8032  decode.loss_cls: 0.0427  decode.loss_mask: 0.3393  decode.loss_dice: 0.2978  decode.d0.loss_cls: 0.1228  decode.d0.loss_mask: 0.3482  decode.d0.loss_dice: 0.3167  decode.d1.loss_cls: 0.0414  decode.d1.loss_mask: 0.3423  decode.d1.loss_dice: 0.2987  decode.d2.loss_cls: 0.0479  decode.d2.loss_mask: 0.3404  decode.d2.loss_dice: 0.2924  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.3366  decode.d3.loss_dice: 0.2984  decode.d4.loss_cls: 0.0291  decode.d4.loss_mask: 0.3340  decode.d4.loss_dice: 0.2989  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.3352  decode.d5.loss_dice: 0.3051  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.3345  decode.d6.loss_dice: 0.3004  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.3350  decode.d7.loss_dice: 0.3009  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.3381  decode.d8.loss_dice: 0.3016
2024/04/12 23:53:40 - mmengine - INFO - Iter(train) [17900/20000]  base_lr: 8.1908e-05 lr: 8.1908e-06  eta: 0:40:47  time: 1.1808  data_time: 0.0152  memory: 7967  grad_norm: 170.7978  loss: 7.5069  decode.loss_cls: 0.0356  decode.loss_mask: 0.4125  decode.loss_dice: 0.2862  decode.d0.loss_cls: 0.1355  decode.d0.loss_mask: 0.4167  decode.d0.loss_dice: 0.2983  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.4078  decode.d1.loss_dice: 0.2856  decode.d2.loss_cls: 0.0297  decode.d2.loss_mask: 0.4238  decode.d2.loss_dice: 0.2904  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.4080  decode.d3.loss_dice: 0.2879  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 0.4376  decode.d4.loss_dice: 0.3033  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.4165  decode.d5.loss_dice: 0.2921  decode.d6.loss_cls: 0.0317  decode.d6.loss_mask: 0.4100  decode.d6.loss_dice: 0.2895  decode.d7.loss_cls: 0.0284  decode.d7.loss_mask: 0.4059  decode.d7.loss_dice: 0.2853  decode.d8.loss_cls: 0.0341  decode.d8.loss_mask: 0.4126  decode.d8.loss_dice: 0.2860
2024/04/12 23:55:38 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/12 23:55:38 - mmengine - INFO - Iter(train) [18000/20000]  base_lr: 8.1806e-05 lr: 8.1806e-06  eta: 0:38:51  time: 1.1788  data_time: 0.0124  memory: 7971  grad_norm: 167.1645  loss: 8.8155  decode.loss_cls: 0.0811  decode.loss_mask: 0.4013  decode.loss_dice: 0.3807  decode.d0.loss_cls: 0.2534  decode.d0.loss_mask: 0.4239  decode.d0.loss_dice: 0.3944  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 0.4144  decode.d1.loss_dice: 0.4252  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.4038  decode.d2.loss_dice: 0.3709  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.4018  decode.d3.loss_dice: 0.3912  decode.d4.loss_cls: 0.0737  decode.d4.loss_mask: 0.4104  decode.d4.loss_dice: 0.3598  decode.d5.loss_cls: 0.0787  decode.d5.loss_mask: 0.4080  decode.d5.loss_dice: 0.3784  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.4018  decode.d6.loss_dice: 0.4004  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.3987  decode.d7.loss_dice: 0.3971  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.4000  decode.d8.loss_dice: 0.3728
2024/04/12 23:55:40 - mmengine - INFO - per class results:
2024/04/12 23:55:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.79 | 98.78 | 98.37 | 98.37  |   97.96   | 98.78  |
| monolayer  | 86.95 | 92.81 | 93.02 | 93.02  |   93.23   | 92.81  |
|  bilayer   | 74.78 | 84.37 | 85.57 | 85.57  |   86.81   | 84.37  |
| multilayer | 85.18 | 90.75 |  92.0 |  92.0  |   93.28   | 90.75  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/12 23:55:40 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.7500  mIoU: 85.9200  mAcc: 91.6800  mDice: 92.2400  mFscore: 92.2400  mPrecision: 92.8200  mRecall: 91.6800  data_time: 0.0151  time: 0.2348
2024/04/12 23:57:37 - mmengine - INFO - Iter(train) [18100/20000]  base_lr: 8.1704e-05 lr: 8.1704e-06  eta: 0:36:54  time: 1.1758  data_time: 0.0145  memory: 7963  grad_norm: 236.9369  loss: 9.4235  decode.loss_cls: 0.0759  decode.loss_mask: 0.4031  decode.loss_dice: 0.4498  decode.d0.loss_cls: 0.1946  decode.d0.loss_mask: 0.4210  decode.d0.loss_dice: 0.4618  decode.d1.loss_cls: 0.0998  decode.d1.loss_mask: 0.4042  decode.d1.loss_dice: 0.4268  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 0.4001  decode.d2.loss_dice: 0.4677  decode.d3.loss_cls: 0.1146  decode.d3.loss_mask: 0.3975  decode.d3.loss_dice: 0.4367  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.3950  decode.d4.loss_dice: 0.4402  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.4037  decode.d5.loss_dice: 0.4438  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.4068  decode.d6.loss_dice: 0.4397  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.4099  decode.d7.loss_dice: 0.4509  decode.d8.loss_cls: 0.0865  decode.d8.loss_mask: 0.4163  decode.d8.loss_dice: 0.4313
2024/04/12 23:59:35 - mmengine - INFO - Iter(train) [18200/20000]  base_lr: 8.1601e-05 lr: 8.1601e-06  eta: 0:34:58  time: 1.1641  data_time: 0.0130  memory: 7968  grad_norm: 182.7042  loss: 10.1799  decode.loss_cls: 0.0621  decode.loss_mask: 0.4830  decode.loss_dice: 0.4495  decode.d0.loss_cls: 0.1269  decode.d0.loss_mask: 0.4828  decode.d0.loss_dice: 0.4417  decode.d1.loss_cls: 0.0897  decode.d1.loss_mask: 0.4904  decode.d1.loss_dice: 0.4477  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 0.4964  decode.d2.loss_dice: 0.4380  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.5142  decode.d3.loss_dice: 0.4449  decode.d4.loss_cls: 0.0737  decode.d4.loss_mask: 0.5007  decode.d4.loss_dice: 0.4463  decode.d5.loss_cls: 0.0952  decode.d5.loss_mask: 0.5002  decode.d5.loss_dice: 0.4411  decode.d6.loss_cls: 0.0804  decode.d6.loss_mask: 0.4676  decode.d6.loss_dice: 0.4513  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.4723  decode.d7.loss_dice: 0.4371  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.4778  decode.d8.loss_dice: 0.4521
2024/04/13 00:01:33 - mmengine - INFO - Iter(train) [18300/20000]  base_lr: 8.1499e-05 lr: 8.1499e-06  eta: 0:33:01  time: 1.1831  data_time: 0.0140  memory: 7967  grad_norm: 152.8470  loss: 7.8809  decode.loss_cls: 0.0132  decode.loss_mask: 0.4287  decode.loss_dice: 0.3206  decode.d0.loss_cls: 0.1529  decode.d0.loss_mask: 0.4433  decode.d0.loss_dice: 0.3318  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.4389  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.4351  decode.d2.loss_dice: 0.3215  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.4415  decode.d3.loss_dice: 0.3346  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.4342  decode.d4.loss_dice: 0.3153  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 0.4287  decode.d5.loss_dice: 0.3188  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.4384  decode.d6.loss_dice: 0.3221  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.4336  decode.d7.loss_dice: 0.3196  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.4390  decode.d8.loss_dice: 0.3196
2024/04/13 00:03:31 - mmengine - INFO - Iter(train) [18400/20000]  base_lr: 8.1397e-05 lr: 8.1397e-06  eta: 0:31:05  time: 1.1762  data_time: 0.0138  memory: 7968  grad_norm: 209.4714  loss: 10.3443  decode.loss_cls: 0.0695  decode.loss_mask: 0.5672  decode.loss_dice: 0.3833  decode.d0.loss_cls: 0.1489  decode.d0.loss_mask: 0.5935  decode.d0.loss_dice: 0.3924  decode.d1.loss_cls: 0.0844  decode.d1.loss_mask: 0.5594  decode.d1.loss_dice: 0.4156  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.5499  decode.d2.loss_dice: 0.3904  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.5511  decode.d3.loss_dice: 0.3947  decode.d4.loss_cls: 0.0895  decode.d4.loss_mask: 0.5723  decode.d4.loss_dice: 0.4011  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.5629  decode.d5.loss_dice: 0.3900  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.5571  decode.d6.loss_dice: 0.3792  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.5607  decode.d7.loss_dice: 0.3762  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.5551  decode.d8.loss_dice: 0.3908
2024/04/13 00:05:29 - mmengine - INFO - Iter(train) [18500/20000]  base_lr: 8.1295e-05 lr: 8.1295e-06  eta: 0:29:08  time: 1.1784  data_time: 0.0136  memory: 7963  grad_norm: 241.0903  loss: 8.5973  decode.loss_cls: 0.0227  decode.loss_mask: 0.4066  decode.loss_dice: 0.4084  decode.d0.loss_cls: 0.1004  decode.d0.loss_mask: 0.4259  decode.d0.loss_dice: 0.4370  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.4081  decode.d1.loss_dice: 0.3679  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.4118  decode.d2.loss_dice: 0.3995  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.3984  decode.d3.loss_dice: 0.3780  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.3986  decode.d4.loss_dice: 0.3793  decode.d5.loss_cls: 0.0770  decode.d5.loss_mask: 0.3967  decode.d5.loss_dice: 0.3739  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.4010  decode.d6.loss_dice: 0.3839  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 0.4018  decode.d7.loss_dice: 0.3943  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.4020  decode.d8.loss_dice: 0.4111
2024/04/13 00:05:31 - mmengine - INFO - per class results:
2024/04/13 00:05:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.81 | 98.53 | 98.38 | 98.38  |   98.23   | 98.53  |
| monolayer  | 87.36 | 93.07 | 93.26 | 93.26  |   93.44   | 93.07  |
|  bilayer   | 73.84 | 85.85 | 84.95 | 84.95  |   84.07   | 85.85  |
| multilayer | 86.57 | 91.79 |  92.8 |  92.8  |   93.83   | 91.79  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/13 00:05:31 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8400  mIoU: 86.1400  mAcc: 92.3100  mDice: 92.3500  mFscore: 92.3500  mPrecision: 92.3900  mRecall: 92.3100  data_time: 0.0152  time: 0.2346
2024/04/13 00:07:29 - mmengine - INFO - Iter(train) [18600/20000]  base_lr: 8.1192e-05 lr: 8.1192e-06  eta: 0:27:12  time: 1.1792  data_time: 0.0131  memory: 7967  grad_norm: 192.8396  loss: 10.2779  decode.loss_cls: 0.0606  decode.loss_mask: 0.4862  decode.loss_dice: 0.4554  decode.d0.loss_cls: 0.2018  decode.d0.loss_mask: 0.5112  decode.d0.loss_dice: 0.4802  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.4710  decode.d1.loss_dice: 0.4460  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.4738  decode.d2.loss_dice: 0.4581  decode.d3.loss_cls: 0.0550  decode.d3.loss_mask: 0.4918  decode.d3.loss_dice: 0.4685  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.4831  decode.d4.loss_dice: 0.4435  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.4880  decode.d5.loss_dice: 0.4674  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.5159  decode.d6.loss_dice: 0.4551  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.5200  decode.d7.loss_dice: 0.4757  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.4954  decode.d8.loss_dice: 0.4563
2024/04/13 00:09:27 - mmengine - INFO - Iter(train) [18700/20000]  base_lr: 8.1090e-05 lr: 8.1090e-06  eta: 0:25:15  time: 1.1697  data_time: 0.0130  memory: 7967  grad_norm: 229.5185  loss: 7.3022  decode.loss_cls: 0.0169  decode.loss_mask: 0.3688  decode.loss_dice: 0.3186  decode.d0.loss_cls: 0.1266  decode.d0.loss_mask: 0.3823  decode.d0.loss_dice: 0.3400  decode.d1.loss_cls: 0.0435  decode.d1.loss_mask: 0.3543  decode.d1.loss_dice: 0.3192  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.3637  decode.d2.loss_dice: 0.2966  decode.d3.loss_cls: 0.0311  decode.d3.loss_mask: 0.3737  decode.d3.loss_dice: 0.3273  decode.d4.loss_cls: 0.0218  decode.d4.loss_mask: 0.3845  decode.d4.loss_dice: 0.3198  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.3799  decode.d5.loss_dice: 0.3167  decode.d6.loss_cls: 0.0204  decode.d6.loss_mask: 0.3784  decode.d6.loss_dice: 0.3183  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 0.3799  decode.d7.loss_dice: 0.3188  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 0.3690  decode.d8.loss_dice: 0.3064
2024/04/13 00:11:24 - mmengine - INFO - Iter(train) [18800/20000]  base_lr: 8.0988e-05 lr: 8.0988e-06  eta: 0:23:19  time: 1.1725  data_time: 0.0148  memory: 7971  grad_norm: 168.9510  loss: 7.2469  decode.loss_cls: 0.0173  decode.loss_mask: 0.3493  decode.loss_dice: 0.3422  decode.d0.loss_cls: 0.0806  decode.d0.loss_mask: 0.3591  decode.d0.loss_dice: 0.3179  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.3701  decode.d1.loss_dice: 0.3411  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.3515  decode.d2.loss_dice: 0.3300  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.3627  decode.d3.loss_dice: 0.3407  decode.d4.loss_cls: 0.0268  decode.d4.loss_mask: 0.3496  decode.d4.loss_dice: 0.3481  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.3488  decode.d5.loss_dice: 0.3493  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.3523  decode.d6.loss_dice: 0.3333  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.3562  decode.d7.loss_dice: 0.3542  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.3561  decode.d8.loss_dice: 0.3512
2024/04/13 00:13:22 - mmengine - INFO - Iter(train) [18900/20000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 0:21:22  time: 1.1792  data_time: 0.0114  memory: 7963  grad_norm: 137.4079  loss: 7.0985  decode.loss_cls: 0.0397  decode.loss_mask: 0.3402  decode.loss_dice: 0.3151  decode.d0.loss_cls: 0.1110  decode.d0.loss_mask: 0.3540  decode.d0.loss_dice: 0.3483  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.3330  decode.d1.loss_dice: 0.3073  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.3426  decode.d2.loss_dice: 0.3385  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.3398  decode.d3.loss_dice: 0.3317  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.3388  decode.d4.loss_dice: 0.3326  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.3413  decode.d5.loss_dice: 0.3256  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.3415  decode.d6.loss_dice: 0.3443  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.3439  decode.d7.loss_dice: 0.3356  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.3426  decode.d8.loss_dice: 0.3462
2024/04/13 00:15:19 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/13 00:15:19 - mmengine - INFO - Iter(train) [19000/20000]  base_lr: 8.0783e-05 lr: 8.0783e-06  eta: 0:19:26  time: 1.1683  data_time: 0.0110  memory: 7967  grad_norm: 184.9094  loss: 7.6409  decode.loss_cls: 0.0474  decode.loss_mask: 0.3830  decode.loss_dice: 0.3214  decode.d0.loss_cls: 0.1088  decode.d0.loss_mask: 0.4058  decode.d0.loss_dice: 0.3398  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.3875  decode.d1.loss_dice: 0.3247  decode.d2.loss_cls: 0.0398  decode.d2.loss_mask: 0.3875  decode.d2.loss_dice: 0.3198  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.3761  decode.d3.loss_dice: 0.3445  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.3764  decode.d4.loss_dice: 0.3334  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.3827  decode.d5.loss_dice: 0.3451  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.3775  decode.d6.loss_dice: 0.3381  decode.d7.loss_cls: 0.0306  decode.d7.loss_mask: 0.3803  decode.d7.loss_dice: 0.3321  decode.d8.loss_cls: 0.0361  decode.d8.loss_mask: 0.3788  decode.d8.loss_dice: 0.3245
2024/04/13 00:15:21 - mmengine - INFO - per class results:
2024/04/13 00:15:21 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.89 |  98.7 | 98.42 | 98.42  |   98.14   |  98.7  |
| monolayer  | 87.66 | 92.98 | 93.43 | 93.43  |   93.88   | 92.98  |
|  bilayer   | 74.36 | 87.01 | 85.29 | 85.29  |   83.64   | 87.01  |
| multilayer | 86.24 | 91.08 | 92.61 | 92.61  |    94.2   | 91.08  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/13 00:15:21 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.9100  mIoU: 86.2900  mAcc: 92.4400  mDice: 92.4400  mFscore: 92.4400  mPrecision: 92.4700  mRecall: 92.4400  data_time: 0.0131  time: 0.2324
2024/04/13 00:17:18 - mmengine - INFO - Iter(train) [19100/20000]  base_lr: 8.0680e-05 lr: 8.0680e-06  eta: 0:17:29  time: 1.1729  data_time: 0.0116  memory: 7963  grad_norm: 186.5110  loss: 7.3305  decode.loss_cls: 0.0526  decode.loss_mask: 0.3454  decode.loss_dice: 0.3247  decode.d0.loss_cls: 0.1368  decode.d0.loss_mask: 0.3615  decode.d0.loss_dice: 0.3287  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.3532  decode.d1.loss_dice: 0.3372  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.3528  decode.d2.loss_dice: 0.3155  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.3518  decode.d3.loss_dice: 0.3183  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.3478  decode.d4.loss_dice: 0.3056  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.3510  decode.d5.loss_dice: 0.3512  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.3493  decode.d6.loss_dice: 0.3001  decode.d7.loss_cls: 0.0411  decode.d7.loss_mask: 0.3527  decode.d7.loss_dice: 0.3429  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.3494  decode.d8.loss_dice: 0.3465
2024/04/13 00:19:14 - mmengine - INFO - Iter(train) [19200/20000]  base_lr: 8.0578e-05 lr: 8.0578e-06  eta: 0:15:32  time: 1.1662  data_time: 0.0121  memory: 7965  grad_norm: 219.1917  loss: 12.2552  decode.loss_cls: 0.1331  decode.loss_mask: 0.6031  decode.loss_dice: 0.4658  decode.d0.loss_cls: 0.2956  decode.d0.loss_mask: 0.6302  decode.d0.loss_dice: 0.5200  decode.d1.loss_cls: 0.1616  decode.d1.loss_mask: 0.5902  decode.d1.loss_dice: 0.4707  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.5920  decode.d2.loss_dice: 0.5011  decode.d3.loss_cls: 0.1226  decode.d3.loss_mask: 0.5794  decode.d3.loss_dice: 0.4786  decode.d4.loss_cls: 0.1430  decode.d4.loss_mask: 0.5783  decode.d4.loss_dice: 0.4792  decode.d5.loss_cls: 0.1375  decode.d5.loss_mask: 0.5830  decode.d5.loss_dice: 0.4775  decode.d6.loss_cls: 0.1217  decode.d6.loss_mask: 0.5956  decode.d6.loss_dice: 0.4882  decode.d7.loss_cls: 0.1455  decode.d7.loss_mask: 0.5774  decode.d7.loss_dice: 0.4701  decode.d8.loss_cls: 0.1183  decode.d8.loss_mask: 0.6013  decode.d8.loss_dice: 0.4922
2024/04/13 00:21:11 - mmengine - INFO - Iter(train) [19300/20000]  base_lr: 8.0475e-05 lr: 8.0475e-06  eta: 0:13:36  time: 1.1614  data_time: 0.0123  memory: 7967  grad_norm: 177.9118  loss: 7.1811  decode.loss_cls: 0.0069  decode.loss_mask: 0.3563  decode.loss_dice: 0.3189  decode.d0.loss_cls: 0.1191  decode.d0.loss_mask: 0.3661  decode.d0.loss_dice: 0.3531  decode.d1.loss_cls: 0.0383  decode.d1.loss_mask: 0.3548  decode.d1.loss_dice: 0.3193  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.3563  decode.d2.loss_dice: 0.3386  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.3520  decode.d3.loss_dice: 0.3379  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.3561  decode.d4.loss_dice: 0.3392  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.3584  decode.d5.loss_dice: 0.3414  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.3593  decode.d6.loss_dice: 0.3367  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.3558  decode.d7.loss_dice: 0.3303  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.3587  decode.d8.loss_dice: 0.3259
2024/04/13 00:23:07 - mmengine - INFO - Iter(train) [19400/20000]  base_lr: 8.0373e-05 lr: 8.0373e-06  eta: 0:11:39  time: 1.1630  data_time: 0.0111  memory: 7969  grad_norm: 189.5995  loss: 6.2441  decode.loss_cls: 0.0578  decode.loss_mask: 0.2503  decode.loss_dice: 0.2952  decode.d0.loss_cls: 0.1453  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.3306  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.2505  decode.d1.loss_dice: 0.2940  decode.d2.loss_cls: 0.0793  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.2747  decode.d3.loss_cls: 0.0662  decode.d3.loss_mask: 0.2493  decode.d3.loss_dice: 0.2993  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.2484  decode.d4.loss_dice: 0.2826  decode.d5.loss_cls: 0.0885  decode.d5.loss_mask: 0.2522  decode.d5.loss_dice: 0.3066  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.2495  decode.d6.loss_dice: 0.2790  decode.d7.loss_cls: 0.0797  decode.d7.loss_mask: 0.2532  decode.d7.loss_dice: 0.2988  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2960
2024/04/13 00:25:04 - mmengine - INFO - Iter(train) [19500/20000]  base_lr: 8.0271e-05 lr: 8.0271e-06  eta: 0:09:43  time: 1.1622  data_time: 0.0113  memory: 7967  grad_norm: 192.9773  loss: 9.3306  decode.loss_cls: 0.0408  decode.loss_mask: 0.4616  decode.loss_dice: 0.4006  decode.d0.loss_cls: 0.1874  decode.d0.loss_mask: 0.4790  decode.d0.loss_dice: 0.4199  decode.d1.loss_cls: 0.0327  decode.d1.loss_mask: 0.4582  decode.d1.loss_dice: 0.3899  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.4564  decode.d2.loss_dice: 0.3956  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.4519  decode.d3.loss_dice: 0.4079  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.4742  decode.d4.loss_dice: 0.3983  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.4678  decode.d5.loss_dice: 0.3982  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.4697  decode.d6.loss_dice: 0.4143  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.4671  decode.d7.loss_dice: 0.4099  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.4631  decode.d8.loss_dice: 0.4073
2024/04/13 00:25:06 - mmengine - INFO - per class results:
2024/04/13 00:25:06 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.89 | 98.47 | 98.42 | 98.42  |   98.37   | 98.47  |
| monolayer  | 87.57 |  93.1 | 93.38 | 93.38  |   93.65   |  93.1  |
|  bilayer   | 75.32 | 86.54 | 85.93 | 85.93  |   85.32   | 86.54  |
| multilayer | 86.55 | 92.94 | 92.79 | 92.79  |   92.64   | 92.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/13 00:25:06 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.9400  mIoU: 86.5800  mAcc: 92.7600  mDice: 92.6300  mFscore: 92.6300  mPrecision: 92.5000  mRecall: 92.7600  data_time: 0.0177  time: 0.2369
2024/04/13 00:27:02 - mmengine - INFO - Iter(train) [19600/20000]  base_lr: 8.0168e-05 lr: 8.0168e-06  eta: 0:07:46  time: 1.1600  data_time: 0.0111  memory: 7967  grad_norm: 189.9264  loss: 10.5087  decode.loss_cls: 0.1392  decode.loss_mask: 0.5027  decode.loss_dice: 0.4349  decode.d0.loss_cls: 0.2442  decode.d0.loss_mask: 0.4817  decode.d0.loss_dice: 0.4915  decode.d1.loss_cls: 0.1404  decode.d1.loss_mask: 0.4690  decode.d1.loss_dice: 0.4275  decode.d2.loss_cls: 0.1293  decode.d2.loss_mask: 0.4573  decode.d2.loss_dice: 0.3832  decode.d3.loss_cls: 0.1284  decode.d3.loss_mask: 0.4653  decode.d3.loss_dice: 0.4341  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.4757  decode.d4.loss_dice: 0.4232  decode.d5.loss_cls: 0.1330  decode.d5.loss_mask: 0.4877  decode.d5.loss_dice: 0.4367  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.4658  decode.d6.loss_dice: 0.4215  decode.d7.loss_cls: 0.0948  decode.d7.loss_mask: 0.4778  decode.d7.loss_dice: 0.4681  decode.d8.loss_cls: 0.1487  decode.d8.loss_mask: 0.4626  decode.d8.loss_dice: 0.4397
2024/04/13 00:28:58 - mmengine - INFO - Iter(train) [19700/20000]  base_lr: 8.0066e-05 lr: 8.0066e-06  eta: 0:05:49  time: 1.1694  data_time: 0.0113  memory: 7971  grad_norm: 156.1751  loss: 9.4865  decode.loss_cls: 0.1261  decode.loss_mask: 0.3864  decode.loss_dice: 0.4284  decode.d0.loss_cls: 0.1822  decode.d0.loss_mask: 0.4061  decode.d0.loss_dice: 0.4513  decode.d1.loss_cls: 0.1197  decode.d1.loss_mask: 0.3893  decode.d1.loss_dice: 0.4298  decode.d2.loss_cls: 0.1092  decode.d2.loss_mask: 0.3889  decode.d2.loss_dice: 0.4359  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.3923  decode.d3.loss_dice: 0.4507  decode.d4.loss_cls: 0.1320  decode.d4.loss_mask: 0.3864  decode.d4.loss_dice: 0.4249  decode.d5.loss_cls: 0.1306  decode.d5.loss_mask: 0.3871  decode.d5.loss_dice: 0.4414  decode.d6.loss_cls: 0.1447  decode.d6.loss_mask: 0.3727  decode.d6.loss_dice: 0.4344  decode.d7.loss_cls: 0.1264  decode.d7.loss_mask: 0.3716  decode.d7.loss_dice: 0.4242  decode.d8.loss_cls: 0.1109  decode.d8.loss_mask: 0.3792  decode.d8.loss_dice: 0.4389
2024/04/13 00:30:55 - mmengine - INFO - Iter(train) [19800/20000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 0:03:53  time: 1.1644  data_time: 0.0113  memory: 7963  grad_norm: 144.4719  loss: 7.8441  decode.loss_cls: 0.0622  decode.loss_mask: 0.3987  decode.loss_dice: 0.3189  decode.d0.loss_cls: 0.1744  decode.d0.loss_mask: 0.4030  decode.d0.loss_dice: 0.3285  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.4070  decode.d1.loss_dice: 0.3111  decode.d2.loss_cls: 0.0653  decode.d2.loss_mask: 0.3949  decode.d2.loss_dice: 0.3234  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.3978  decode.d3.loss_dice: 0.3183  decode.d4.loss_cls: 0.0613  decode.d4.loss_mask: 0.3990  decode.d4.loss_dice: 0.3213  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.3914  decode.d5.loss_dice: 0.3181  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.3836  decode.d6.loss_dice: 0.3226  decode.d7.loss_cls: 0.0353  decode.d7.loss_mask: 0.3880  decode.d7.loss_dice: 0.3269  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.3965  decode.d8.loss_dice: 0.3191
2024/04/13 00:32:52 - mmengine - INFO - Iter(train) [19900/20000]  base_lr: 7.9861e-05 lr: 7.9861e-06  eta: 0:01:56  time: 1.1607  data_time: 0.0114  memory: 7968  grad_norm: 187.4625  loss: 8.4936  decode.loss_cls: 0.0429  decode.loss_mask: 0.4385  decode.loss_dice: 0.3580  decode.d0.loss_cls: 0.1459  decode.d0.loss_mask: 0.4497  decode.d0.loss_dice: 0.3679  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 0.4322  decode.d1.loss_dice: 0.3547  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.4394  decode.d2.loss_dice: 0.3607  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.4303  decode.d3.loss_dice: 0.3467  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.4362  decode.d4.loss_dice: 0.3497  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.4353  decode.d5.loss_dice: 0.3536  decode.d6.loss_cls: 0.0422  decode.d6.loss_mask: 0.4432  decode.d6.loss_dice: 0.3595  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.4384  decode.d7.loss_dice: 0.3469  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.4368  decode.d8.loss_dice: 0.3500
2024/04/13 00:34:48 - mmengine - INFO - Exp name: mask2former-ful_20240412_180429
2024/04/13 00:34:48 - mmengine - INFO - Iter(train) [20000/20000]  base_lr: 7.9758e-05 lr: 7.9758e-06  eta: 0:00:00  time: 1.1636  data_time: 0.0112  memory: 7967  grad_norm: 569.9276  loss: 6.7944  decode.loss_cls: 0.0272  decode.loss_mask: 0.3627  decode.loss_dice: 0.2944  decode.d0.loss_cls: 0.1671  decode.d0.loss_mask: 0.3610  decode.d0.loss_dice: 0.3189  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 0.3159  decode.d1.loss_dice: 0.2923  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.3372  decode.d2.loss_dice: 0.3042  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.3409  decode.d3.loss_dice: 0.2916  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 0.3352  decode.d4.loss_dice: 0.2936  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.3383  decode.d5.loss_dice: 0.3003  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.3283  decode.d6.loss_dice: 0.2814  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.3328  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.3711  decode.d8.loss_dice: 0.3056
2024/04/13 00:34:48 - mmengine - INFO - Saving checkpoint at 20000 iterations
2024/04/13 00:34:52 - mmengine - INFO - per class results:
2024/04/13 00:34:52 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| Background | 96.91 | 98.45 | 98.43 | 98.43  |    98.4   | 98.45  |
| monolayer  | 87.49 | 93.81 | 93.33 | 93.33  |   92.85   | 93.81  |
|  bilayer   | 74.16 | 84.67 | 85.16 | 85.16  |   85.66   | 84.67  |
| multilayer | 86.06 |  91.2 | 92.51 | 92.51  |   93.86   |  91.2  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/04/13 00:34:52 - mmengine - INFO - Iter(val) [8/8]    aAcc: 95.8800  mIoU: 86.1500  mAcc: 92.0300  mDice: 92.3600  mFscore: 92.3600  mPrecision: 92.6900  mRecall: 92.0300  data_time: 0.0107  time: 0.2302
